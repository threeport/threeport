{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Threeport","text":"<p>Threeport is an open source application platform and platform engineering framework.</p> <p>What is an application platform?  It is a system that is used to deliver software into its runtime environment and manage it over time.</p> <p>What is platform engineering?  It is a software engineering discipline focused on the development of application platforms.</p> <p>Threeport consists of two parts:</p> <ol> <li>Threeport Core: The core components of an application platform.  It includes an API server, database, message broker and core modules.  Modules abstract and automate distinct platform engineering concerns.  For more detail, see the Threeport Core architecture document.</li> <li>Threeport SDK: A framework for building independent modules to add to Threeport Core.  The SDK is Ruby on Rails for application platforms.  To learn more about the SDK, see the Threeport SDK Introduction document.</li> </ol>"},{"location":"#motivation","title":"Motivation","text":"<p>Software delivery had been dominated by DevOps practices for the past decade or so.  This is primarily a configuration management practice.  Modern software has become increasingly complex to manage and config management is just no longer sufficient for the task.</p> <p>Threeport takes a software engineering - rather than a config management - approach to application platforms.  We call this \"Application Orchestration.\"</p> <p>To learn more on this topic, see the Application Orchestration concepts document.</p> <p>Fundamentally, Threeport exists to reduce engineering toil, improve resource efficiency, and make the most complex software systems manageable by relatively small teams.  This leads to the delivery of more feature-rich and more reliable software with lower infrastructure and engineering costs.</p> <p>Better software.  Lower costs.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<p>Check out the Getting Started guide to try out Threeport for yourself.</p> <p>See our Application Orchestration document in our Concepts section for more information on how Threeport approaches software delivery.</p> <p>To dive into the architecture of Threeport, see the Threeport Core architecture.</p>"},{"location":"contact/","title":"Contact","text":"<p>If you find a bug or issue, please open an issue on Github</p> <p>If you would like to contribute to Threeport:</p> <ul> <li>Check out our Developer   Docs</li> <li>For simple bug fixes or documentation updates, please open a   PR</li> <li>For new feature additions or involved changes, please open an   issue before you   start work.</li> </ul> <p>For general help or questions, hit us up on Discord</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#what-kind-of-applications-does-threeport-support","title":"What kind of applications does Threeport support?","text":"<p>Threeport supports any containerized application.  It doesn't matter what language your app is developed in or what your build processes are.  Threeport intentionally does not dictate any build processes, frameworks or app architecture. Your continuous integration processes need not change.  If your app can be built into a container image, it can run on Threeport.</p>"},{"location":"faq/#does-threeport-support-runtime-environments-besides-kubernetes","title":"Does Threeport support runtime environments besides Kubernetes?","text":"<p>Threeport can be extended to support other runtime environments or container orchestrators, but Kubernetes is the only one supported today.  Threeport makes using Kubernetes much more approachable and provides access to the capabilities of that system.</p>"},{"location":"faq/#which-cloud-providers-does-threeport-support","title":"Which cloud providers does Threeport support?","text":"<p>Today, Amazon Web Services is the only supported cloud provider.  See our roadmap for plans to support others.</p>"},{"location":"faq/#where-did-the-name-threeport-come-from","title":"Where did the name \"Threeport\" come from?","text":"<p>Your application is a boat and it has dependencies on ports, or something like that.</p>"},{"location":"faq/#how-can-i-contribute-to-threeport","title":"How can I contribute to Threeport?","text":"<p>The developer docs for Threeport are on GitHub.  There you'll find a contributing guide and quickstart guide.</p>"},{"location":"faq/#what-is-on-the-threeport-roadmap","title":"What is on the Threeport roadmap?","text":"<p>You can find the project roadmap on GitHub as well.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<ol> <li> <p>Install tptctl: If you don't have the Threeport command    line tool installed, start with this step.</p> </li> <li> <p>Install Threeport Locally: Install the    Threeport core system on your local workstation. This is the fastest way    to see how Threeport works.</p> <p>a. Deploy a Sample Workload Locally: Deploy a sample WordPress app to see how Threeport manages workload delivery.</p> </li> <li> <p>Install Threeport on AWS: Install the Threeport    core system on AWS in an EKS cluster. This gives a more realistic example    of how Threeport is used in practice. This guide requires an AWS    account.</p> <p>a. Deploy a Sample Workload to AWS: Deploy a sample WordPress app to AWS. This guide includes several dependency management features that illustrate the usefulness of Threeport.</p> </li> </ol>"},{"location":"managed-threeport/","title":"Managed Threeport","text":"<p>Threeport itself is a complex distributed software system that is trivial to use and deploy for testing or development, but non-trivial to manage, upgrade, maintain and troubleshoot when problems arise.</p>"},{"location":"managed-threeport/#commercial-service-offerings","title":"Commercial Service Offerings","text":"<ul> <li>Qleet is currently the only service provider that offers   fully managed Threeport control planes.  The originators, developers and   maintainers of the Threeport project are on the engineering team at Qleet.   It's free to get started.</li> </ul> <p>If your company launches a managed Threeport service and wishes to be listed here, open a PR on the user-docs repo.</p>"},{"location":"architecture/control-plane/","title":"Control Plane","text":"<p>This document provides a description of the technologies and open source projects used in Threeport.</p> <p>This document includes a description each component of the Threeport control plane, including the technologies and open source projects in use.</p>"},{"location":"architecture/control-plane/#restful-api","title":"RESTful API","text":"<p>The Threeport API is the heart of the control plane.  All clients and control plane components coordinate their activity and store persistent data through the API.</p> <p>The API is written with the Go programming language.  We chose Go because of its portability, efficiency, built-in concurrency, standard library and ecosystem of 3rd party libraries.  It has become the default programming language for cloud native systems and has been used extensively in open source projects like Docker and Kubernetes.</p> <p>We use the Echo framework because it has useful, performant routing and middleware, is easily extensible and does not contain excessive, obstructive features.</p>"},{"location":"architecture/control-plane/#api-database","title":"API Database","text":"<p>The Threeport API uses CockroachDB for data persistence.  We chose to use a SQL database in general for its transactional and relational capabilities.  We chose CockroachDB in particular for its distributed capabilities.  Threeport offers a global control plane so resilience is a primary concern.  We found CockroachDB to be the best implementation of a distributed SQL database.</p>"},{"location":"architecture/control-plane/#notification-broker","title":"Notification Broker","text":"<p>The horizontal scalability of Threeport controllers is enabled by the NATS messaging system.  The API uses the NATS server to notify controllers of changes in the system.  The controllers use NATS to re-queue reconciliation as needed (when unmet conditions prevent immediate reconciliation) and to place distributed locks on particular objects during reconciliation.</p>"},{"location":"architecture/control-plane/#threeport-agent","title":"Threeport Agent","text":"<p>The Threeport agent is a Kubernetes operator built using the Kubebuilder SDK.  It is informed about Threeport-managed workloads using a custom Kubernetes resource.  It then places watches on those resources and collects Events in Kubernetes to report back status on those workloads to the Threeport API.</p> <p>You can find more information about the Threeport agent in the Threeport developer documentation.</p>"},{"location":"architecture/control-plane/#threeport-controllers","title":"Threeport Controllers","text":"<p>Threeport controllers provide the logic and state reconciliation for the control plane. They are written in Go and model some engineering principles from Kubernetes controllers. When a change is made to an object in the Threeport API, the relevant controller is notified so that it can reconcile the state of the system with the desired state configured for that object.</p> <p>The primary feature that differentiates Threeport controllers from those in Kubernetes is that Threeport controllers are horizontally scalable.  Threeport does not not use a watch mechanism the way Kubernetes does.  Instead we use a notification broker that allows notifications to be provided to only one of a set of identical controllers at a time.</p>"},{"location":"architecture/control-plane/#aws-controller","title":"AWS Controller","text":"<p>The AWS controller is responsible for managing the following managed services in AWS:</p> <ul> <li>Elastic Kubernetes Clusters (EKS): used for Kubernetes Runtime environments to   deploy user workloads.</li> <li>Relational Database Service (RDS): available as a dependency when used as a   part of an application stack.</li> <li>Simple Storage Service (S3): available as a dependency when used by an   application to store objects.</li> </ul> <p>We use a library called aws-builder that was developed for use by Threeport.  It uses the v2 SDK for the Go programming language to manage AWS resources.  We do not use any intermediate toolchains or libraries such as Pulumi, ACK, Crossplane or Terraform. These are capable tools for certain use cases.  However, using the AWS SDK directly gives us the most flexibility and ensures we don't encounter any unsupported operations we might need to perform in managing cloud resources for Threeport users.  It also serves as a reference implementation for platform engineers that extend Threeport and wish to use a similar approach.</p>"},{"location":"architecture/control-plane/#control-plane-controller","title":"Control Plane Controller","text":"<p>The control plane controller allows users of Threeport to deploy new Threeport control planes using Threeport itself.  This is available so that large organization that wish to clearly separate concerns between lines of business can do so in a Threeport-native way without the need to use <code>tptctl</code> to bootstrap new control planes when needed.  It also allows separation of tiers, e.g. development and production if desired.  However, we don't recommend this approach for most users unless they have a compelling need for it.</p>"},{"location":"architecture/control-plane/#gateway-controller","title":"Gateway Controller","text":"<p>The gateway controller manages network ingress support services when a workload has such a dependency.</p> <p>The following support services are installed on Kubernetes as needed by the Gateway controller:</p> <ul> <li>Gloo Edge: the network ingress controller used by Threeport.</li> <li>cert-manager: used to provision and rotate TLS certificates.</li> <li>external-dns: manages DNS records created for workloads.</li> </ul> <p>When a support service controller needs to be installed in Kubernetes, we use the support-services-operator to perform the install.  The Kubernetes manifest provided to the Workload is actually a custom resource that is managed by the support-services-operator.  It installs the support services listed above in this manner.</p> <p>In addition to the support services installations on Kubernetes, the gateway controller appends Kubernetes resources to those defined by the user with the Workload resource to configure the support service for that workload.</p>"},{"location":"architecture/control-plane/#helm-workload-controller","title":"Helm Workload Controller","text":"<p>The Helm workload controller uses the popular Kubernetes package manager, Helm to deploy workloads in Kubernetes.  Helm templates have drawbacks in complex environments since templating is inherently inferior to general purpose programming languages.  More on this topic is discussed in the Continuous Delivery &amp; GitOps section of the Application Orchestration document.  We prefer Go programs to construct Kubernetes resources.  However, Helm support is still valuable because many open-source charts are available and it is already in extensive use by many teams.</p> <p>Although we prefer Go to manage Kubernetes resources, we recognize there are use-cases where it is more appropriate to use Helm. Threeport's implementation of the Observability Stack is one example.  The requirements for observability line up well with what is already provided by open-source Helm charts, so it made more sense to implement this controller with Threeport's Helm integration.</p>"},{"location":"architecture/control-plane/#kubernetes-runtime-controller","title":"Kubernetes Runtime Controller","text":"<p>The Kubernetes runtime controller is used to provision new Kubernetes environments for workloads.  It serves as a cloud provider agnostic abstraction that allows a user to provision environments with the cloud provider as a simple attribute of the <code>KubernetesRuntimeDefinition</code> object.  The <code>KubernetesRuntimeInstance</code> object is where connection information for each cluster is stored and utilized when workloads are deployed to that cluster.</p>"},{"location":"architecture/control-plane/#observability-controller","title":"Observability Controller","text":"<p>The observability controller is responsible for deploying observability stacks when a Threeport user wishes to have access to metrics and logs from their workloads.</p> <p>The following components are available to deploy as a part of the stack:</p> <ul> <li>Prometheus: the metrics   collection system.</li> <li>Promtail: log   forwarding from individual machines to the log storage back end.</li> <li>Loki: log storage.</li> <li>Grafana: observability dashboard.</li> </ul> <p>The observability controller leverages the Helm workload controller to install Helm charts to deploy each of these components.</p>"},{"location":"architecture/control-plane/#secrets-controller","title":"Secrets Controller","text":"<p>The secrets controller is responsible for storing sensitive information in a secret storage system.  Currently, the only supported managed service for this is AWS Secret Manager.  The secret manager leverages the external-secrets project.  This support service is also installed by the support-services-operator when needed.  This allows Threeport to expose secrets to running apps as needed by users.</p> <p>Note: when storing secrets using Threeport, the value of the secret is never stored in the Threeport database.  The notifications that contain the secret value are never written to disk by NATS and are encrypted in transit.</p>"},{"location":"architecture/control-plane/#terraform-controller","title":"Terraform Controller","text":"<p>The Terraform controller uses Terraform to provision custom infrastructure needed by workloads.  Terraform is less than ideal for provisioning infrastructure in a control plane like Threeport for reasons discussed elsewhere but it is offered in Threeport for two reasons.  Many teams have made extensive use of Terraform and this allows them to use those configs in Threeport.  Also, Threeport offers native support for only a small number of AWS managed services and Terraform offers support for a much larger number of those resources.  Using Terraform for simpler use cases can be useful compared to the alternative of developing a custom Threeport extension to manage those same AWS resources.</p> <p>Note: Terraform is only supported for managing AWS resource at this time.</p>"},{"location":"architecture/control-plane/#workload-controller","title":"Workload Controller","text":"<p>The workload controller deploys a defined set of Kubernetes resources to a nominated (or default) Kubernetes runtime instance.  This controller is quite rudimentary in that the user is required to define the granular detail of all Kubernetes resources that constitute their workload.  However, it is useful in simple implementations.  When paired with a Kubernetes operator or a custom Threeport controller that abstracts the details of the Kubernetes resources, it is a vital mechanism.  It is the primary interface with the Kubernetes API in Threeport.</p>"},{"location":"architecture/control-plane/#next-steps","title":"Next Steps","text":"<p>For a more depth of understanding in how Threeport controllers work, see our Threeport Controllers architecture documentation.</p>"},{"location":"architecture/kubernetes-federation/","title":"Kubernetes Federation","text":"<p>This document describes the Threeport approach to managing a fleet of Kubernetes clusters.</p> <p>There have been many attempts at federating Kubernetes using Kubernetes itself, i.e. Kubernetes operators that install and keep an inventory of clusters as well as manage multi-cluster app deployments.  Kubernetes was designed to be a data center-level abstraction and it performs this function very well.  It was not designed to be a global software fleet abstraction and it has inherent scaling and availability constraints that prevent it from providing the ideal solution to this concern.</p> <p>A global federation layer must be highly scalable and have geo-redundant availability.  A control plane for all your software deployments must have the appropriate capacity and resilience for the task.</p>"},{"location":"architecture/kubernetes-federation/#kubernetes-controllers","title":"Kubernetes Controllers","text":"<p>Kubernetes controllers are not horizontally scalable.  When deployed in a highly available configuration, only one controller is active at any given time and they use leader election to determine which of a set of identical controllers manage operations at any given time.  In many use-cases, many thousands of clusters must be managed coherently, not to mention the software in those clusters.  This is a tremendous amount of state reconciliation to be performed by a single controller that does not share load across multiple instances.</p>"},{"location":"architecture/kubernetes-federation/#kubernetes-data-store","title":"Kubernetes Data Store","text":"<p>Kubernetes uses etcd which is an excellent distributed key-value store.  It has served Kubernetes very well in its purpose.  However, etcd works best in a single region.  Tuning for the increased latency of cross-region etcd clusters is possible, but treacherous.  Furthermore, it is not a relational database which means if you need transactional capabilities that allow a database to make changes to multiple objects with ACID guarantees, etcd is not the best choice.</p> <p></p>"},{"location":"architecture/kubernetes-federation/#threeport-controllers","title":"Threeport Controllers","text":"<p>Threeport controllers inherit a lot of design principles from Kubernetes.  They are level-triggered state reconciliation programs that operate on a non-terminating loop until the desired state is realized in the system.  One thing that Threeport controllers add is horizontal scalability.  Any number of Threeport Controllers can operate simultaneously to manage the same set of object types. They use NATS Jetstream to broker notifications to help achieve this.  In Threeport, the message broker helps ensure a notification of a particular change is delivered to just one of a set of identical Threeport controllers.  Threeport controllers also use the message broker to place distributed locks on specific objects while they are being reconciled so that race conditions don't occur between different replicas of a controller when rapid changes are made to a particular object.</p>"},{"location":"architecture/kubernetes-federation/#threeport-data-store","title":"Threeport Data Store","text":"<p>Threeport uses CockroachDB, a purpose-built geo-redundant relational database.  The geo-redundancy is essential for a purpose as critical as a global control plane.  And the transactional capabilities allow changes to multiple related objects to happen safely.  When you are dealing with remote clusters and the workloads therein, changes that affect multiple objects are common.  Being able to apply a change to all the affected objects or none at all if a problem occurs, is an important guarantee to have for stability.</p> <p></p>"},{"location":"architecture/threeport-controllers/","title":"Threeport Controllers","text":"<p>Threeport controllers perform state reconciliation in the system.  When a user deploys a workload, a change is made to the data store through the Threeport RESTful API.  Once that change has been successfully persisted, the API notifies the appropriate controller via the notification broker.  The Threeport controller responsible for deploying the workload then executes the action and updates the status of the object in the API.</p> <p>The following diagram illustrates this process for the workload controller as an example.</p> <p></p> <ol> <li>A developer requests a workload by sending a request to the API, usually    using the CLI tool <code>tptctl</code>.</li> <li>The API validates the request and then stores the workload objects'    configuration values in the database.</li> <li>Once persisted, the API notifies the message broker of the change, including    the database ID of the objects in question.</li> <li>The message broker delivers the notification to the correct Threeport    controller.  If no Threeport controller is available immediately due to load    or temporary outage, the NATS Jetstream broker holds the message until a    Threeport controller instance becomes available.</li> <li>The Threeport controller puts a lock on the specific object by type and    unique ID.  That way if another change is made to the same object before    reconciliation is complete, the first change is completed and then the second    change is executed so that race conditions don't develop.  In the event that    a reconciliation cannot be completed, such as when a lock exists on a    particular object, the notification is re-queued through the broker so that it    is performed at a later time.</li> <li>Reconciliation is completed.  In this case, the workload is deployed by    calling the Kubernetes API of the target cluster for the workload.</li> <li>Once the operation is successfully reconciled, the Workload controller    updates the status of the object through the API.</li> <li>Finally, the Threeport controller releases the lock on the object instance so    that it may undergo any future reconciliation.</li> </ol>"},{"location":"architecture/threeport-controllers/#reconcilers","title":"Reconcilers","text":"<p>To drill into a little more detail, a Threeport controller internally consists of one or more reconcilers.  Each reconciler is responsible for the state of a single object type.  To continue the example above, two objects were created by the developer.  A WorkloadDefinition and a WorkloadInstance.  The Workload controller has a distinct reconciler for each object.</p> <p></p> <p>Note: this illustration does not include an exhaustive list of reconcilers in the Workload Controller.  It is just a representation of the components involved in the example from above.</p> <p>The blue arrows illustrate the notifications that are sent to the reconcilers when a change occurs in the system.</p> <p>The orange arrows represent the communication from the reconcilers to the message broker.  They first check to see if a lock exists on a particular object before reconciling.  If no lock is found, they place a lock and reconcile.  If a lock is found, they re-queue the notification - usually after some short period - so that reconciliation can occur at a later time if needed.  Once reconciliation is complete, the lock is released.</p> <p>The green arrows show the calls from the reconcilers to the Kubernetes API in the Compute Space.  The Kubernetes API provides the primary interface point for the reconcilers to the compute space.  No calls are made into processes or workloads in those clusters as a rule.  Any custom operations that are not satisfied by Kubernetes are achieved with custom Kubernetes operators that can be configured and triggered through the Kubernetes API.</p> <p>The purple arrows show the calls back to the API to update other related objects or write the status of the object reconciled.</p>"},{"location":"architecture/threeport-core/","title":"Threeport Core","text":"<p>The Threeport Core is a distributed software system that serves as a software delivery platform.  It provices a unified, global control plane for all cloud infrastructure, compute environments and the applications that run there.</p> <p>Users interface with the Threeport RESTful API in the control plane. In response to user requests, Threeport interfaces with infrastructure, managed service provider and Kubernetes APIs on the user's behalf.  It orchestrates the delivery of software with all of its dependencies.  Those dependencies encompass everything from the cloud infrastructure up to the services needed for the application to run successfully.</p> <p></p>"},{"location":"architecture/threeport-core/#requirements","title":"Requirements","text":"<p>The following outline the primary requirements used to develop Threeport Core.</p> <ul> <li>Scalable: All components of Threeport Core are designed to scale to meet the global needs of an organization's software delivery.  The API, and all controllers are horizontally scalable.</li> <li>Resilient: Threeport Core is designed to be installed across multiple regions to remain functional in the event of a regional outage.</li> <li>Extensible: Threeport Core is extensible via modules so that all common and specialized requirements can be accommodated in a single, coherent system.</li> </ul>"},{"location":"architecture/threeport-core/#foundational-principles","title":"Foundational Principles","text":"<p>Threeport is designed and built upon the following principles:</p> <ul> <li>General purpose programming languages like Go are superior to DSLs and   templates for defining the behavior of complex systems.</li> <li>Git repos are not great for storing the configuration of complex systems.  For   a system that is driven by software controllers, a database is more efficient   for both reads and writes by those controllers.</li> <li>Use progressive disclosure in the abstractions available to users.  Dead   simple use cases should be trivial to configure and execute.  However, complex   use cases should be supported by allowing users greater level of   configurability in the underlying systems when needed.</li> </ul>"},{"location":"architecture/threeport-core/#control-plane","title":"Control Plane","text":"<p>The diagram below illustrates the Threeport control plane in a little more detail.  The control plane consists primarily of:</p> <ul> <li>A RESTful API</li> <li>A relational database: CockroachDB</li> <li>A controller notification broker: NATS Jetstream</li> <li>A number of controllers that each manage a specific domain of concerns and   reconcile state for specific objects in the system, such as Workloads,   KubernetesRuntimes and support services such as Gateways and DomainNames.</li> <li>An agent that runs in the Kubernetes environments to report back on the status   of workloads running there.</li> </ul> <p>Note: the controllers in the diagram below are just abstract examples.  For a complete list of the actual controllers in the Threeport control plane, see the Control Plane architecture docs.</p> <p></p> <p>This diagram illustrates the following process:</p> <ol> <li>The Threeport user sends a request to the Threeport API.  This is usually    done with the Threeport CLI, <code>tptctl</code> but can be made by anything that can    make a call to a RESTful API.  This request might be for a new Kubernetes    environment or for an application deployment into that environment.</li> <li>A request handler in the Threeport API persists the desired state from the    user in the Threeport database which is CockroachDB.  Once the desired state    is persisted, the request handler sends a notification to the appropriate    controller/s through NATS Jetstream.</li> <li>If the request requires some compute infrastructure and/or managed services,    the controller responsible for infrastructure services connects to the cloud    provider API to manage that.</li> <li>If the requests requires the deployment of a tenant workload, the    controller responsible for workloads connects to the Kubernetes API to    instruct its control plane to deploy the containerized workloads.</li> <li>If the workload dependencies require a support service to be installed on    Kubernetes, the controller responsible for support services will create new    Workload objects in the Threeport API which, in turn, prompts the controller    for workloads to connect to Kubernetes to install and configure the support    services for that workload.</li> </ol> <p>If a controller cannot complete its work immediately because of some long-running process or missing dependency that is being satisfied elsewhere, it will request a re-queue of the notification after a specified delay so that it can retry.  This process repeats until the desired state is reconciled.  At this point, the controller acknowledges the notification as complete.</p> <p>Each controller writes back any relevant updates to the Threeport API.</p> <p>The Threeport Agent which runs in the compute space environment watches the resources deployed by Threeport and reports back statuses to the Threeport API.</p> <p>The end result is the tenant workload running in the Kubernetes runtime environment with all of its dependencies satisfied.</p> <p>Note: The Threeport controllers never directly interact with each other. Whenever a controller needs work completed by another controller, it makes calls to the Threeport API to persist that change in the DB. The Threeport API then notifies the appropriate controller that its respective state needs to be reconciled.</p> <p>See the Control Plane document for more detailed information about the control plane.</p>"},{"location":"architecture/threeport-core/#compute-space","title":"Compute Space","text":"<p>The compute space is simply the compute environments where the user's applications run.  Threeport is a natively multi-cluster orchestrator so the compute space includes all the Kubernetes clusters hosting workloads. Any number of environments in any region on any supported cloud provider can be managed be a part of the compute space and managed with a single Threeport control plane.</p> <p>Note: Today, AWS is the only supported cloud provider and Kubernetes is the only supported runtime.  However, we plan to add additional providers and runtimes in the future.</p> <p></p>"},{"location":"architecture/threeport-core/#bootstrapping-threeport","title":"Bootstrapping Threeport","text":"<p>Threeport itself runs on Kubernetes.  As such, Threeport needs a bootstrapping mechanism to create the environment for the Threeport control plane.</p> <p>The Threeport CLI, <code>tptctl</code> provides that bootstrapping.</p> <p>See the tptctl install guide for a guide on installing the <code>tptctl</code> command line tool.</p> <p>See the Remote Threeport guide for a walk through on installing Threeport in AWS using <code>tptctl</code>.</p> <p></p> <p>The <code>tptctl up</code> command executes the following steps when installing on AWS:</p> <ol> <li>The user's local AWS config and credentials are referenced to call the AWS    API and install Kubernetes using the EKS service.</li> <li>Once the Kubernetes cluster is available, the Kubernetes API is called to    install the Threeport control plane components.</li> <li>Once the Threeport control plane is up, the Threeport API is called to    register the provisioned Kubernetes environment with the system so that it    may be used as a part of the compute space for tenant workloads if desired.</li> <li>Finally, the user's local Threeport config is updated with connection details    and credentials so the user can securely connect to the Threeport API with    <code>tptctl</code> to manage their applications.</li> </ol> <p>A Threeport control plane can also be installed locally on a user's workstation using kind for local testing and development. See our Local Threeport guide for instructions on installing Threeport locally.  With a local Threeport control plane, the user can then deploy Kubernetes clusters in the cloud and deploy workloads there.  However, this is only recommended for testing and development.  Don't use local Threeport control planes to run important production workloads.</p>"},{"location":"architecture/threeport-core/#next-steps","title":"Next Steps","text":"<p>See our Control Plane document for more architectural detail on the Threeport control plane and the Threeport Controllers document for information about how Threeport controllers work.</p>"},{"location":"aws/advanced-aws-setup/","title":"Advanced AWS Setup","text":"<p>Use this documentation to configure Threeport to manage resources in an AWS account that is separate from the account Threeport is deployed in.</p> <p>If using the same AWS account for Threeport and the workloads it will manage, follow the directions in the Basic AWS Setup guide</p>"},{"location":"aws/advanced-aws-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>An instance of the Threeport API: Follow the getting started guide to set one up if you have not already done so. Note that EKS clusters are currently the only supported type of control plane instance that can authenticate to an external AWS account.</p> </li> <li> <p>AWS CLI: The <code>aws</code> CLI tool must be installed and configured.</p> </li> </ul>"},{"location":"aws/advanced-aws-setup/#configure-aws-account","title":"Configure AWS Account","text":"<p><code>tptctl config aws-account</code> configures AWS cross-account permissions. It creates an <code>AwsAccount</code> object in the Threeport API and also configures the respective externally-managed AWS account.</p> <p></p> <p>To run this command, the following flags must be provided:</p> <ul> <li><code>--aws-account-name</code> - name of the AWS account that is being stored in the Threeport API</li> <li><code>--aws-region</code> - the default AWS region that Threeport will manage resources in</li> <li><code>--aws-profile</code> - the local AWS profile that will be used to authenticate to AWS</li> <li><code>--aws-account-id</code> - the external AWS account to grant access to.</li> </ul> <p>Here is an example of the complete command.  This command configures permissions for the Threeport control plane in AWS Account #1 from the diagram above to manage resources in AWS Account #2.</p> <pre><code>tptctl config aws-account \\\n--aws-account-name my-account \\\n--aws-region us-east-1 \\\n--aws-profile my-profile \\\n--aws-account-id 111111111\n</code></pre> <p>Upon completion of the above command, you will be able to create Kubernetes runtime instances in an external AWS account.</p>"},{"location":"aws/aws-iam/","title":"AWS Permissions","text":"<p>Before standing up a Threeport control plane in AWS using the <code>eks</code> provider, ensure you have the required IAM permissions set for your AWS user.</p> <p>To install Threeport using <code>tptctl up</code>, an AWS user first creates a new \"resource-manager\" role and two policies for that role.  The AWS user then assumes that role in order to create and operate Threeport.  Therefore an AWS user needs the following permissions to install and manage Threeport:</p> <ul> <li>Create and manage IAM roles</li> <li>Create and manage IAM permissions</li> <li>Assume that role for installing Threeport</li> </ul> <p></p> <p>If you don't have those permissions, you will need someone else on your AWS account to grant you that access.  The following instructions are for that user on AWS to grant access to another user to manage Threeport installations.</p>"},{"location":"aws/aws-iam/#threeport-resource-manager-permissions","title":"Threeport Resource Manager Permissions","text":"<p>To see the permissions available to the resource-manager role that manages Threeport, see the AssumeAnyRolePolicyDocument and ResourceManagerPolicyDocument in the Threeport source code.</p>"},{"location":"aws/aws-iam/#prerequisites","title":"Prerequisites","text":"<p>The instructions below require:</p> <ul> <li>The AWS CLI installed and configured to access   your account.</li> <li>The jq command line json parsing tool.</li> </ul>"},{"location":"aws/aws-iam/#set-environment-variables","title":"Set Environment Variables","text":"<p>Following are the values we will need to set up access for another user to manage Threeport.</p> <p>Set the user name for the user being granted access to manage Threeport:</p> <pre><code>export THREEPORT_ADMIN_USER_NAME=&lt;aws user name&gt;\n</code></pre> <p>Set your AWS account ID:</p> <pre><code>export AWS_ACCOUNT_ID=&lt;aws account id&gt;\n</code></pre> <p>Set the names of the group and policy for Threeport admins.  These are arbitrary and can be changed:</p> <pre><code>export THREEPORT_ADMIN_POLICY_NAME=ThreeportAdmin\nexport THREEPORT_ADMIN_GROUP_NAME=threeport-admin\n</code></pre>"},{"location":"aws/aws-iam/#create-a-threeport-admin-policy","title":"Create a Threeport Admin Policy","text":"<p>The following command will generate the policy document for your ThreeportAdmin users and write it to your working directory.</p> <pre><code>cat &lt;&lt;EOF &gt; threeport-admin-iam-policy.json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AssumeAnyThreeportResourceManager\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"sts:AssumeRole\",\n            \"Resource\": \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/resource-manager-threeport-*\"\n        },\n        {\n            \"Sid\": \"CreateRolePermissions\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:CreatePolicy\",\n                \"iam:DeletePolicy\",\n                \"iam:ListPolicies\",\n                \"iam:CreatePolicyVersion\",\n                \"iam:DeletePolicyVersion\",\n                \"iam:SetDefaultPolicyVersion\",\n                \"iam:GetRole\",\n                \"iam:CreateRole\",\n                \"iam:DeleteRole\",\n                \"iam:UpdateRole\",\n                \"iam:PutRolePolicy\",\n                \"iam:DeleteRolePolicy\",\n                \"iam:AttachRolePolicy\",\n                \"iam:DetachRolePolicy\",\n                \"iam:TagRole\",\n                \"iam:UntagRole\",\n                \"iam:ListAttachedRolePolicies\",\n                \"iam:TagPolicy\",\n                \"iam:UpdateAssumeRolePolicy\"\n            ],\n            \"Resource\": [\n                \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/resource-manager-threeport-*\",\n                \"arn:aws:iam::${AWS_ACCOUNT_ID}:policy/resource-manager-threeport-*\"\n            ]\n        }\n    ]\n}\nEOF\n</code></pre> <p>Create the policy in AWS and capture the policy ARN:</p> <pre><code>export THREEPORT_ADMIN_POLICY_ARN=$(\\\n    aws iam create-policy \\\n        --policy-name $THREEPORT_ADMIN_POLICY_NAME \\\n        --policy-document file://threeport-admin-iam-policy.json \\\n        --description \"Create Threeport resource manager role and policy, allow assumption of the resource manager role\" \\\n    | jq -r '.Policy.Arn')\n</code></pre>"},{"location":"aws/aws-iam/#create-a-user-group","title":"Create a User Group","text":"<p>Create a group for managing Threeport instances:</p> <pre><code>aws iam create-group \\\n    --group-name $THREEPORT_ADMIN_GROUP_NAME\n</code></pre>"},{"location":"aws/aws-iam/#attach-policy-to-user-group","title":"Attach Policy to User Group","text":"<pre><code>aws iam attach-group-policy \\\n    --group-name $THREEPORT_ADMIN_GROUP_NAME \\\n    --policy-arn $THREEPORT_ADMIN_POLICY_ARN\n</code></pre>"},{"location":"aws/aws-iam/#add-threeport-admin-user-to-the-user-group","title":"Add Threeport Admin User to the User Group","text":"<pre><code>aws iam add-user-to-group \\\n    --group-name $THREEPORT_ADMIN_GROUP_NAME \\\n    --user-name $THREEPORT_ADMIN_USER_NAME\n</code></pre> <p>You can now add more users to that group if need be:</p> <pre><code>export THREEPORT_ADMIN_USER_NAME=&lt;another aws user name&gt;\naws iam add-user-to-group \\\n    --group-name $THREEPORT_ADMIN_GROUP_NAME \\\n    --user-name $THREEPORT_ADMIN_USER_NAME\n</code></pre>"},{"location":"aws/aws-iam/#clean-up","title":"Clean Up","text":"<p>Remove the Threeport admin policy document file:</p> <pre><code>rm threeport-admin-iam-policy.json\n</code></pre>"},{"location":"aws/aws-intro/","title":"AWS","text":"<p>Amazon Web Services (AWS) is currently the only supported cloud provider on Threeport.</p> <p>The following services can be managed with Threeport objects:</p> <ul> <li>Elastic Kubernetes Service (EKS) for Kubernetes Runtimes.</li> <li>Relational Database Service (RDS) for managed databases as an application   dependency.</li> <li>Simple Storage Service (S3) for object storage buckets as an application   dependency.</li> </ul> <p>There are many other AWS resources that are managed by Threeport to deliver these services.  VPCs, subnets, elastic load balancers are all managed in service of the supported services on Threeport, but Threeport users need not configure or provision these separately.</p>"},{"location":"aws/aws-intro/#aws-account","title":"AWS Account","text":"<p>An AWS Account object allows you to register AWS account information with Threeport so that it can be used to deploy runtimes, workloads and managed services in that account.  A genesis Threeport control plane deployed to AWS will utilize AWS best-practice IRSA authentication to manage resources within its own AWS account.  To give Threeport access to other AWS accounts, you must include an AWS account ID, access key ID, and secret access key credentials to authenticate. If you have your local AWS config set up to use the <code>aws</code> CLI tool you can reference those credentials stored on your local file system when creating an external AWS account.</p> <p>You can register and use as many AWS accounts in Threeport as you wish.</p> <p>Reference: AwsAccount</p>"},{"location":"aws/aws-intro/#aws-eks-kubernetes-runtime-definition","title":"AWS EKS Kubernetes Runtime Definition","text":"<p>This object allows you to configure an AWS EKS cluster directly.  We recommend using the <code>KubernetesRuntimeDefinition</code> object with the <code>InfraProvider</code> field set to <code>eks</code> to provision EKS clusters.  However, if there is a specific EC2 instance type that you'd like to use that isn't offered through the Threeport NodeProfile and NodeSize abstractions, you can directly provision EKS clusters using this object.</p> <p>When you create one of these objects, Threeport will create a corresponding Kubernetes Runtime Definition so that it can be referenced by the system as needed.</p> <p>Reference: AwsEksKubernetesRuntimeDefinition</p>"},{"location":"aws/aws-intro/#aws-eks-kubernetes-runtime-instance","title":"AWS EKS Kubernetes Runtime Instance","text":"<p>This object allows you to provision an instance from the config in a definition. Similar to the definition, we recommend using the <code>KubernetesRuntimeInstance</code> to provision EKS clusters in AWS.  However, if you need to specify a region not offered through the Threeport Location abstraction, you can use this object.</p> <p>When you create one of these objects, Threeport will create a corresponding Kubernetes Runtime Instance so that it can be referenced by the system as needed.  This Kubernetes Runtime Instance contains the connection information for the Kubernetes API that is used by the workload controller to deploy resources.</p> <p>Reference: AwsEksKubernetesRuntimeInstance</p>"},{"location":"aws/aws-intro/#aws-relational-database-definition","title":"AWS Relational Database Definition","text":"<p>This object allows you to define an RDS instance configuration.  You can specify the engine (one of <code>mysql</code>, <code>postgres</code> or <code>mariadb</code>) and the version of that engine.  You can also specify the name of the database the client workload will connect to, the port, the machine size to use for the database, the amount of storage to provision as well as the number of days to retain database backups. If you specify <code>0</code> for the <code>BackupDays</code> field, no backups will be kept.  You can also specify the AWS account to use for the database.</p> <p>The field that is important to connecting it to the client workload is the <code>WorkloadSecretName</code> field.  This field tells Threeport what name to give to the Kubernetes secret that will provide the database connection credentials to the workload connecting to the database.  Threeport will create a Kubernetes secret with the following keys:</p> <ul> <li><code>db-endpoint</code>: The network endpoint at which the RDS instance is available.</li> <li><code>db-port</code>: The port the client workload can connect to the database on.</li> <li><code>db-name</code>: The name of the database the client workload will use.</li> <li><code>db-user</code>: The database user name the client workload uses to authenticate.</li> <li><code>db-password</code>: The client workload's user password to authenticate to the DB.</li> </ul> <p>When constructing the Kubernetes resource manifest for the workload, configure your pods to retrieve these values from the specified secret as an environment variable.  If you're not sure how to do this, see our Deploy Workload on AWS guide for a detailed walk through of an app on Kubernetes using an RDS database.</p> <p>Reference: AwsRelationalDatabaseDefinition</p>"},{"location":"aws/aws-intro/#aws-relational-database-instance","title":"AWS Relational Database Instance","text":"<p>This object represents a deployed instance of RDS as configured by the definition.  This object connects the instance to the Workload that will use the DB.</p> <p>Reference: AwsRelationalDatabaseInstance</p>"},{"location":"aws/aws-intro/#aws-object-storage-bucket-definition","title":"AWS Object Storage Bucket Definition","text":"<p>This object allows you to configure an S3 bucket for use by an application.  You can nominate whether the bucket should have public read access or not.  Public read access is useful for serving static assets for a web front end.  Otherwise, if the data to be stored on S3 is private, you will not want public read access (which is the default).</p> <p>You also need to provide a value for the <code>WorkloadServiceAccountName</code> field. Threeport uses IAM Roles for Service Accounts (IRSA) to provide access to the S3 bucket for your workload.  This means you'll need to include a Kubernetes Service Account with a matching name in the Kubernetes manifests in the WorkloadDefinition for your workload that will use S3.  If you're unsure how to do this see our Deploy Workload on AWS guide for a detailed walk through of an app on Kubernetes that also uses S3.</p> <p>Lastly, you'll need to provide the environment variable your workload will use to reference the name of the S3 bucket.  This environment variable will be added to your workload by Threeport.  Your app just needs to know what env var to reference.</p> <p>Reference: AwsObjectStorageBucketDefinition</p>"},{"location":"aws/aws-intro/#aws-object-storage-bucket-instance","title":"AWS Object Storage Bucket Instance","text":"<p>This is a deployed instance of S3 that connects it to a WorkloadInstance object.</p> <p>Reference: AwsObjectStorageBucketInstance</p>"},{"location":"aws/aws-intro/#next-steps","title":"Next Steps","text":"<p>Check out our Deploy Workload on AWS guide see an example of how to deploy a workload that is connected to an RDS database and S3 bucket.</p>"},{"location":"aws/basic-aws-setup/","title":"Basic AWS Setup","text":"<p>Use this documentation to configure Threeport to manage resources within the same AWS account.  If you need to manage workloads in a different AWS account from the one Threeport is deployed in, follow the Advanced AWS Setup guide</p> <p>To get started, construct a config with the required fields. Here is an example of what this config looks like:</p> <pre><code>AwsAccount:\n  Name: default-account\n  AccountID: \"555555555555\"\n  DefaultAccount: true\n\n  # option 1: provide explicit configs/credentials\n  #DefaultRegion: some-region\n  #AccessKeyID: \"ASDF\"\n  #SecretAccessKey: \"asdf\"\n\n  # option 2: use local AWS configs/credentials\n  LocalConfig: /path/to/local/.aws/config\n  LocalCredentials: /path/to/local/.aws/credentials\n  LocalProfile: default\n</code></pre> <p>Paste the following command to download <code>aws-account.yaml</code>. Open the file and update <code>AccountID</code>, <code>LocalConfig</code>, and <code>LocalCredentials</code> to the appropriate values for your environment.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/releases/main/samples/aws-account.yaml\n</code></pre> <p>Once <code>aws-account.yaml</code> is prepared, run the following command to create the <code>AwsAccount</code> object in the Threeport API: <pre><code>tptctl create aws-account --config aws-account.yaml\n</code></pre></p>"},{"location":"concepts/application-orchestration/","title":"Application Orchestration","text":"<p>Application orchestration is an approach to software delivery that favors software engineering over configuration management.  Similar to how user-facing applications are often designed, Threeport employs event-driven and service-oriented architecture to manage the deployment and ongoing management of applications.</p> <p>In order to clarify, let's compare two approaches:</p> <ol> <li>Configuration Management Approach:  This is commonly what is used today with DevOps platforms.</li> <li>Application Orchestration Approach: This is a software engineering approach to  the development of application platforms.</li> </ol>"},{"location":"concepts/application-orchestration/#configuration-management-approach","title":"Configuration Management Approach","text":"<p>Before \"cloud native\" systems we used tools like Ansible, Chef and Puppet to install apps on remote servers.  Because every tool has its limitations, we also developed Continuous Delivery (CD) pipelines to plumb together multiple steps using different tools. Infrastructure-as-Code became a buzz word that applied config management to cloud services.  As Docker and containerization became prevalent, we invented GitOps to implement config management principles to a new abstraction layer: Kubernetes.</p> <p>Config management deals in large part with data serialization languages, e.g. JSON and YAML to define the desired state of a system.  As systems become more complex, the configuration quickly becomes vast and infeasible to manage as static config assets.</p> <p>In order to bridge this gap we have used several different workarounds:</p> <ol> <li>Domain specific languages: HashiCorp Config Language (HCL) is a good example of this which introduces some control flow constructs to help manage complex configs.</li> <li>Templating systems: Helm is an example of a system that uses a templating language to produce large static configs.  Again control flow constructs are used to produce conditional and looping logic to manage vast configurations.</li> <li>Overlay systems: Kustomize is an example of an overlay system that takes a base configuration, then adds, removes or replace elements for different use cases.</li> </ol> <p>The problem with both DSLs, templates and overlays is that they manage logical constructs poorly when compared to general purpose programming languages.</p> <p>The end result of config management systems is a rapid deterioration of maintainability as complexity grows.  Because of their limitations, they become littered with workarounds, complex combinations and enormous text file configs that are very challenging for humans to manage.</p>"},{"location":"concepts/application-orchestration/#application-orchestration-approach","title":"Application Orchestration Approach","text":"<p>With Threeport, we use a software engineering approach to solving the challenge of software delivery.  Event-driven and service-oriented architectures are powerful and effective when executed well.  We are applying these principles to application platforms.</p> <p>One way to think about Threeport is that it is Ruby on Rails for application platforms.</p> <p>The table below helps illustrate the difference between the approaches.</p> Config Management Application Orchestration Team Sepciality DevOps Platform engineering Primary Focus Text configs, templates, pipelines Threeport modules (software service or controller) Skillset Tools like Helm, Terraform, Crossplane Software development Languages JSON, YAML, HCL, templating languages Programming languages, primarily Go Source of Truth Text files configs in Git Threeport database Tradeoff Easy to get started, doesn't scale well with complexity Requires software development, scales well with complexity Result Platform teams usually need to execute deployments and upgrades for dev teams Self-service app platform for dev teams to deploy and upgrade their apps"},{"location":"concepts/application-orchestration/#continuous-delivery-gitops","title":"Continuous Delivery &amp; GitOps","text":"<p>This section delves a little deeper into configuration management in its modern forms with CD and GitOps.</p> <p>CD and GitOps are primarily adaptations using CLI tools that humans use.  They were an improvement on run books used by system admins in days gone by, and they served us well for a time.  However, their shortcomings are glaring.</p> <p>Tools like Terraform, Helm and Kustomize are not natively interoperable.  They require vast text file configurations and do not handle logical constructs well. Hashicorp did its best to introduce conditionals and loops to Terraform.  The go templating used by Helm is similarly capable.  These methods are fine for early testing and development.  However, when complex production environments grow from those early POCs and MVPs, these config languages and templating systems fall short.  Any web developer will tell you that logic should be kept out of the templates that render HTML as much as possible.  There's a good reason for this: templating languages are limited, difficult to maintain and much more challenging to write unit and end-to-end tests for.</p> <p>Below is a diagram that illustrates a pretty typical use of GitOps.</p> <p></p> <ol> <li>Ahead of time, the GitOps team builds the GitOps pipeline which generally    includes Helm templates and Kustomize overlays.  The pipeline itself also must    be configured.  A popular choice is ArgoCD and, in that case, the pipelines    are configured using their Kubernetes custom resources.</li> <li>The developer merges changes to their application which fires off a    continuous integration process to test and build their app.  The end result    is a container image pushed to a registry.</li> <li>The developer pushes a change to the config repo.  This would include an    update to the version of the container image they wish to deploy.  They would    usually apply that change to the branch or set of configs that correspond to    the environment they wish to deploy to.</li> <li>The GitOps pipeline is triggered by the change and runs the templating and    overlay operations to render complete Kubernetes manifests that are then    applied to the cluster.</li> </ol> <p>This GitOps workflow can work fine in simple use cases.  The problems arise as sophistication increases.  Helm templates often become overwhelmed with conditional and looping logic that is messy to express in templating languages. The additional complexity of multiple layers of configuration with Helm and Kustomize make it challenging just to figure out where values are being set. And since such pipelines are difficult to test before use, they tend to be brittle and interrupt day-to-day operations.</p> <p>This complexity is compounded when using multiple inter-dependent workloads in a microservices architecture.  The configuration to connect those components must be supplied as inputs to the pipeline, adding more config vars that apply in multiple places inside a maze of templates, overlays and configs.</p> <p>The complexity is increased further if there are controllers in your system that update resource configurations that have been defined in a config repo.  You then have to either tell your GitOps engine to ignore some changes or push those changes back into the code repo from your runtime environment.</p> <p>In summary, GitOps is OK early in early development.  However, it becomes entirely inelegant as complexity scales up - as it inevitably does when the realities of production hit and as requirements for your software accumulate.</p>"},{"location":"concepts/application-orchestration/#threeport","title":"Threeport","text":"<p>This section dives deeper into the approach taken with Threeport in juxtaposition with CD and GitOps.</p> <p>In contrast to config languages and templating languages, general purpose programming languages like Java, Python and Go are designed to manage complex logic elegantly.  Logic defined in these languages is maintainable and can have comprehensive automated testing applied to maintain reliability and backward compatibility.  They are great for writing APIs that enable further software interoperability.</p> <p>We chose Go to build Threeport.  It exposes a RESTful API that can be called through our CLI <code>tptctl</code> or by any application that can call an API over HTTP.  It stores state in a relational database and uses controllers to reconcile state for objects defined by users.</p> <p>You no longer have to manage thousands of lines of config in a git repo that triggers pipelines.  Threeport is an application that manages the delivery of your workloads.  It orchestrates all of your app's dependencies in a cloud native environment, all the way down to the infrastructure.</p> <p>Threeport manages software delivery in these distinctly different ways from pipeline-driven systems:</p> <ul> <li>The developers and DevOps team don't store their configs and templates in git.   We view git as an excellent tool for version control of source code for   applications, but not as a data store for system configuration.  Threeport   stores user-defined config in a database so that controllers in the system   can readily read those configs and update them with statuses and other information   collected at deploy and run time.</li> <li>Configs are not processed through a pipeline.  When configuration is added,   updated or removed, level-triggered controllers are notified of the change and   set about reconciling the user-defined state with the actual state of the   system.  They operate on a non-terminating loop until the desired state is   reached.</li> <li>Threeport enables the use of custom controllers to provide customized   functionality.  While Threeport supports the use of Helm and Terraform for   those that want to start with those methods, we encourage the use of the   Threeport SDK   to build controllers that understand each particular custom use   case.  These controllers can be maintained with unit tests and   end-to-end tests.  Rather than templates with placeholders, software uses objects with   variable substitution.  Values for those variables can be passed as parameters   into functions that and are naturally subject to more rigorous controls.</li> <li>Threeport is a natively multi-cluster system.  Many organizations use multiple   clusters across different tiers and environments.  This allows Threeport to   perform actions that take these clusters, tiers and environments as input   configurations.  Logic can be implemented for multi-cluster systems to enable   the orchestration of advanced disaster recovery, failovers, migrations and   multi-region applications in a coherent, reliable and scalable way.</li> </ul> <p>The following diagram illustrates software delivery using app orchestration with Threeport.</p> <p></p> <ol> <li>Ahead of time, the DevOps team sets up definitions and defaults for apps    and their dependencies.  These provide the guardrails and rules leveraged    by the developer to deploy instances.</li> <li>The developer merges changes that trigger a CI process using, for example,    GitHub Actions.  This typically runs automated tests and build processes.<ol> <li>The final build artifact is generally a container image that is pushed to an    image registry to become available to run in an environment.</li> </ol> </li> <li>The developer can now trigger a deployment of an instance of that    application.<ol> <li>In the near future, updates from GitHub Actions will be available.  This will change the image version to trigger automated updates when desired.</li> </ol> </li> <li>The Threeport control plane notifies a controller to perform a deployment or    update to the running containers and Kubernetes resources necessary to    achieve the desired state.  This enables future behavior to automate roll    outs in some tiers, e.g. dev, while ensuring that human operators can trigger    roll outs for more critical tiers like staging and production.</li> <li>Any deployments, updates and deletes are then conducted by the Threeport    controller by calling the relevant Kubernetes API running in the environment    being used.</li> </ol> <p>Subsequently, the developer and other team members can then retrieve status updates and operational data - including any errors - for the new deployment through the Threeport control plane.</p>"},{"location":"concepts/application-orchestration/#summary","title":"Summary","text":"<p>Application orchestration uses a control plane to execute application deployment and ongoing management.  It scales well with complex software systems that have many dependencies on infrastructure and other services.</p> <p>Cloud native systems were enabled by container orchestration with Kubernetes. It alleviated the need to use config management with tools like Ansible, Chef and Puppet because a control plane took responsibility for reconciling state across clusters of machines.  App orchestration removes the need to use config tools to define our applications and their dependencies because a control plane becomes responsible for stitching all these elements together to produce a running app.</p>"},{"location":"concepts/application-orchestration/#next-steps","title":"Next Steps","text":"<p>To get a practical understanding of how Threeport manages delivery, check out our Getting Started page which provides the steps to install Threeport and use it to deploy a sample application.</p>"},{"location":"concepts/comparisons/","title":"Comparisons","text":"<p>Following are some comparisons between Threeport and other projects and products.</p>"},{"location":"concepts/comparisons/#kubernetes-distributions","title":"Kubernetes Distributions","text":"<p>There are many vendors that provide installation of Kubernetes with various support services offered as optional installs on Kubernetes.  Some of them also offer GitOps systems that can be used to deploy workloads.</p> <p>The workflow when using a Kubernetes distribution is generally as follows:</p> <ol> <li>A platform team use the Kubernetes distro to install clusters and prepare    them for use.</li> <li>DevOps sets up CI/CD or GitOps pipelines to deploy into those clusters.</li> <li>Developers push changes to config repos that trigger delivery of workloads to    the clusters.  If any mishaps occur in the pipeline, DevOps is usually    consulted to troubleshoot.</li> </ol> <p>Threeport provides Kubernetes clusters as well, but it installs support services as they are needed by workloads.  And the clusters need not be provisioned by the platform team ahead of time.  They can be spun up on-demand by teams that need them.</p> <p>The core Threeport project does not support any particular vendor distro, but can be extended using the Threeport SDK to support any distro as the provider of Kubernetes clusters.  With Threeport, the workflow is different:</p> <ol> <li>The platform team installs the Threeport control plane.</li> <li>The DevOps team provides definitions and defaults for Kubernetes runtimes    and/or dependencies that can be used by dev teams.</li> <li>Developers provide workload configs with dependency declarations to    Threeport.  Threeport orchestrates the deployment of the application and its    dependencies.</li> </ol> <p>Threeport enables a true self-service experience for dev teams that provides efficiency and velocity not available when humans are on the critical delivery path for applications.</p>"},{"location":"concepts/comparisons/#cicd","title":"CI/CD","text":"<p>Continuous integration and continuous delivery are very different concerns.  The only reason these two operations are mashed into a single term is that pipeline systems like Jenkins were used to implement them.</p>"},{"location":"concepts/comparisons/#continuous-integration","title":"Continuous Integration","text":"<p>CI is concerned with automating the tests, security scans and builds for pieces of software.  Generally, when a pull request is opened to make changes to a codebase, these operations are run so that when code is merged a reliable artifact can be made available for delivery.  In cloud native systems, the final artifact is a container image that can be pulled to a runtime environment and deployed.</p> <p>There are many CI solutions, such as GitHub Actions that are commonly configured and managed by dev teams as a software development concern.</p> <p>Threeport is not involved in the continuous integration processes.</p>"},{"location":"concepts/comparisons/#continuous-delivery","title":"Continuous Delivery","text":"<p>CD uses similar version control triggers and pipeline-based mechanisms but has the distinct job of managing complex configurations for software to run in compute environments.  There are far more dynamic and complex concerns at play in delivery than there are in the well-understood domain of tests, scans and builds for a particular software project.</p> <p>GitOps is a more recent evolution of this concept that wrangles complex infrastructure and Kubernetes configuration for workloads.  Those configurations are managed by humans and stored in version control and leverage CLI tools to perform templating, overlays, and API calls to cloud provider and Kubernetes APIs to deliver apps to their runtime.  Due to their size and complexity, these configs usually live in their own distinct git repositories, separate from the app's source code.  This additional complexity and human involvement adds considerable overhead to dev teams and/or requires dedicated DevOps teams to manage.</p> <p>Threeport provides an alternative to continuous delivery systems.  It stores user-defined config in a database, rather than a git repo.  And it uses a purpose-built control plane to deliver software rather than a pipeline with a set of CLI tools that were designed for humans to use and are not natively interoperable.</p>"},{"location":"concepts/comparisons/#radius","title":"Radius","text":"<p>Radius helps teams manage cloud native application dependencies.</p> <p>Similarities:</p> <ul> <li>Both Threeport and Radius have a strong emphasis on providing developer   abstractions that allow workloads to be deployed with their dependencies,   such as managed services like AWS RDS and S3.  Radius' support for a wide   range of managed services is more mature than in Threeport.</li> <li>Both Threeport and Radius are fundamentally multi-cloud systems.  Threeport   only supports AWS today - but it is designed to have other cloud provider   support plugged in.  Radius offers support for AWS and Azure today.</li> <li>Both Threeport and Radius aim to provide a platform for collaboration between   developers and other IT operators.  Developers need ways to smoothly leverage   the expertise offered by other teams with minimal friction.</li> </ul> <p>Differences:</p> <ul> <li>Radius does not manage Kubernetes clusters.  To get started with Radius, you   must have a Kubernetes cluster.  In contrast, Threeport manages Kubernetes   clusters as runtime dependencies.</li> <li>Threeport manages support services that must be installed on Kubernetes as   application dependencies.  Examples include network ingress routing, TLS   termination and DNS management.  These common support services are installed   and configured for tenant applications by Threeport.  With Radius, support   services can be installed, but configuration of them is up to the user to   manage.</li> <li>Radius has a strong emphaisis on leveraging existing tools like Bicep, Helm   and Terraform and unifying them in a common platform.  Threeport supports Helm   and Terraform, but encourages migrating towards the use of programming   languages like Go to manage resource configuration.  The Threeport SDK (coming   soon) allows a smooth transition from DevOps tools to controllers for   accomplishing this.</li> </ul> <p>Radius and Threeport have very complimentary characteristics and could be combined well.</p>"},{"location":"concepts/comparisons/#crossplane","title":"Crossplane","text":"<p>Crossplane provides a framework for building customizations to the Kubernetes control plane.</p> <p>Similarities:</p> <ul> <li>Both Threeport and Crossplane facilitate building custom application   platforms.</li> <li>Threeport manages workload dependencies, such as managed services, as a   primary function.  Similar functionality can be built out with Crossplane.</li> </ul> <p>Differences:</p> <ul> <li>Crossplane aims to build custom Kubernetes control planes without needing to   write code.  This is achieved with compositions that define new APIs in YAML.   In contrast, platform engineers extend Threeport by writing code.  We believe   that languages like Go are a better choice for implementing sophisticated   software systems.  As such, we offer the Threeport SDK   that allows users to build their custom implementations with Go, rather than   with compositions defined in YAML.</li> <li>Crossplane is an extension of the Kubernetes control plane.  The Threeport control   plane is a distinct control plane with its own APIs.  The Threeport control   plane supports greater scalability and geo-redundancy than Kubernetes so as to   serve as a global control plane for all clusters under management.</li> </ul> <p>Crossplane and Threeport could be used in conjunction by using Threeport to provision and manage Kubernetes with Crossplane extensions.  However, there are a lot of overlapping concerns between the projects.  Building an application platform using both projects would introduce more complexity and unclear boundaries.</p>"},{"location":"concepts/comparisons/#argocd","title":"ArgoCD","text":"<p>Argo CD is a modern Kubernetes-native continuous delivery system.</p> <p>Similarities:</p> <ul> <li>Both ArgoCD and Threeport manage software delivery.</li> </ul> <p>Differences:</p> <ul> <li>ArgoCD supports various DevOps tools to be used in workflows to execute the   steps needed to deliver software.  Threeport instead uses software   controllers to manage software delivery.  With ArgoCD you can get a delivery   pipeline up and running pretty quickly.  The challenge is maintainability when   complexity increases.  When using Helm charts with Kustomize overlays for   sophisticated distributed applications, the complexity overhead can become   quite a burden.  Threeport advocates using code in a software controller   instead of config languages in a pipeline.  This means more work up-front and   changes to the delivery system are a bit more involved.  However, this   approach improves the maintainability of complex delivery systems.</li> <li>ArgoCD generally pulls configuration from Git repos and applies them to   Kubernetes clusters.  Threeport uses a relational database to store config   which provides more efficient access to software controllers that need to both   read and write configuration details.</li> </ul> <p>ArgoCD and Threeport could be used in conjunction by using Threeport to provision and manage Kubernetes clusters with ArgoCD.  However, similar to Crossplane, there are a lot of overlapping concerns between the projects.  Using Crossplane and ArgoCD together make far more sense than using Threeport with either Crossplane or ArgoCD.</p>"},{"location":"concepts/comparisons/#next-steps","title":"Next Steps","text":"<p>If you'd like to try out Threeport for yourself, visit our getting started guide.</p> <p>If you'd like to learn about the architecture, check out our architecture overview.</p>"},{"location":"concepts/definitions-instances/","title":"Definitions &amp; Instances","text":"<p>Most objects in Threeport are broken into two parts:</p> <ul> <li>Definition: This holds the configuration of attributes for an object.</li> <li>Instance: A deployed instance of the configuration with a limited number of   runtime parameters.</li> </ul> <p>You can deploy any number of instances for a definition.  This diagram provides two examples:</p> <p></p> <p>A Kubernetes Definition provides the configuration for a Kubernetes cluster. This includes attributes such as the cloud provider to run on, the node sizes and types to use as well as the maximum number of nodes allowed for the cluster.</p> <p>Using Instances, the user can then provision as many clusters with this configuration as they need.  Each time a Kubernetes Instance is provisioned, the configuration in the definition is referenced as well a runtime parameter that specifies which location the Kubernetes cluster should run in.</p> <p>Note: In Threeport, the \"Location\" is an abstraction of the regions for the different cloud providers.  This allows users to use Locations that can be translated to different cloud providers and, thus, enable smoother multi-cloud provider environments.</p> <p>A Workload Definition provides the configuration for a containerized workload. It includes the Kubernetes resource manifests for that workload.</p> <p>Subsequently, a user can deploy any number of instances that use the resource manifests defined in the Definition.  Each time a Workload Instance is deployed, the configuration in the definition is referenced as well as a runtime parameter that determines which Kubernetes cluster the workload should run on.</p>"},{"location":"concepts/definitions-instances/#defined-instance-abstractions","title":"Defined Instance Abstractions","text":"<p>In Threeport, to streamline the process of deploying a cluster, workload or any other object, we provide a defined instance configuration option that allows the user to provide the definition and instance in a single config to Threeport. The Threeport CLI, <code>tptctl</code>, then breaks that into its component parts and creates them in Threeport.</p> <p>As a result, the user can then deploy a second instance of the object</p> <p></p>"},{"location":"concepts/definitions-instances/#division-of-responsibility","title":"Division of Responsibility","text":"<p>These constructs allow team leads and domain experts to define the attributes for different objects.  Then, individual contributors can rapidly provision instances leveraging those detailed configs made available to them in Threeport.</p> <p>For example, the available definitions for AWS RDS database instances can be provided by a database expert for different tiers of usage, i.e. definitions for development, staging and production.  Then, when developers who use RDS as a part of their app stack need to deploy an application instance, they can reference the definition provided for them, rather than determining the config details themselves.</p> <p>In another example, the platform team may take responsibility for defining the Kubernetes cluster attributes that teams may use.  Then when teams need a temporary development or testing cluster, they can rapidly provision them by referencing a provided definition when they create an instance.</p>"},{"location":"concepts/definitions-instances/#comparison-to-other-systems","title":"Comparison to Other Systems","text":"<p>It is common for other systems to couple the configuration to the instantiation of a distinct object that is created and managed.  This often leads to templating mechanisms to deploy similar instances of objects with slight variances.</p> <p>In Threeport we decoupled these elements so that, once the config details are established, any number of instances can be derived from it.  This allows for improved division of responsibility, as discussed above, and avoids the use of complex templating to define different instances.</p>"},{"location":"concepts/definitions-instances/#next-steps","title":"Next Steps","text":"<p>To get a practical understanding of how Threeport manages delivery, check out our Getting Started page which provides the steps to install Threeport and use it to deploy a sample application.</p> <p>Also, the Namespace Management guide provides instructions for creating workload definitions and deriving multiple instances from that definition.  It includes important namespacing considerations for workloads in this context.</p>"},{"location":"concepts/dependencies/","title":"Dependencies","text":"<p>Applications don't exist in a vacuum. They have dependencies.  Threeport manages all the dependencies for an application so that a development team can start with absolutely no infrastructure or runtime environment and readily deploy their application using Threeport.</p> <p>Threeport treats the following concerns as application dependencies:</p> <ul> <li>Cloud Infrastructure: Threeport orchestrates the provisioning, availability   and autoscaling of all compute and networking infra needed to run an   application.</li> <li>Container Orchestration: Kubernetes is the most capable runtime environment   for cloud native software.  Threeport installs and configures Kubernetes   environments for the application being deployed.</li> <li>Support Services: Applications need support services installed on Kubernetes   to provide things like network connectivity, TLS termination, DNS record   management, secrets, metrics and log aggregation.  Threeport installs and   configures these support services for each application deployed.</li> <li>Managed Services: Many applications use cloud provider and/or commercial   managed services such as databases or observability services as a part of   their stack.  Threeport orchestrates the provisioning and connectivity for   the application's workloads to make these managed services available.</li> </ul> <p>The ultimate end-user of Threeport is the developer or operator that needs to deploy and manage instances of their applications - for development, testing, staging or production. The user provides a config for their app that declares its dependencies.  Threeport orchestrates the delivery of the application workloads along with all their dependencies.</p> <p></p>"},{"location":"concepts/dependencies/#next-steps","title":"Next Steps","text":"<p>To get a practical understanding of how Threeport manages delivery, check out our Getting Started page which provides the steps to install Threeport and use it to deploy a sample application.</p>"},{"location":"concepts/extensions/","title":"Threeport Modules","text":"<p>Threeport provides primitives and systems for managing software delivery. It covers a  certain number of use-cases but is necessarily limited to generalized usage. One system  cannot - and should not - provide built-in capabilities for every custom implementation  possible.</p> <p>For this reason, Threeport provides a Golang SDK to extend the functionality of the system  to any use case imaginable. The Threeport SDK can be thought of as a framework for  building custom software delivery solutions, similar to how Django or Ruby on Rails are  frameworks for building web applications.</p> <p>Note: Threeport is written in Go and the SDK currently only supports modules written in  the same language. Because Threeport is built on a standard RESTful API, modules can be  written in any language, however, we don't currently offer SDKs for any other languages  besides Go.</p>"},{"location":"concepts/extensions/#custom-delivery-systems","title":"Custom Delivery Systems","text":"<p>Many large enterprises have invested millions of dollars and dedicated large engineering  teams to build custom delivery systems that serve the purposes of that organization.</p> <p>This results in the following:</p> <ul> <li>Many different organizations solve the same sets of problems concurrently with limited    to no collaboration.</li> <li>Great expense is incurred, sometimes without the intended efficiency, resiliency and    operational outcomes.</li> <li>When successful, the resulting system often solves problems for that organization's    existing workloads exclusively and is difficult to extend when new projects and    requirements spring up.</li> <li>When engineers join an organization, they have limited skill transfer from earlier work    they've engaged in. The time-to-productivity is thus reduced.</li> <li>Conventional delivery tools commonly use domain-specific languages and not    general-purpose programming languages, which further silos platform engineering from    collaboration with developers.</li> </ul> <p>Threeport exists to solve these problems. It provides a framework and software development  kit for building custom delivery systems without starting from scratch. This enables  collaboration between organizations on the same or similar problem sets, reduces the  expense in creating such systems, is infinitely extensible by design and allows engineers  to transfer their skills between different organizations and implementations built atop  Threeport.</p>"},{"location":"concepts/extensions/#example-use-cases","title":"Example Use Cases","text":""},{"location":"concepts/extensions/#primitive-object-abstractions","title":"Primitive Object Abstractions","text":"<p>One way to leverage the SDK is to build abstractions that leverage existing Threeport objects in the API. This is useful for moderately complex distributed applications that use several distinct workloads and a number of managed services as a part of the app stack.</p> <p>In this case the custom API object allows users to define complex apps with relatively few attributes that can be interpreted by the custom controller to configure the different components appropriately.</p> <p>In the following example diagram, the application consists of three separate workloads and several managed services from AWS. The \"Custom Workload\" object used by the dev team provides a simplified abstraction for all the resources needed by that app. The reconcilers in the Custom Threeport Controller understand the custom app's requirements and creates the primitive Threeport objects on behalf of the developer when instances are deployed.</p> <p></p>"},{"location":"concepts/extensions/#custom-infrastructure-management","title":"Custom Infrastructure Management","text":"<p>In the case that a high-value application leverages cloud provider managed services not supported by core Threeport, a module can be built that manages those services as a part of an app instance deployment.</p> <p>This example extends the previous to add a controller to manage AWS ElastiCache and CloudFront instances that are used in the app stack. We encourage software engineers to use the AWS Go SDK in use cases such as this by creating a library for services your organization manages. We follow a similar approach with the aws-builder project that we maintain to support Threeport.</p> <p>Platform engineers have other Kubernetes-based solutions that may also be appropriate such as the AWS Controllers for Kubernetes.</p> <p>We generally do not recommend using an infrastructure-as-code solution such as Terraform or CloudFormation. These do not offer the flexibility and sophistication that direct integrations or Kubernetes-based abstractions do.</p> <p></p>"},{"location":"concepts/extensions/#advanced-application-orchestration","title":"Advanced Application Orchestration","text":"<p>This approach is more involved to develop but produces the best outcome. It is most  appropriate for the highest value revenue-generating applications, especially those that  require a large number of Kubernetes resources to deploy them.</p> <p>This approach involves developing a custom Kubernetes operator that is leveraged by Threeport. It reduces complexity in the Threeport module development and offloads much of the workload management logic to the Kubernetes operator where it is more effective.</p> <p>In this case, native Threeport objects can be used to provision AWS managed services, e.g. RDS, as well as support services, e.g. Domain Names and Gateways. However, by leveraging a Kubernetes operator, the custom Threeport controller need only create a single Workload object that defines the \"CustomApp\" Kubernetes resource, shown in this diagram in dark orange. On the Kubernetes cluster, the Custom App Operator, shown in light orange in this diagram, deploys all of the individual Kubernetes resources in response to that CustomApp resource being created, updated or deleted.</p> <p></p> <p>The advantages to this approach are as follows:</p> <ul> <li>The logic for managing the application is separated between   the Threeport controller and the Kubernetes operator. This division of   concerns assists in reducing complexity in any single component. This also   allows for evolving functionality to be implemented at the correct level:<ul> <li>Single in-cluster concerns live in the Kubernetes operator.</li> <li>Multi-cluster concerns such as multi-cluster deployments live in the   Threeport controller.</li> </ul> </li> <li>Kubernetes operators maintain a Watch on the custom resources - the CustomApp   resource in this example - and will make updates to the child Kubernetes   resources as needed when changes occur to the CustomApp resource. The   Kubernetes operator can also ensure that no changes are made directly to those   child Kubernetes resources and revert them if changes occur. This is not   appropriate to do at the Threeport layer.</li> <li>Engineering responsibility can be more distributed across distinct concerns.   As long as the requirements and scope are clearly defined for each component,   this arrangement works well since there will be two distinct software   projects:<ul> <li>The Threeport controller</li> <li>The Kubernetes operator</li> </ul> </li> </ul> <p>The disadvantages:</p> <ul> <li>There will be two distinct software projects to manage:<ul> <li>The Threeport controller</li> <li>The Kubernetes operator</li> </ul> </li> <li>The implementation for both Threeport controllers and Kubernetes operators need to   be well understood.</li> <li>The API contracts between the two projects need to be maintained and managed   well.</li> </ul> <p>In summary, the advanced application orchestration approach requires greater engineering expertise and investment, but for high-value applications with relatively large development teams, the savings in developer toil and application reliability make the trade-off worthwhile.</p>"},{"location":"concepts/extensions/#summary","title":"Summary","text":"<p>Threeport modules provide infinite flexibility in building the software delivery system your use-case calls for. It can be as simple or sophisticated as your requirements dictate. It allows engineers to leverage the level-triggered controller pattern already in place with Threeport, saving them engineering investments in fundamental architecture. This allows them to focus on the specific business logic and implementation details they are building for.</p>"},{"location":"concepts/extensions/#next-steps","title":"Next Steps","text":"<p>Check out the Threeport SDK Introduction to get started building with the Threeport SDK.</p>"},{"location":"concepts/orchestration-abstractions/","title":"Orchestration Abstractions","text":"<p>Threeport was built on the shoulders of giants.  This document describes how we see Threeport in the context of the cloud native software stack and how we build upon previous advancements.</p> <p>This document is a bit of an over-simplification of a complex topic, but helps illustrate Threeport's value proposition.</p>"},{"location":"concepts/orchestration-abstractions/#linux","title":"Linux","text":"<p>Linux is an operating system for a single machine.  It provides abstractions for the devices on a computer and orchestrates process on that machine.  It allows us to write programs without integrating directly with the underlying hardware. The Unix operating systems enabled the explosion of monolithic software.</p> <p></p>"},{"location":"concepts/orchestration-abstractions/#kubernetes","title":"Kubernetes","text":"<p>Kubernetes is an operating system for a data center of machines.  It provides abstractions for scheduling, network and storage, and orchestrates containers in a single geographical region.  It facilitates managing software deployments at scale and has enabled the explosion of distributed software.</p> <p></p>"},{"location":"concepts/orchestration-abstractions/#threeport","title":"Threeport","text":"<p>Threeport is an operating system for all of your data centers globally.  It provides abstractions for workload dependencies and orchestrates application delivery to any location.  Threeport manages cloud provider infrastructure, Kubernetes clusters, managed services and support services installed on Kubernetes.  These are all managed in service of the application you need to deliver.  Threeport is designed to enable the explosion of decentralized and globally distributed software systems.</p> <p></p>"},{"location":"concepts/orchestration-abstractions/#next-steps","title":"Next Steps","text":"<p>To get a practical understanding of how Threeport orchestrates app delivery, see our Getting Started page which provides the steps to install Threeport and use it to deploy a sample application.</p>"},{"location":"concepts/use-cases/","title":"Use Cases","text":"<p>Following is an overview on how the following three roles use Threeport:</p> <ul> <li>Platform Engineers</li> <li>DevOps</li> <li>Developers</li> </ul>"},{"location":"concepts/use-cases/#threeport-for-platform-engineers","title":"Threeport for Platform Engineers","text":"<p>Platform engineering can extend Threeport using the Threeport SDK.  When an organization has a high-value, complex workload, this approach is highly recommended.  It provides maximum programmatic control of app delivery resulting in greater capabilities, reliability and cost efficiency.  It also requires a greater up-front engineering investment from the platform engineering team which is why using this approach is optimal for sophisticated, revenue generating applications.</p> <p></p> <p>The process for optimizing application delivery with platform engineering looks something like this:</p> <ol> <li>A platform engineering team uses the Threeport SDK to build a custom module for the    Threeport core system.  The code for this module lives in its own    git repo.  Experienced Go programmers with a sound understanding of    Kubernetes and Threeport can usually produce a POC within a couple of weeks,    even faster for simpler use cases.</li> <li>The primary asset produced from the project's CI pipeline is a container    image for the Threeport controller that understands the needs of the custom    workload.</li> <li>The custom controller is deployed with the rest of the Threeport core    system.  Threeport is now extended to include intelligent management of    instances of the custom workload.</li> <li>The developers now use a custom object that requires much less configuration    as the details of implementation are built into the custom Threeport    controller.</li> <li>When the custom workload is created, Threeport deploys all the components of    the application, stitching all the components together to produce a running,    available application as soon as all resources are provisioned.  In the above    example a front-end component is deployed with TLS termination and network    ingress from the public internet plumbed through an AWS load balancer.  The    back end workload is deployed and connected to a new AWS RDS database that is    also spun up by Threeport.  A batch workload is deployed with a new S3 bucket    for assets to be processed.  DNS records are created in a Route53 hosted zone    to provide a domain name for connection to the load balancer's IP.</li> </ol>"},{"location":"concepts/use-cases/#threeport-for-devops","title":"Threeport for DevOps","text":"<p>DevOps can streamline developer usage by creating definitions for the resources developers need to deliver.  Most Threeport objects have two components: a definition and instance.  The definition provides the configuration.  The instance uses a small number of runtime parameters and references the definition to spin up the resources required.  Learn more about definitions and instances in the Concepts section.</p> <p></p> <p>DevOps supports developers as follows:</p> <ol> <li>DevOps creates the definition configurations that can be referenced later by    developers.  Any number of definitions can be made available for different    needs for each resource type.</li> <li>The developer creates instances from these definitions to create a new    Kubernetes runtime, if needed, service dependencies like network gateways,    managed dependencies like RDS databases, as well as the workload itself.  The    developer doesn't have to worry about any resource configuration since DevOps    took care of this.  They only provide runtime parameters such as which    Kubernetes runtime to use for their workload.</li> <li>Threeport deploys a kubernetes runtime and any dependencies that may be    needed. These dependencies can include kubernetes manifests, gateway    resources such as load balancers, and managed AWS services such as RDS.  All    dependencies are connected and the workload is immediately available to the    end user as soon as resources are up. An example configuration can be found    on the Threeport GitHub repository    here.</li> </ol>"},{"location":"concepts/use-cases/#threeport-for-developers","title":"Threeport for Developers","text":"<p>Threeport allows developers to deliver the apps they build to cloud native environments.</p> <p></p> <p>Following is a common scenario for a developer workflow using Threeport:</p> <ol> <li>Developer pushes code to GitHub.</li> <li>The CI actions run (GitHub actions in this case) and produce a container image that is    pushed to a registry such as Docker Hub or GitHub Container Registry.</li> <li>The developer uses <code>tptctl</code> to deploy their workload.  This makes a call to    the Threeport core system and triggers it to deploy the app.    Threeport will call the Kubernetes API to deploy the Kubernetes resources.    If requested, Threeport can deploy AWS managed service dependencies as well    as other support services to configure ingress routing from the internet,    provision SSL certs, set DNS records, etc.</li> <li>The image is pulled by the Kubernetes control plane.</li> <li>The app runs in containers on the Kubernetes cluster.  This example shows    the app running in the same Kubernetes environment as the Threeport Core,    but this is optional.  Threeport can deploy separate Kubernetes    runtime environments as needed, and manage deployments to any cluster managed    by Threeport.</li> </ol>"},{"location":"control-planes/control-plane-intro/","title":"Control Planes","text":"<p>Control planes in Threeport offer a mechanism to provision new Threeport control planes using an existing Threeport control plane.</p> <p>We don't recommend managing multiple Threeport control planes unless you have a compelling use case for it.  It adds complexity to your systems that you may not need.</p> <p>One possible use case is for a large organization with a central IT team that wants to provide dedicated Threeport control planes to different lines of business.</p> <p>This diagram shows a \"parent\" control plane run by central IT that an Admin uses to provision new \"child\" control planes for teams in other parts of the organization to use.</p> <p></p> <p>In this model, central IT can provide Threeport as a service to internal teams, each with dedicated, segregated Threeport control planes to orchestrate their applications.</p>"},{"location":"control-planes/control-plane-intro/#control-plane-definition","title":"Control Plane Definition","text":"<p>The definition for a new Threeport control plane allows you to disable auth (only appropriate for test environments) and gives you the option to register the parent control plane with the child so the hierarchy is known to each control plane.</p> <p>Reference: ControlPlaneDefinition</p>"},{"location":"control-planes/control-plane-intro/#control-plane-instance","title":"Control Plane Instance","text":"<p>The control plane instance allows you to nominate the Kubernetes namespace where the Threeport control plane will be deployed.  Since a Threeport control plane has a <code>ControlPlaneInstance</code> object stored in its database that represents itself (as distinct from control plane instances that are created separately), this information is also represented on this object.  This object also records whether it is a \"Genesis\" control plane, i.e. was bootstrapped with tptctl rather than deployed as a child of another Threeport control plane.</p> <p>Reference: ControlPlaneInstance</p>"},{"location":"control-planes/control-plane-intro/#next-steps","title":"Next Steps","text":"<p>For more information about Threeport architecture to understand how Threeport works and how it is bootstrapped, see our Architecture Overview document</p>"},{"location":"gateways/gateway-intro/","title":"Gateways","text":"<p>Gateways provide a common support service to workloads.  They provide network ingress into the Kubernetes Runtime to route traffic to a workload that is exposed to end users, usually from the public internet.</p> <p>When you declare a Gateway for your workload, Threeport installs and configures a Gloo Edge to manage incoming traffic.  A cloud provider load balancer is also provisioned that provides a network endpoint and proxies traffic to Gloo.  Gloo terminates TLS connections and forwards connections to the appropriate workloads.</p> <p>TLS assets are provisioned and rotated by cert-manager.  Again, this support service is installed and configured for the workload at runtime as needed.</p>"},{"location":"gateways/gateway-intro/#gateway-definition","title":"Gateway Definition","text":"<p>The gateway definition allows you define the HTTP and TCP ports you wish to use, as well as the subdomain for a hosted zone if DNS records are also being managed.  You can also provide the Kubernetes Service name that Gloo will forward traffic to.  This will need to correspond to the Service resource name in the Kubernetes resource manifest supplied with a Workload Definition.</p> <p>You can also instruct Threeport to enable TLS - in which case cert-manager will provision and rotate certs for your app.  You can also request HTTPS redirects so that HTTP requests on port 80 will be redirected to HTTPS on 443.</p> <p>You can also specify a request path to instruct the gateway to forward traffic to different workloads based on the path in the request URL.</p> <p>Reference: GatewayDefinition</p>"},{"location":"gateways/gateway-intro/#gateway-instance","title":"Gateway Instance","text":"<p>The gateway instance allows you to tie the gateway config in the definition to a particular workload that prompts Threeport to deploy the Gloo Edge support service and configure it for the workload.</p> <p>Reference: GatewayInstance</p> <p>Domain names can be managed through a Threeport support service as well. Threeport uses a project called external-dns to do this. When using domain names, Threeport will install and configure external-dns as needed.</p>"},{"location":"gateways/gateway-intro/#domain-name-definition","title":"Domain Name Definition","text":"<p>The domain name definition allows you to configure a Route53 zone to use for DNS records for your application.  For example if you have a hosted zone <code>myorg.com</code> that manages DNS records for that domain, you can provide that in a definition and a subdomain such as <code>myapp</code> in the gateway definition so that your app can be reached at <code>myapp.myorg.com</code>.</p> <p>Reference: DomainNameDefinition</p>"},{"location":"gateways/gateway-intro/#domain-name-instance","title":"Domain Name Instance","text":"<p>The domain name instance ties a workload to the domain name definition and configures the external-dns support service to update Route53 to provide the full domain name used by the workload.</p> <p>Reference: DomainNameInstance</p>"},{"location":"gateways/gateway-intro/#next-steps","title":"Next Steps","text":"<p>See our Deploy Workload on AWS guide for an example of how to use Gateways and Domain Names for your application.</p>"},{"location":"guides/s3-dependency/","title":"Workload With AWS S3 Dependency","text":"<p>This guide walks through deploying a workload with a dependency on an AWS S3 bucket.</p>"},{"location":"guides/s3-dependency/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes you have a remote Kubernetes runtime instance provisioned using the eks provider.  See Remote Kubernetes Runtime guide for instructions.</p>"},{"location":"guides/s3-dependency/#download-configs","title":"Download Configs","text":"<p>Download the Kubernetes manifest for a simple containerized workload that has the AWS CLI installed.</p> <p>TODO</p> <p>Download the Threeport config for the workload.</p> <p>TODO</p>"},{"location":"guides/s3-dependency/#deploy","title":"Deploy","text":"<p>Deploy the workload to the remote runtime:</p> <pre><code>tptctl create workload -c s3-client-workload.yaml\n</code></pre>"},{"location":"guides/s3-dependency/#test","title":"Test","text":"<p>Now let's ensure our S3 client workload has access to create and delete objects on that S3 bucket.</p> <p>First let's get our workload's pod name and namespace.</p> <pre><code>POD_NAMESPACE=$(kubectl get ns -l app=aws-client -o=jsonpath='{@.items[0].metadata.name}')\nPOD_NAME=$(kubectl get po -n $POD_NAMESPACE -l app=aws-client -o=jsonpath='{@.items[0].metadata.name}')\n</code></pre> <p>Get bash session in the running container.</p> <pre><code>kubectl exec -it -n $POD_NAMESPACE $POD_NAME -- bash\n</code></pre> <p>Inside the container, create a text file to save to S3.</p> <pre><code>echo \"testing s3\" &gt; test.txt\n</code></pre> <p>Copy that file to our S3 bucket.</p> <pre><code>aws s3 cp test.txt s3://$S3_BUCKET_NAME/test.txt\n</code></pre> <p>Remove the local file, re-sync with the S3 bucket and confirm the contents of the received file.</p> <pre><code>rm test.txt\naws s3 sync s3://$S3_BUCKET_NAME ./\ncat test.txt\n</code></pre> <p>Disonnect from the container.</p> <pre><code>exit\n</code></pre>"},{"location":"guides/s3-dependency/#clean-up","title":"Clean Up","text":"<p>Remove the workload instance.</p> <pre><code>tptctl delete workload-instance -n aws-client\n</code></pre>"},{"location":"helm-workloads/deploy-helm-local/","title":"Deploy Helm Workload Locally","text":"<p>In this guide, we're going to use a Helm workload to deploy a sample app locally using Threeport.</p> <p>First we'll create a definition and some instances from that definition.  After that, we'll deploy a Helm workload using the defined instance abstraction which creates a definition and instance in a single step.  If you prefer, jump straight to the Helm Workload Defined Instance section for the quick intro.  If you would like a clearer understanding of how the definitions and instances work for Helm workloads, run through this document from beginning to end.</p> <p>See our Definitions &amp; Instances concepts document for more details about definitions and instances in Threeport.</p>"},{"location":"helm-workloads/deploy-helm-local/#prerequisites","title":"Prerequisites","text":"<p>You'll need a local Threeport control plane for this guide.  Follow the Install Threeport Locally guide to set that up.</p>"},{"location":"helm-workloads/deploy-helm-local/#create-helm-workload-definition","title":"Create Helm Workload Definition","text":"<p>First, create a work space on your local file system:</p> <pre><code>mkdir threeport-helm-test\ncd threeport-helm-test\n</code></pre> <p>Download a sample Helm workload config and values file as follows:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-definition.yaml\ncurl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-definition-values.yaml\n</code></pre> <p>The Helm workload config looks as follows:</p> <pre><code>HelmWorkloadDefinition:\n  Name: wordpress\n  Repo: \"oci://registry-1.docker.io/bitnamicharts\"\n  Chart: wordpress\n  ValuesDocument: wordpress-helm-workload-definition-values.yaml\n</code></pre> <p>This definition specifies Bitnami charts repo and the Helm WordPress chart to be used by all instances derived from this definition.  It also references the values file that you download that has an override for the default number of replicas in that upstream Helm chart:</p> <p>Note: At this time, Helm charts must be hosted in a Helm repo to be used in Threeport.</p> <pre><code>replicaCount: 2\n</code></pre> <p>This means that, unless otherwise specified on the instance, 2 replicas of the WordPress app will be created.</p> <p>We can now create the workload as follows:</p> <pre><code>tptctl create helm-workload-definition --config wordpress-helm-workload-definition.yaml\n</code></pre> <p>This command calls the Threeport API to create the HelmWorkload object. No workloads are deployed at this time.  We've just defined the chart and default values to be used by instances.  Next, we'll create some running instances from this definition.</p>"},{"location":"helm-workloads/deploy-helm-local/#create-helm-workload-instances","title":"Create Helm Workload Instances","text":"<p>First let's create a instance a default instance.  In this case we're just using the Helm chart with the default values <code>replicaCount: 2</code>.  All other values are inherited from the upstream defaults.</p> <p>Download the instance config:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-default.yaml\n</code></pre> <p>This config simply references the definition and adds no runtime parameters (values that provide config at runtime).</p> <pre><code>HelmWorkloadInstance:\n  Name: wordpress-default\n  HelmWorkloadDefinition:\n    Name: wordpress\n</code></pre> <p>Create the default Helm workload instance:</p> <pre><code>tptctl create helm-workload-instance --config wordpress-helm-workload-instance-default.yaml\n</code></pre> <p>Now you can view the Helm workload you have running.</p> <pre><code>tptctl get helm-workloads\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAME           HELM WORKLOAD DEFINITION     HELM WORKLOAD INSTANCE     KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nwordpress      wordpress                    wordpress-default          threeport-dev-0                 Healthy      1m3s\n</code></pre> <p>If you have kubectl installed you can view the pods in your cluster:</p> <pre><code>kubectl get pods -A -l control-plane.threeport.io/managed-by=threeport\n</code></pre> <p>You should see output similar to this:</p> <pre><code>NAMESPACE                      NAME                                        READY   STATUS    RESTARTS      AGE\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-9zt4d   1/1     Running   1 (67s ago)   3m49s\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-fckqp   1/1     Running   0             3m49s\nwordpress-default-vpmmjfosws   wordpress-default-release-mariadb-0         1/1     Running   0             3m49s\n</code></pre> <p>As you can see, there are two replicas of the WordPress app and one instance of its database.</p> <p>Now let's create another Helm workload instance from our definition.  In this case we'll simulate a dev instance that has some Helm values as runtime parameters.  Download the config and values file:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-dev.yaml\ncurl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-dev-values.yaml\n</code></pre> <p>The config for the dev instance looks similar to the default instance deployed above but references the values file for the runtime parameters.</p> <pre><code>HelmWorkloadInstance:\n  Name: wordpress-dev\n  ValuesDocument: wordpress-helm-workload-instance-dev-values.yaml\n  HelmWorkloadDefinition:\n    Name: wordpress\n</code></pre> <p>The values file specifies a label to identify the tier of the app.</p> <pre><code>commonLabels:\n  tier: \"dev\"\n</code></pre> <p>We can now create the new instance.</p> <pre><code>tptctl create helm-workload-instance --config wordpress-helm-workload-instance-dev.yaml\n</code></pre> <p>Now, if we get the Helm workload instances from the system we can see both instances derived from the same definition.</p> <pre><code>tptctl get helm-workloads\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAME           HELM WORKLOAD DEFINITION     HELM WORKLOAD INSTANCE     KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nwordpress      wordpress                    wordpress-default          threeport-dev-0                 Healthy      15m12s\nwordpress      wordpress                    wordpress-dev              threeport-dev-0                 Healthy      1m5s\n</code></pre> <p>If we view Threeport-managed pods with kubectl again we can see pods for both instances of WordPress.</p> <pre><code>kubectl get pods -A -l control-plane.threeport.io/managed-by=threeport\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAMESPACE                      NAME                                        READY   STATUS    RESTARTS        AGE\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-9zt4d   1/1     Running   1 (14m ago)     17m\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-fckqp   1/1     Running   0               17m\nwordpress-default-vpmmjfosws   wordpress-default-release-mariadb-0         1/1     Running   0               17m\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-d5df57df-5c8bx        1/1     Running   1 (2m34s ago)   3m14s\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-d5df57df-hzz46        1/1     Running   0               3m14s\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-mariadb-0             1/1     Running   0               3m14s\n</code></pre> <p>One thing you'll notice is that each time a new instance is created, it gets its own namespace which allows you to create as many instances in the same Kubernetes runtime as you need.</p> <p>Now, let's create one more instance for prod.  In this case we'll apply a different label and also override the Helm values provided in the definition.</p> <p>Download the config and values file:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-prod.yaml\ncurl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-prod-values.yaml\n</code></pre> <p>The instance config references the same definition and points to the new prod values file:</p> <pre><code>HelmWorkloadInstance:\n  Name: wordpress-prod\n  ValuesDocument: wordpress-helm-workload-instance-prod-values.yaml\n  HelmWorkloadDefinition:\n    Name: wordpress\n</code></pre> <p>The values file has a its own labels and overrides the replicas:</p> <pre><code>replicaCount: 4\ncommonLabels:\n  tier: \"prod\"\n</code></pre> <p>We can now deploy the prod instance:</p> <pre><code>tptctl create helm-workload-instance --config wordpress-helm-workload-instance-prod.yaml\n</code></pre> <p>Now, when we view Helm workloads we can see all 3 instances derived from the same definition:</p> <pre><code>tptctl get helm-workloads\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAME           HELM WORKLOAD DEFINITION     HELM WORKLOAD INSTANCE     KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nwordpress      wordpress                    wordpress-default          threeport-dev-0                 Healthy      22m49s\nwordpress      wordpress                    wordpress-dev              threeport-dev-0                 Healthy      8m42s\nwordpress      wordpress                    wordpress-prod             threeport-dev-0                 Healthy      38s\n</code></pre> <p>And, again, we can see the pods from the new deployment using kubectl.</p> <pre><code>kubectl get pods -A -l control-plane.threeport.io/managed-by=threeport\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAMESPACE                      NAME                                        READY   STATUS    RESTARTS        AGE\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-9zt4d   1/1     Running   1 (21m ago)     24m\nwordpress-default-vpmmjfosws   wordpress-default-release-d699bdb6b-fckqp   1/1     Running   0               24m\nwordpress-default-vpmmjfosws   wordpress-default-release-mariadb-0         1/1     Running   0               24m\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-d5df57df-5c8bx        1/1     Running   1 (9m23s ago)   10m\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-d5df57df-hzz46        1/1     Running   0               10m\nwordpress-dev-xsiqnjpkgd       wordpress-dev-release-mariadb-0             1/1     Running   0               10m\nwordpress-prod-fqgiwndiur      wordpress-prod-release-766467d4c-9qrv9      1/1     Running   1 (72s ago)     2m\nwordpress-prod-fqgiwndiur      wordpress-prod-release-766467d4c-n594w      1/1     Running   1 (72s ago)     2m\nwordpress-prod-fqgiwndiur      wordpress-prod-release-766467d4c-q9wp7      1/1     Running   0               2m\nwordpress-prod-fqgiwndiur      wordpress-prod-release-766467d4c-st2qn      1/1     Running   1 (72s ago)     2m\nwordpress-prod-fqgiwndiur      wordpress-prod-release-mariadb-0            1/1     Running   0               2m\n</code></pre> <p>As you can see, due to the runtime parameters for the prod instance specifying 4 replicas, there are 4 pods for the WordPress app.</p> <p>Before we move on, let's clean up the Helm workloads we've deployed so far.</p> <pre><code>tptctl delete helm-workload-instance -n wordpress-prod\ntptctl delete helm-workload-instance -n wordpress-dev\ntptctl delete helm-workload-instance -n wordpress-default\ntptctl delete helm-workload-definition -n wordpress\n</code></pre>"},{"location":"helm-workloads/deploy-helm-local/#helm-workload-defined-instance","title":"Helm Workload Defined Instance","text":"<p>If you would like to create a definition and instance in one step, you can do that too.  Download sample config.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload.yaml\n</code></pre> <p>This config includes the definition info, default Helm values for the definition as well as Helm values for the instance.  It is referencing Helm values documents we previously downloaded.</p> <pre><code>HelmWorkload:\n  Name: wordpress-dev\n  Repo: \"oci://registry-1.docker.io/bitnamicharts\"\n  Chart: wordpress\n  DefinitionValuesDocument: wordpress-helm-workload-definition-values.yaml\n  InstanceValuesDocument: wordpress-helm-workload-instance-dev-values.yaml\n</code></pre> <p>If you haven't already, download the values documents referenced in the config.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-definition-values.yaml\ncurl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/helm/wordpress-helm-workload-instance-dev-values.yaml\n</code></pre> <p>Now we can create a Helm workload definition and instance with one command:</p> <pre><code>tptctl create helm-workload --config wordpress-helm-workload.yaml\n</code></pre> <p>If we get Helm workloads we can see we now have a definition with an instance already derived from it.</p> <pre><code>tptctl get helm-workloads\n</code></pre> <p>Your output should look similar to this:</p> <pre><code>NAME               HELM WORKLOAD DEFINITION     HELM WORKLOAD INSTANCE     KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nwordpress-dev      wordpress-dev                wordpress-dev              threeport-dev-0                 Healthy      54s\n</code></pre> <p>We can also delete both with a single step as well.</p> <pre><code>tptctl delete helm-workload --config wordpress-helm-workload.yaml\n</code></pre>"},{"location":"helm-workloads/deploy-helm-local/#clean-up","title":"Clean Up","text":"<p>Before we finish, let's clean up the files we downloaded to your file system.</p> <pre><code>cd ../\nrm -rf threeport-helm-test\n</code></pre>"},{"location":"helm-workloads/deploy-helm-local/#summary","title":"Summary","text":"<p>In this guide we demonstrated how to use Helm charts that are hosted on a Helm repo to install Helm workloads.  We created definitions and instances separately and also created a definition and instance with one step using the defined instance abstraction.</p>"},{"location":"helm-workloads/helm-intro/","title":"Helm Workloads","text":"<p>Helm is a popular package manager for Kubernetes.  Helm charts use templates to render Kubernetes resource manifests. Helm is generally used as a command line tool and/or incorporated into a GitOps pipeline.</p> <p>In Threeport, Helm is offered so that teams already using Helm can get started using the charts they have or currently use.  Helm is useful for relatively uncomplicated deployments or when using community-supported projects that have Helm charts available.  However, the templating used by Helm breaks down in sophisticated, production environments when the templates become overwhelmed with conditionals and loops.  In more advanced use-cases, we recommend using custom Kubernetes operators and/or Threeport controllers to programmatically manage complex configuration of software delivery.  See our documentation on Threeport Extensions for more information on this topic.</p> <p>Note: In order to use Helm charts in Threeport, the chart must be hosted on a Helm repo.</p>"},{"location":"helm-workloads/helm-intro/#helm-workload-definition","title":"Helm Workload Definition","text":"<p>A Helm Workload Definition allows you to specify the repo URL, chart name, chart version and a set of Helm values that will be used each time an instance of the Helm chart is deployed.  The Helm values available on the definition allow you to set default values (that may differ from the defaults applied on the upstream project) for each instance deployed.</p> <p>Reference: HelmWorkloadDefinition</p>"},{"location":"helm-workloads/helm-intro/#helm-workload-instance","title":"Helm Workload Instance","text":"<p>An instance of a Helm Workload allows you to provide additional Helm values that will override any values provided on the definition.  You can also specify which Kubernetes Runtime Instance to deploy to.</p> <p>Reference: HelmWorkloadInstance</p>"},{"location":"helm-workloads/helm-intro/#next-steps","title":"Next Steps","text":"<p>See our Local Helm Workload guide for a walk through on using Helm in Threeport.</p>"},{"location":"install/install-threeport-aws/","title":"Install Threeport on AWS","text":"<p>This guide provides instructions to install Threeport on AWS Elastic Kubernetes Service.  We will spin up a new EKS cluster and install the Threeport core system there.  It requires you have an AWS account and API keys.  This install method is useful for testing Threeport on a remote cloud provider.</p> <p>If you would prefer to test out Threeport locally, see our guide to Install Threeport Locally</p> <p>Note: this guide requires you have our tptctl command line tool installed.  See our Install tptctl guide to install if you haven't already.</p>"},{"location":"install/install-threeport-aws/#install-threeport","title":"Install Threeport","text":"<p>This section assumes you already have an AWS account and credentials configured on your local machine with a profile named \"default\".  Follow the AWS quickstart page for steps on how to do this.</p> <p>Note: if you have the <code>~/.aws/config</code> and <code>~/.aws/credentials</code> files on your file system, you're likely already set up.</p> <p>Also, ensure you have the required permissions to create the necessary resources in AWS.  If your user has the built-in <code>AdministratorAccess</code> policy attached, you can continue.  Otherwise, check out our AWS Permissions guide to make sure you can create the resources required to run a Threeport core system.</p> <p>You also will need your AWS account ID.  It can be found in the AWS console. Log in to AWS and look at the top-right of the console.  It will say something like <code>username @ 1111-2222-3333</code>.  The 12 digit number (without dashes) is your account ID.</p> <p>With credentials configured, run the following to install Threeport in EKS:</p> <pre><code>tptctl up \\\n    --name test \\\n    --provider eks \\\n    --aws-region [aws region]  # e.g. us-east-1\n</code></pre> <p>This process will usually take 10-15 minutes.  It can take even longer on some AWS accounts.  You will see output as AWS resources are created. It will create a remote EKS Kubernetes cluster and install all of the core system components.  It will also register the same EKS cluster as the default Kubernetes cluster for tenant workloads.</p>"},{"location":"install/install-threeport-aws/#validate-deployment","title":"Validate Deployment","text":"<p>Note: if you would like to use kubectl against the cluster where Threeport is running, and you have the AWS CLI installed, you can update your kubeconfig with:</p> <pre><code>aws eks update-kubeconfig --name threeport-test --region [aws region]\n</code></pre> <p>Then, view the Threeport core system pods with kubectl:</p> <pre><code>kubectl get pods -n threeport-control-plane\n</code></pre>"},{"location":"install/install-threeport-aws/#next-steps","title":"Next Steps","text":"<p>Next, we suggest you deploy a sample workload to AWS using Threeport.  It will give you clear idea of Threeport's dependency management capabilities.  See our Deploy Workload on AWS guide for instructions.</p>"},{"location":"install/install-threeport-aws/#clean-up","title":"Clean Up","text":"<p>If you're done for now and not installing a workload on AWS, you can uninstall Threeport:</p> <pre><code>tptctl down --name test\n</code></pre>"},{"location":"install/install-threeport-local/","title":"Install Threeport Locally","text":"<p>This guide provides instructions for installing Threeport on kind.  We will run Kubernetes in docker containers on your local machine and install the Threeport core system there. It requires you have docker installed on your machine.  This install method is useful for testing out Threeport to get an idea of how it works.</p> <p>If you would like to install Threeport on AWS for a more realistic experience of how Threeport is generally used, see our guide to Install Threeport on AWS</p> <p>Note: this guide requires you have our tptctl command line tool installed.  See our Install tptctl guide to install if you haven't already.</p>"},{"location":"install/install-threeport-local/#docker","title":"Docker","text":"<p>In order to run Threeport locally, you must first have Docker Desktop installed if on a Mac or Docker Engine on Linux.</p> <p>If you are on Ubuntu you can install and add your user to the docker group as follows:</p> <pre><code>sudo apt-get install gcc docker.io\nsudo usermod -aG docker $USER\n</code></pre>"},{"location":"install/install-threeport-local/#install-threeport","title":"Install Threeport","text":"<p>To install the Threeport core system locally:</p> <pre><code>tptctl up \\\n    --name=test \\\n    --provider=kind \\\n    --auth-enabled=false\n</code></pre> <p>The <code>--provider</code> flag indicates that we're using kind to provision the underlying Kubernetes cluster.  The <code>--name</code> flag provides an arbitrary name for this control plane instance.  And the <code>--auth-enabled</code> flag indicates we want to turn off user authentication which is turned on by default and should only be turned off when testing locally.  Disabling auth will allow us to more easily explore the API in a subsequent step.</p> <p>It will take a few minutes for this process to complete.</p> <p>This will create a local kind Kubernetes cluster and install all of the control plane components.  It will also register the same kind cluster as the default compute space cluster for tenant workloads.</p>"},{"location":"install/install-threeport-local/#validate-deployment","title":"Validate Deployment","text":"<p>If you have kubectl installed and wish to view the pods that constitute the Threeport control plane:</p> <pre><code>kubectl get pods -n threeport-control-plane\n</code></pre> <p>Note: if you notice any pods crashlooping, give them a few minutes.  The Threeport controllers depend on the API server which, in turn, depends on the database and message broker.  Each component will come up once its dependencies are running.</p>"},{"location":"install/install-threeport-local/#swagger-documentation","title":"Swagger Documentation","text":"<p>Threeport API endpoints are documented with Swagger at <code>$THREEPORT_API_ENDPOINT/swagger/index.html</code>. This is most easily accessed by setting <code>--auth-enabled=false</code> on a Threeport control plane deployed to Kind and visiting http://localhost/swagger/index.html.</p>"},{"location":"install/install-threeport-local/#next-steps","title":"Next Steps","text":"<p>Next, we suggest you deploy a sample workload locally using Threeport.  See our Deploy Workload Locally guide for instructions.</p>"},{"location":"install/install-threeport-local/#clean-up","title":"Clean Up","text":"<p>If you're done for now and not installing a workload locally, you can uninstall the Threeport control plane:</p> <pre><code>tptctl down --name test\n</code></pre>"},{"location":"install/install-tptctl/","title":"Install tptctl","text":"<p>This guide has instructions for installing the Threeport command line tool.</p> <p>Note: while we're building releases for Windows, they are not tested and not expected to work at this time.</p>"},{"location":"install/install-tptctl/#get-latest-version","title":"Get Latest Version","text":"<p>If you have jq installed, run the following command:</p> <pre><code>TPTCTL_VERSION=$(curl -s \"https://api.github.com/repos/threeport/threeport/releases/latest\" | jq '.tag_name' -r)\n</code></pre> <p>Otherwise, look up the version at the releases page and set it like so:</p> <pre><code>TPTCTL_VERSION=v0.5.1  # substitute latest version\n</code></pre>"},{"location":"install/install-tptctl/#download","title":"Download","text":"<p>Download the release and checksums: <pre><code>curl -LO \"https://github.com/threeport/threeport/releases/download/$TPTCTL_VERSION/tptctl_${TPTCTL_VERSION}_$(uname)_$(uname -m).tar.gz\"\ncurl -L \"https://github.com/threeport/threeport/releases/download/$TPTCTL_VERSION/checksums.txt\" &gt; checksums.txt\n</code></pre></p>"},{"location":"install/install-tptctl/#verify","title":"Verify","text":"<p>Optional but recommended.</p> <p>Run the following command on Linux to verify the integrity of the package:</p> <pre><code>sha256sum -c --ignore-missing checksums.txt\n</code></pre>"},{"location":"install/install-tptctl/#install","title":"Install","text":"<pre><code>tar xf tptctl_${TPTCTL_VERSION}_$(uname)_$(uname -m).tar.gz\nsudo mv tptctl_${TPTCTL_VERSION}_$(uname)_$(uname -m)/tptctl /usr/local/bin\n</code></pre>"},{"location":"install/install-tptctl/#cleanup","title":"Cleanup","text":"<pre><code>rm checksums.txt tptctl_${TPTCTL_VERSION}_$(uname)_$(uname -m).tar.gz\nrm -rf tptctl_${TPTCTL_VERSION}_$(uname)_$(uname -m)\n</code></pre>"},{"location":"install/install-tptctl/#view-usage-info","title":"View Usage Info","text":"<pre><code>tptctl help\n</code></pre>"},{"location":"install/install-tptctl/#note-for-macos-users","title":"Note for MacOS Users","text":"<p>If you have issues running <code>tptctl</code> on your machine, follow the steps outlined by Apple here.</p>"},{"location":"install/install-tptctl/#next-steps","title":"Next Steps","text":"<p>Now that you have tptctl installed, we suggest you follow our guide to install Threeport locally.</p>"},{"location":"kubernetes-runtime/kubernetes-intro/","title":"Kubernetes Runtimes","text":"<p>A Kubernetes Runtime is currently the only Threeport-supported runtime environment for workloads.  Each instance represents a distinct Kubernetes cluster.  You can deploy and utilize as many Kubernetes Runtimes as your needs required.</p> <p>As such Workloads in Threeport require Kubernetes resource manifests to deploy them.</p> <p>For more information about Kubernetes, see the official Kubernetes docs.</p>"},{"location":"kubernetes-runtime/kubernetes-intro/#alternative-runtimes","title":"Alternative Runtimes","text":"<p>It is possible to add support for alternative runtime environments such as machines, i.e. deploying directly to a server using a machine image.</p> <p>Alternative runtimes are not on the Threeport roadmap but could be incorporated.</p>"},{"location":"kubernetes-runtime/kubernetes-intro/#kubernetes-runtime-definition","title":"Kubernetes Runtime Definition","text":"<p>The definition allows you to specify which infrastructure provider to use (currently only EKS on AWS is supported).  You can also specify the node sizes and profiles.  Currently, you can reference the source code to see which NodeSize and NodeProfile values are available and what AWS machine types these translate to.  All Kubernetes Runtimes use cluster autoscaling and you can specify the maximum number of nodes to allow in the cluster.</p> <p>Reference: KubernetesRuntimeDefinition</p>"},{"location":"kubernetes-runtime/kubernetes-intro/#kubernetesruntimeinstance","title":"KubernetesRuntimeInstance","text":"<p>This represents a deployed instance of a Kubernetes cluster.  You can specify which location you would like to use.  Currently, you can reference the source code for the available Location values and which AWS regions they correspond to.</p> <p>Reference: KubernetesRuntimeInstance</p>"},{"location":"kubernetes-runtime/kubernetes-intro/#next-steps","title":"Next Steps","text":"<p>We have a Remote Kubernetes Runtime guide that walks you through the creation of a Kubernetes cluster to use for your workloads in Threeport.</p>"},{"location":"kubernetes-runtime/remote-kubernetes-runtime/","title":"Remote Kubernetes Runtime","text":"<p>Threeport supports the management of Kubernetes clusters as remote runtimes. This pattern may be used to run workloads on separate Kubernetes clusters from the one that the Threeport API is deployed to.</p>"},{"location":"kubernetes-runtime/remote-kubernetes-runtime/#prerequisites","title":"Prerequisites","text":"<p>An instance of the Threeport is required to get started.  You can install a Local Threeport instance and use it to create a remote Kubernetes runtime.</p> <p>Note that AWS EKS clusters are currently the only supported type of remote Kubernetes runtime.</p>"},{"location":"kubernetes-runtime/remote-kubernetes-runtime/#aws-account-setup","title":"AWS Account Setup","text":"<p>First, create a work space on your local file system:</p> <pre><code>mkdir threeport-runtime-test\ncd threeport-runtime-test\n</code></pre> <p>To get started, a valid <code>AwsAccount</code> object must be created. Use the Basic AWS Setup guide for instructions.</p>"},{"location":"kubernetes-runtime/remote-kubernetes-runtime/#deployment","title":"Deployment","text":"<p>Kubernetes clusters are represented as <code>KubernetesRuntime</code> objects in the Threeport API.</p> <p>Use the following command to download a sample Kubernetes Runtime config:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/releases/main/samples/k8s-runtime.yaml\n</code></pre> <p>If you open the file it will look as follows:</p> <pre><code>KubernetesRuntime:\n  Name: eks-remote\n  InfraProvider: eks\n  InfraProviderAccountName: default-account\n  HighAvailability: false\n  Location: NorthAmerica:NewYork\n  DefaultRuntime: true\n</code></pre> <p>The <code>Name</code> field is an arbitrary name for the user to assign.</p> <p>The <code>InfraProvider</code> indicates we will use AWS EKS to spin up the Kubernetes cluster.</p> <p>The <code>InfraProviderAccountName</code> references the name of the AWS account we created above.</p> <p>The <code>HighAvailability</code> field determines the number of availability zones (AZs) the cluster will be installed across.  When <code>false</code> it will installed across two AZs.</p> <p>The <code>Location</code> field tells Threeport where to install the Kubernetes cluster. <code>NorthAmerica:NewYork</code> is a Threeport abstraction that allows users to reference a common set of locations, regardless of provider.  For AWS, this translates to the <code>us-east-1</code> region.  When other cloud providers are supported, it will reference the appropriate region for the cloud provider being used.  For now, you can reference the Threeport source code to see which locations map to which regions in AWS.</p> <p>The <code>DefaultRuntime</code> field indicates that, when deploying workloads, if a Kubernetes Runtime is not specified, it will use this one by default.</p> <p>Create a <code>KubernetesRuntime</code> instance: <pre><code>tptctl create kubernetes-runtime --config k8s-runtime.yaml\n</code></pre></p> <p>View the status of the deployed Kubernetes runtime instance: <pre><code>tptctl get kubernetes-runtime-instances\n</code></pre></p> <p>Note: if you would like to use kubectl against the cluster where Threeport is running and you have the AWS CLI installed you can update your kubeconfig with:</p> <pre><code>aws eks update-kubeconfig --name threeport-test\n</code></pre>"},{"location":"kubernetes-runtime/remote-kubernetes-runtime/#cleanup","title":"Cleanup","text":"<p>Run the following command to delete the remote Kubernetes runtime instance: <pre><code>tptctl delete kubernetes-runtime-instance --name eks-remote\n</code></pre></p> <p>Clean up the downloaded config files: <pre><code>rm aws-account.yaml\nrm k8s-runtime.yaml\n</code></pre></p>"},{"location":"observability/deploy-observability-local/","title":"Deploy Observability Locally","text":"<p>The observability stack provides access to metrics and logging for your workloads.  This guide walks through the installation and usage of observability with Threeport.</p>"},{"location":"observability/deploy-observability-local/#prerequisites","title":"Prerequisites","text":"<p>You'll need a local Threeport control plane for this guide.  Follow the Install Threeport Locally guide to set that up.</p> <p>You'll also want to deploy a workload to get metrics and logs for.  Follow the Deploy Workload Locally guide to deploy a sample WordPress app.</p> <p>Note: for this guide, you will need to have kubectl installed at this time.</p>"},{"location":"observability/deploy-observability-local/#configs","title":"Configs","text":"<p>First, create a work space on your local file system:</p> <pre><code>mkdir threeport-observability-test\ncd threeport-observability-test\n</code></pre> <p>Download a sample workload config as follows:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/observability/observability-stack.yaml\n</code></pre> <p>You now have the config for an observability stack on your file system.  This is what it looks like.</p> <pre><code>ObservabilityStack:\n  Name: observability\n  KubernetesRuntimeInstance:\n    Name: eks-remote\n  MetricsEnabled: true\n  LoggingEnabled: true\n  # LokiHelmValues: |\n  # PromtailHelmValues: |\n  # KubePrometheusStackHelmValues: |\n  # KubePrometheusStackHelmValuesDocument: kube-prometheus-stack-values.yaml\n  # GrafanaHelmValues: |\n  #   grafana.ini:\n  #     auth.anonymous:\n  #       enabled: true\n  #       org_role: Admin\n</code></pre> <p>The commented fields indicate how the observability stack can be customized, but that is outside the scope of this guide.  We're going to deploy it with the default settings.</p> <p>The only change you should make is to set the <code>KubernetesRuntimeInstance.Name</code> field.  Get the name of the K8s runtime instance/s you have available with this command:</p> <pre><code>tptctl get kubernetes-runtime-instances\n</code></pre>"},{"location":"observability/deploy-observability-local/#create-observability-stack","title":"Create Observability Stack","text":"<p>This command will create all the observability stack components:</p> <pre><code>tptctl create observability-stack --config observability-stack.yaml\n</code></pre> <p>Give Threeport a few minutes to get all the stack components up and running.</p> <p>You can use this kubectl command to determine when the observability dashboard is up and running.</p> <pre><code>kubectl get po -A -l app.kubernetes.io/name=grafana\n</code></pre> <p>When the output shows <code>STATUS: Running</code> like this, you can proceed.</p> <pre><code>NAMESPACE                                                  NAME                                                              READY   STATUS    RESTARTS   AGE\nobservability-observability-dashboard-grafana-dasjscmzhg   observability-observability-dashboard-grafana-release-6bf4ppg8g   3/3     Running   0          2m55s\n</code></pre>"},{"location":"observability/deploy-observability-local/#connect-to-the-dashboard","title":"Connect to the Dashboard","text":"<p>When running locally, you can connect to the observability dashboard as follows.</p> <p>First get the namespace for the dashboard:</p> <pre><code>DASHBOARD_NAMESPACE=$(kubectl get po -A -l app.kubernetes.io/name=grafana -o=jsonpath='{.items[0].metadata.namespace}')\n</code></pre> <p>Then, create a port forward to allow you to connect to the dashboard locally:</p> <pre><code>kubectl port-forward pod/$(kubectl get po -A -l app.kubernetes.io/name=grafana -o=jsonpath='{.items[0].metadata.name}') 3000:3000 -n $DASHBOARD_NAMESPACE\n</code></pre> <p>Now visit http://localhost:3000 in your browser.</p> <p>This should bring you to the Grafan login.  Enter <code>admin</code> for the username and <code>password</code> for the password.</p>"},{"location":"observability/deploy-observability-local/#metrics","title":"Metrics","text":"<p>On the left, click on the hamburger menu and navigate to <code>Dashboards</code> then <code>Kubernetes / Compute Resources / Pod</code>.</p> <p>At the top of the dashboard, you can select the namespace and pod for which to view metrics.</p> <p></p> <p>Select the namespace with the <code>wordpress-</code> prefeix and one of the pods for that application.  You can view CPU and memory usage, among other metrics, on this page for the workload.</p> <p>Click \"Home\" at the top-left of the screen.</p>"},{"location":"observability/deploy-observability-local/#logs","title":"Logs","text":"<p>To get logs for the WordPress app, click the hamburger menu next to \"Home\" at the top-left of the screen.  Then select Connections &gt; Data sources from the menu.</p> <p></p> <p>On the Data sources page, click \"Explore\" on the loki data source.</p> <p></p> <p>On the Explore page, under \"Label filters\" select \"pod\" from the \"Select label\" menu and select the \"getting-started-wordpress\" pod from the \"Select value\" menu.</p> <p></p> <p>Now, click the blue \"Run query\" button at the top-right of the screen.</p> <p></p> <p>You'll now be able to view the logs from the WordPress application.</p>"},{"location":"observability/deploy-observability-local/#remove-observability-stack","title":"Remove Observability Stack","text":"<p>You can now hit ctrl-c to on the port forward to terminate it.</p> <p>The observability stack can be uninstalled with the following command.</p> <pre><code>tptctl delete observability-stack --config observability-stack.yaml\n</code></pre>"},{"location":"observability/deploy-observability-local/#clean-up","title":"Clean Up","text":"<p>Finally, we can remove the files we downloaded.</p> <pre><code>cd ../\nrm -rf threeport-observability-test\n</code></pre>"},{"location":"observability/deploy-observability-local/#summary","title":"Summary","text":"<p>In this guide we walked through how to install the observability stack and then use the dashboard to get basic metrics and log output from the sample Wordpress application.</p>"},{"location":"observability/observability-intro/","title":"Observability","text":"<p>Threeport offers observability systems for your applications as a support service so that you can access metrics and logs for your workloads.</p> <p>Threeport uses Prometheus for metrics collection and alerting, Promtail for log forwarding, Loki for log storage and Grafana to access this info.</p>"},{"location":"observability/observability-intro/#observability-stack-definition","title":"Observability Stack Definition","text":"<p>This object defines the entire observability stack using the projects mentioned above.  They can be configured to your liking, however, the default values can be used to set up an observability stack without input values.</p> <p>Reference: ObservabilityStackDefinition</p>"},{"location":"observability/observability-intro/#observability-stack-instance","title":"Observability Stack Instance","text":"<p>When you create an instance, you can disable metrics or logging if you don't need one of them and you can specify the Kubernetes Runtime Instance you would like the observability stack deployed to.  Once deployed, all workload metrics and logs will be collected and made available to the user.</p> <p>Reference: ObservabilityStackInstance</p>"},{"location":"sdk/advanced-app-abstraction/","title":"Advanced Application Abstraction","text":"<p>Guide on using a Kubernetes operator to deploy K8s resources with a Go library to manage AWS resources using the AWS Go SDK V2.</p>"},{"location":"sdk/config-abstraction/","title":"Config Abstraction","text":"<p>Guide using helm and terraform to deploy app</p>"},{"location":"sdk/install/","title":"Install threeport-sdk","text":"<p>To install the Threeport SDK, visit the Threeport project's releases page on GitHub and download the checksums and tarball for your OS and architecture.</p> <p>Verify the downloaded file.</p> <pre><code>sha256sum -c --ignore-missing checksums.txt\n</code></pre> <p>Unpack and install.</p> <pre><code>tar xf [tarball filename]\nsudo mv [binary filename] /usr/local/bin/\n</code></pre> <p>Confirm version and view usage info.</p> <pre><code>threeport-sdk version\nthreeport-sdk help\n</code></pre>"},{"location":"sdk/install/#next-steps","title":"Next Steps","text":"<p>Next, check out our tutorial on using the SDK.</p>"},{"location":"sdk/sdk-intro/","title":"Threeport SDK Introduction","text":"<p>The Threeport SDK is a command line tool that enables software engineers to rapidly develop custom modules for Threeport.</p>"},{"location":"sdk/sdk-intro/#how-it-works","title":"How It Works","text":"<p>A software engineer uses the Threeport SDK to build modules that provide custom abstractions and functionality for their development teams to use.</p> <p>Once the requirements are well understood, the process to build a custom Threeport module is as follows:</p> <ol> <li>Initialize a Threeport module project. The engineer starts a new    project with its own git repo and uses the <code>threeport-sdk</code> CLI tool to    initialize the repository which scaffolds all the directories and code needed    to compile their software.</li> <li>Create one or more new API objects. The engineer designs a data    model based on module requirements and uses <code>threeport-sdk</code> to generate    its source code scaffolding. Then the engineer updates this code with fields    that define the object's attributes to meet the project's requirements.</li> <li>The generated scaffolding includes functions to add logic for    reconcilers that will manage the state of the new custom object. This    reconciliation logic will be compiled into one or more custom controllers    that will be added to the Threeport core system.</li> <li>The engineer then compiles the module's controller and API server into    binaries and builds container images using built-in utilities provided by    the SDK.</li> <li>The engineer deploys the custom module into a Threeport installation using    built-in utilities and makes it available for testing and feedback.</li> </ol> <p>Organizations that support open source and community engagement can make their modules publicly available in case they may be applicable to other use cases.</p>"},{"location":"sdk/sdk-intro/#next-steps","title":"Next Steps","text":"<p>Check out the SDK Tutorial to get started building with the Threeport SDK.</p>"},{"location":"sdk/tutorial/","title":"Threeport SDK Tutorial","text":"<p>The following tutorial walks through building a Threeport module for managing WordPress deployments.</p> <p>Note: This tutorial provides instructions to build a new Golang project from scratch.  If you'd like to skip to the end, the finished project can be viewed on GitHub.</p>"},{"location":"sdk/tutorial/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install threeport-sdk</li> <li>Install tptctl</li> <li>Install docker</li> <li>Install golang</li> <li>Install mage</li> </ul>"},{"location":"sdk/tutorial/#initialize-project","title":"Initialize Project","text":"<pre><code>mkdir wordpress-threeport-module\ncd wordpress-threeport-module\ngit init\ngo mod init wordpress-threeport-module\n</code></pre>"},{"location":"sdk/tutorial/#create-sdk-config","title":"Create SDK Config","text":"<p>Create a new file at the root of the repo called <code>sdk-config.yaml</code> with the following contents.  Replace the <code>ImageRepo</code> value for one that you have access to.</p> <pre><code>ModuleName: Wordpress\nApiNamespace: example.com\nApiDocs:\n  Title: WordPress Threeport API\n  Description: API server for the Threeport WordPress module.\n  ContactName: John Doe\n  ContactEmail: john@example.com\nImageRepo: ghcr.io/myorg/myimage\nApiObjectGroups:\n- Name: wordpress\n  Objects:\n    - Name: WordpressDefinition\n      Versions:\n        - v0\n      Reconcilable: true\n      Tptctl:\n        Enabled: true\n    - Name: WordpressInstance\n      Versions:\n        - v0\n      Reconcilable: true\n      Tptctl:\n        Enabled: true\n</code></pre>"},{"location":"sdk/tutorial/#define-api","title":"Define API","text":"<p>Use the Threeport SDK to create scaffolding for new API objects.  This will create a source code file for each API object group defined in the SDK config. In each source code file, an object that corresponds to a database table will be scaffolded.</p> <pre><code>threeport-sdk create --config sdk-config.yaml\n</code></pre> <p>For the SDK config shown above, it will create the following.</p> <pre><code>// originally generated by 'threeport-sdk create' for API object\n// scaffolding but will not be re-generated - intended for modification\n\npackage v0\n\nimport tpapi_v0 \"github.com/threeport/threeport/pkg/api/v0\"\n\ntype WordpressDefinition struct {\n    tpapi_v0.Common         `mapstructure:\",squash\" swaggerignore:\"true\"`\n    tpapi_v0.Reconciliation `mapstructure:\",squash\"`\n    tpapi_v0.Definition     `mapstructure:\",squash\"`\n    WordpressInstances      []*WordpressInstance `json:\"WordpressInstances,omitempty\" validate:\"optional,association\"`\n}\n\ntype WordpressInstance struct {\n    tpapi_v0.Common         `mapstructure:\",squash\" swaggerignore:\"true\"`\n    tpapi_v0.Reconciliation `mapstructure:\",squash\"`\n    tpapi_v0.Instance       `mapstructure:\",squash\"`\n    WordpressDefinitionID   *uint `gorm:\"not null\" json:\"WordpressDefinitionID,omitempty\" query:\"wordpressdefinitionid\" validate:\"required\"`\n}\n</code></pre> <p>This constitutes your Threeport module's data model. Add fields to these objects for config information that will need to be persisted.</p> <p>Add the following fields so that the file looks as follows when you are finished.</p> <pre><code>// originally generated by 'threeport-sdk create' for API object\n// scaffolding but will not be re-generated - intended for modification\n\npackage v0\n\nimport tpapi_v0 \"github.com/threeport/threeport/pkg/api/v0\"\n\ntype WordpressDefinition struct {\n    tpapi_v0.Common         `mapstructure:\",squash\" swaggerignore:\"true\"`\n    tpapi_v0.Reconciliation `mapstructure:\",squash\"`\n    tpapi_v0.Definition     `mapstructure:\",squash\"`\n\n    // The environment type used to determine config settings for a wordpress\n    // definition.\n    Environment *string `json:\"Environment,omitempty\" query:\"environment\" gorm:\"default:dev\" validate:\"optional\"`\n\n    // The number of pod replicas to deploy for the WordPress app\n    Replicas *int `json:\"Replicas,omitempty\" query:\"replicas\" validate:\"optional\"`\n\n    // If true, a cloud provider's managed database will be used for the\n    // WordPress DB.  If false, a containerized database will be deployed to\n    // Kubernetes.\n    ManagedDatabase *bool `json:\"ManagedDatabase,omitempty\" query:\"manageddatabase\" gorm:\"default:false\" validate:\"optional\"`\n\n    WordpressInstances []*WordpressInstance `json:\"WordpressInstances,omitempty\" validate:\"optional,association\"`\n}\n\ntype WordpressInstance struct {\n    tpapi_v0.Common         `mapstructure:\",squash\" swaggerignore:\"true\"`\n    tpapi_v0.Reconciliation `mapstructure:\",squash\"`\n    tpapi_v0.Instance       `mapstructure:\",squash\"`\n\n    // When using a DomainName, the subdomain to use to reach the WordPress\n    // instance.\n    SubDomain *string `jaon:\"SubDomain,omitempty\" query:\"subdomain\" validate:\"optional\"`\n\n    WordpressDefinitionID *uint `gorm:\"not null\" json:\"WordpressDefinitionID,omitempty\" query:\"wordpressdefinitionid\" validate:\"required\"`\n}\n</code></pre>"},{"location":"sdk/tutorial/#generate-source-code","title":"Generate Source Code","text":"<pre><code>threeport-sdk gen --config sdk-config.yaml\n</code></pre> <p>This will generate all the source code boilerplate and scaffolding needed for the project.</p>"},{"location":"sdk/tutorial/#add-controller-business-logic","title":"Add Controller Business Logic","text":"<p>The next step is to add the business logic for managing wordpress instances to the scaffolding for the wordpress controller.</p>"},{"location":"sdk/tutorial/#updates-to-internalwordpressv0_wordpress_definitiongo","title":"Updates to <code>internal/wordpress/v0_wordpress_definition.go</code>","text":"<p>The first file we will modify managed <code>WordpressDefinition</code> objects.  The file is located at <code>internal/wordpress/v0_wordpress_definition.go</code>.  If you open that file, you'll see functions to create, update and delete those objects.  These functions run when the corresponding actions are executed through the Threeport API.</p> <p>Now, let's update that file to insert some business logic.  In the following code snippet, is a new constant and the contents for the <code>v0WordpressDefinitionCreated</code> function.  Update your code to reflect these changes.</p> <pre><code>const wordpressDbConnSecretName = \"wordpress-db-conn\"\n\n// v0WordpressDefinitionCreated performs reconciliation when a v0 WordpressDefinition\n// has been created.\nfunc v0WordpressDefinitionCreated(\n    r *controller.Reconciler,\n    wordpressDefinition *v0.WordpressDefinition,\n    log *logr.Logger,\n) (int64, error) {\n    // set wordpress deployment replicas\n    var wordpressReplicas int\n    if wordpressDefinition.Replicas != nil {\n        wordpressReplicas = *wordpressDefinition.Replicas\n    } else {\n        wordpressReplicas = setWordpressReplicasByEnv(*wordpressDefinition.Environment)\n    }\n\n    // set wordpress DB storage volume size\n    wordpressDbStorageGb := setWordpressDbStorage(*wordpressDefinition.Environment)\n\n    // generate YAML manifest for wordpress app\n    yamlDoc, err := wordpressYaml(\n        *wordpressDefinition.Name,\n        wordpressReplicas,\n        *wordpressDefinition.Environment,\n        *wordpressDefinition.ManagedDatabase,\n        wordpressDbStorageGb,\n        wordpressDbConnSecretName,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to generate wordpress YAML manifest: %w\", err)\n    }\n\n    // create wordpress workload definition if it doesn't already exist\n    nameQuery := fmt.Sprintf(\"name=%s\", *wordpressDefinition.Name)\n    existingWorkloadDefinitions, err := tpclient.GetWorkloadDefinitionsByQueryString(\n        r.APIClient,\n        r.APIServer,\n        nameQuery,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to check for workload definitions with name %s: %w\", *wordpressDefinition.Name, err)\n    }\n    var createdWorkloadDefinition *tpapi.WorkloadDefinition\n    if len(*existingWorkloadDefinitions) == 0 {\n        workloadDefinition := tpapi.WorkloadDefinition{\n            Definition: tpapi.Definition{\n                Name: wordpressDefinition.Name,\n            },\n            YAMLDocument: &amp;yamlDoc,\n        }\n        createdWorkloadDef, err := tpclient.CreateWorkloadDefinition(\n            r.APIClient,\n            r.APIServer,\n            &amp;workloadDefinition,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create Threeport workload definition: %w\", err)\n        }\n        createdWorkloadDefinition = createdWorkloadDef\n    } else {\n        createdWorkloadDefinition = &amp;(*existingWorkloadDefinitions)[0]\n    }\n\n    // establish attachment between wordpress definition and workload definition\n    if err := tpclient.EnsureAttachedObjectReferenceExists(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadDefinition,\n        createdWorkloadDefinition.ID,\n        v0.ObjectTypeWordpressDefinition,\n        wordpressDefinition.ID,\n    ); err != nil {\n        return 0, fmt.Errorf(\"failed to attach wordpress definition to workload definition: %w\", err)\n    }\n\n    // create relational database definition if requested\n    if *wordpressDefinition.ManagedDatabase {\n        storageGb := setWordpressDbStorage(*wordpressDefinition.Environment)\n        var backupDays int\n        var machineSize string\n        switch *wordpressDefinition.Environment {\n        case \"prod\":\n            backupDays = 30\n            machineSize = \"Large\"\n        default:\n            backupDays = 0\n            machineSize = \"XSmall\"\n        }\n        // get AWS account ID\n        awsAccountId, err := tpclient.GetObjectIdByAttachedObject(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeAwsAccount,\n            v0.ObjectTypeWordpressDefinition,\n            *wordpressDefinition.ID,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to get attached AWS account ID: %w\", err)\n        }\n        // construct relational database definition\n        awsRdsDefinition := tpapi.AwsRelationalDatabaseDefinition{\n            Definition: tpapi.Definition{\n                Name: wordpressDefinition.Name,\n            },\n            Engine:             util.Ptr(\"mariadb\"),\n            EngineVersion:      util.Ptr(\"10.11\"),\n            DatabaseName:       util.Ptr(\"wordpress\"),\n            DatabasePort:       util.Ptr(3306),\n            BackupDays:         util.Ptr(backupDays),\n            StorageGb:          util.Ptr(storageGb),\n            MachineSize:        util.Ptr(machineSize),\n            WorkloadSecretName: util.Ptr(wordpressDbConnSecretName),\n            AwsAccountID:       awsAccountId,\n        }\n        // create releational database definition\n        createdAwsRdsDefinition, err := tpclient.CreateAwsRelationalDatabaseDefinition(\n            r.APIClient,\n            r.APIServer,\n            &amp;awsRdsDefinition,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create AWS relational database definition: %w\", err)\n        }\n        // establish attachment between wordpress definition and relational\n        // database definition\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeAwsRelationalDatabaseDefinition,\n            createdAwsRdsDefinition.ID,\n            v0.ObjectTypeWordpressDefinition,\n            wordpressDefinition.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to attach wordpress definition to AWS relational database definition: %w\", err)\n        }\n    }\n\n    return 0, nil\n}\n</code></pre> <p>Now, let's update the <code>v0WordpressDefinitionDeleted</code> function with the code shown below.</p> <pre><code>// v0WordpressDefinitionDeleted performs reconciliation when a v0 WordpressDefinition\n// has been deleted.\nfunc v0WordpressDefinitionDeleted(\n    r *controller.Reconciler,\n    wordpressDefinition *v0.WordpressDefinition,\n    log *logr.Logger,\n) (int64, error) {\n    // get attached workload definition\n    workloadDefinitionId, err := tpclient.GetObjectIdByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadDefinition,\n        v0.ObjectTypeWordpressDefinition,\n        *wordpressDefinition.ID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to find attached workload definition: %w\", err)\n    }\n\n    // delete workload definition\n    _, err = tpclient.DeleteWorkloadDefinition(\n        r.APIClient,\n        r.APIServer,\n        *workloadDefinitionId,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to delete workload definition: %w\", err)\n    }\n\n    // remove workload definition attachment\n    if err := tpclient.EnsureAttachedObjectReferenceRemoved(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadDefinition,\n        workloadDefinitionId,\n        v0.ObjectTypeWordpressDefinition,\n        wordpressDefinition.ID,\n    ); err != nil {\n        return 0, fmt.Errorf(\"failed to remove attachment to deleted workload definition: %w\", err)\n    }\n\n    // delete relational database definition if it exists\n    awsRdsDefinitionIds, err := tpclient.GetObjectIdsByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeAwsRelationalDatabaseDefinition,\n        v0.ObjectTypeWordpressDefinition,\n        *wordpressDefinition.ID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get attached AWS relational database definition IDs: %w\", err)\n    }\n    for _, awsRdsDefinitionId := range awsRdsDefinitionIds {\n        _, err := tpclient.DeleteGatewayInstance(\n            r.APIClient,\n            r.APIServer,\n            *awsRdsDefinitionId,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to delete AWS relational database definition with ID %d: %w\", *awsRdsDefinitionId, err)\n        }\n        if err := tpclient.EnsureAttachedObjectReferenceRemoved(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeGatewayDefinition,\n            awsRdsDefinitionId,\n            v0.ObjectTypeWordpressDefinition,\n            wordpressDefinition.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to remove wordpress definition attachment to deleted AWS relational database definition: %w\", err)\n        }\n    }\n\n    return 0, nil\n}\n</code></pre> <p>Lastly, add these two functions at the end of that file.</p> <pre><code>// setWordpressReplicasByEnv sets default replicas for the Wordpress deployment\n// based on the environment value.\nfunc setWordpressReplicasByEnv(env string) int {\n    switch env {\n    case \"prod\":\n        return 5\n    default:\n        return 2\n    }\n}\n\n// setWordpressDbStorage sets the database storage volume size.\nfunc setWordpressDbStorage(env string) int {\n    switch env {\n    case \"prod\":\n        return 100\n    default:\n        return 20\n    }\n}\n</code></pre> <p>Ensure the following imports are included in this file.</p> <pre><code>import (\n    \"fmt\"\n\n    logr \"github.com/go-logr/logr\"\n    tpapi \"github.com/threeport/threeport/pkg/api/v0\"\n    tpclient \"github.com/threeport/threeport/pkg/client/v0\"\n    controller \"github.com/threeport/threeport/pkg/controller/v0\"\n    util \"github.com/threeport/threeport/pkg/util/v0\"\n\n    v0 \"wordpress-threeport-module/pkg/api/v0\"\n)\n</code></pre>"},{"location":"sdk/tutorial/#updates-to-internalwordpressv0_wordpress_instancego","title":"Updates to <code>internal/wordpress/v0_wordpress_instance.go</code>","text":"<p>Lastly, let's add the operations to mange <code>WordpressInstance</code> objects.  The scaffolding for this is in <code>internal/wordpress/v0_wordpress_instance.go</code>.  If you open that file, you'll see empty functions to create, update and delete these objects.  Again, when actions are executed through the Threeport API, these functions will be called to reconcile the desired operations.</p> <p>Update the <code>v0WordpressInstanceCreated</code> function as shown below.</p> <pre><code>// v0WordpressInstanceCreated performs reconciliation when a v0 WordpressInstance\n// has been created.\nfunc v0WordpressInstanceCreated(\n    r *controller.Reconciler,\n    wordpressInstance *v0.WordpressInstance,\n    log *logr.Logger,\n) (int64, error) {\n    // get attached Kubernetes runtime instance ID\n    kubernetesRuntimeInstanceId, err := tpclient.GetObjectIdByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeKubernetesRuntimeInstance,\n        v0.ObjectTypeWordpressInstance,\n        *wordpressInstance.ID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get Kubernetes runtime instance by attachment: %w\", err)\n    }\n\n    // get workload definition attached to wordpress definition\n    workloadDefinitionId, err := tpclient.GetObjectIdByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadDefinition,\n        v0.ObjectTypeWordpressDefinition,\n        *wordpressInstance.WordpressDefinitionID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get workload definition by attachment: %w\", err)\n    }\n\n    // create workload instance if it doesn't already exist\n    nameQuery := fmt.Sprintf(\"name=%s\", *wordpressInstance.Name)\n    existingWorkloadInstances, err := tpclient.GetWorkloadInstancesByQueryString(\n        r.APIClient,\n        r.APIServer,\n        nameQuery,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to check for workload instance with name %s: %w\", *wordpressInstance.Name, err)\n    }\n    var createdWorkloadInstance *tpapi.WorkloadInstance\n    if len(*existingWorkloadInstances) == 0 {\n        workloadInstance := tpapi.WorkloadInstance{\n            Instance: tpapi.Instance{\n                Name: wordpressInstance.Name,\n            },\n            KubernetesRuntimeInstanceID: kubernetesRuntimeInstanceId,\n            WorkloadDefinitionID:        workloadDefinitionId,\n        }\n        createdWorkloadInst, err := tpclient.CreateWorkloadInstance(\n            r.APIClient,\n            r.APIServer,\n            &amp;workloadInstance,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create workload instance: %w\", err)\n        }\n        createdWorkloadInstance = createdWorkloadInst\n    }\n\n    // establish attachment between wordpress instance and workload instance\n    if err := tpclient.EnsureAttachedObjectReferenceExists(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadInstance,\n        createdWorkloadInstance.ID,\n        v0.ObjectTypeWordpressInstance,\n        wordpressInstance.ID,\n    ); err != nil {\n        return 0, fmt.Errorf(\"failed to attach wordpress instance to workload instance: %w\", err)\n    }\n\n    // get wordpress definition\n    wordpressDefinition, err := client.GetWordpressDefinitionByID(\n        r.APIClient,\n        r.APIServer,\n        *wordpressInstance.WordpressDefinitionID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get wordpress definition: %w\", err)\n    }\n\n    // get infra provider for kubernetes runtime - needed to determine storage\n    // class for wordpress PVC\n    infraProvider, err := tpclient.GetInfraProviderByKubernetesRuntimeInstanceID(\n        r.APIClient,\n        r.APIServer,\n        kubernetesRuntimeInstanceId,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to determine infra provider for Kubernetes runtime: %w\", err)\n    }\n\n    // get the manifest for the PVC\n    pvcManifest, err := getPvcManifest(\n        *infraProvider,\n        *wordpressDefinition.Name,\n        *wordpressDefinition.Environment,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get Kubernetes manifest for persistent volume claim: %w\", err)\n    }\n\n    // create the workload resource instance for the PVC\n    pvcWri := tpapi.WorkloadResourceInstance{\n        JSONDefinition:     pvcManifest,\n        WorkloadInstanceID: createdWorkloadInstance.ID,\n    }\n    _, err = tpclient.CreateWorkloadResourceInstance(\n        r.APIClient,\n        r.APIServer,\n        &amp;pvcWri,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to create workload resource instance for persistent volume claim: %w\", err)\n    }\n\n    // trigger reconciliation to create the PVC\n    unreconciledWorkloadInstance := tpapi.WorkloadInstance{\n        Common: tpapi.Common{\n            ID: createdWorkloadInstance.ID,\n        },\n        Reconciliation: tpapi.Reconciliation{\n            Reconciled: util.Ptr(false),\n        },\n    }\n    _, err = tpclient.UpdateWorkloadInstance(\n        r.APIClient,\n        r.APIServer,\n        &amp;unreconciledWorkloadInstance,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to update workload instance as unreconciled: %w\", err)\n    }\n\n    // create relational database instance if requested\n    if *wordpressDefinition.ManagedDatabase {\n        // get relational database definition ID\n        awsRdsDefinitionId, err := tpclient.GetObjectIdByAttachedObject(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeAwsRelationalDatabaseDefinition,\n            v0.ObjectTypeWordpressDefinition,\n            *wordpressDefinition.ID,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to get AWS relational database definition ID by attachment: %w\", err)\n        }\n        // construct relational database instance\n        awsRdsInstance := tpapi.AwsRelationalDatabaseInstance{\n            Instance: tpapi.Instance{\n                Name: wordpressInstance.Name,\n            },\n            AwsRelationalDatabaseDefinitionID: awsRdsDefinitionId,\n            WorkloadInstanceID:                createdWorkloadInstance.ID,\n        }\n        // create relational database instance\n        createdRdsInstance, err := tpclient.CreateAwsRelationalDatabaseInstance(\n            r.APIClient,\n            r.APIServer,\n            &amp;awsRdsInstance,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create AWS relational database instance: %w\", err)\n        }\n        // establish attachment between wordpress instance and relational\n        // database instance\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeAwsRelationalDatabaseInstance,\n            createdRdsInstance.ID,\n            v0.ObjectTypeWordpressInstance,\n            wordpressInstance.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to attach wordpress instance to AWS relational database instance: %w\", err)\n        }\n    }\n\n    // create gateway and subdomain DNS record if requested\n    if wordpressInstance.SubDomain != nil &amp;&amp; *wordpressInstance.SubDomain != \"\" {\n        // get attached domain name definition ID\n        domainNameDefinitionId, err := tpclient.GetObjectIdByAttachedObject(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeDomainNameDefinition,\n            v0.ObjectTypeWordpressDefinition,\n            *wordpressDefinition.ID,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to get attached domain name definition: %w\", err)\n        }\n        // contruct gateway definition object\n        gatewayDefinition := tpapi.GatewayDefinition{\n            Definition: tpapi.Definition{\n                Name: util.Ptr(\"web-service-gateway\"),\n            },\n            HttpPorts: []*tpapi.GatewayHttpPort{\n                {\n                    Port:          util.Ptr(80),\n                    Path:          util.Ptr(\"/\"),\n                    HTTPSRedirect: util.Ptr(true),\n                }, {\n                    Port:       util.Ptr(443),\n                    Path:       util.Ptr(\"/\"),\n                    TLSEnabled: util.Ptr(true),\n                },\n            },\n            DomainNameDefinitionID: domainNameDefinitionId,\n            SubDomain:              wordpressInstance.SubDomain,\n            ServiceName:            util.Ptr(getWordpressServiceName(*wordpressDefinition.Name)),\n            WorkloadDefinitionID:   workloadDefinitionId,\n        }\n        // create gateway definition\n        createdGatewayDefinition, err := tpclient.CreateGatewayDefinition(\n            r.APIClient,\n            r.APIServer,\n            &amp;gatewayDefinition,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create gateway definition: %w\", err)\n        }\n        // construct gateway instance\n        gatewayInstance := tpapi.GatewayInstance{\n            Instance: tpapi.Instance{\n                Name: util.Ptr(fmt.Sprintf(\"%s-gateway\", *wordpressInstance.Name)),\n            },\n            KubernetesRuntimeInstanceID: kubernetesRuntimeInstanceId,\n            GatewayDefinitionID:         createdGatewayDefinition.ID,\n            WorkloadInstanceID:          createdWorkloadInstance.ID,\n        }\n        // created gateway instance\n        createdGatewayInstance, err := tpclient.CreateGatewayInstance(\n            r.APIClient,\n            r.APIServer,\n            &amp;gatewayInstance,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create gateway instance: %w\", err)\n        }\n        // create attachment between gateway instance and wordpress instance\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeGatewayInstance,\n            createdGatewayInstance.ID,\n            v0.ObjectTypeWordpressInstance,\n            wordpressInstance.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to create attachment between wordpress instance and gateway instance: %w\", err)\n        }\n        // construct domain name instance\n        domainNameInstance := tpapi.DomainNameInstance{\n            Instance: tpapi.Instance{\n                Name: util.Ptr(fmt.Sprintf(\"%s-domain-name\", *wordpressInstance.Name)),\n            },\n            DomainNameDefinitionID:      domainNameDefinitionId,\n            WorkloadInstanceID:          createdWorkloadInstance.ID,\n            KubernetesRuntimeInstanceID: kubernetesRuntimeInstanceId,\n        }\n        // create domain name instance\n        createdDomainNameInstance, err := tpclient.CreateDomainNameInstance(\n            r.APIClient,\n            r.APIServer,\n            &amp;domainNameInstance,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to create domain name instance: %w\", err)\n        }\n        // create attachment between domain name instance and wordpress instance\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeDomainNameInstance,\n            createdDomainNameInstance.ID,\n            v0.ObjectTypeWordpressInstance,\n            wordpressInstance.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to create attachment between wordpress instance and domain name instance: %w\", err)\n        }\n    }\n\n    return 0, nil\n}\n</code></pre> <p>Now, update the <code>v0WordpressInstanceDeleted</code> function with the code below.</p> <pre><code>// v0WordpressInstanceDeleted performs reconciliation when a v0 WordpressInstance\n// has been deleted.\nfunc v0WordpressInstanceDeleted(\n    r *controller.Reconciler,\n    wordpressInstance *v0.WordpressInstance,\n    log *logr.Logger,\n) (int64, error) {\n    // get attached workload instance\n    workloadInstanceId, err := tpclient.GetObjectIdByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadInstance,\n        v0.ObjectTypeWordpressInstance,\n        *wordpressInstance.ID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to find attached workload instance: %w\", err)\n    }\n\n    // delete workload instance\n    _, err = tpclient.DeleteWorkloadInstance(\n        r.APIClient,\n        r.APIServer,\n        *workloadInstanceId,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to delete workload instance: %w\", err)\n    }\n\n    // remove workload instance attachment\n    if err := tpclient.EnsureAttachedObjectReferenceRemoved(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeWorkloadInstance,\n        workloadInstanceId,\n        v0.ObjectTypeWordpressInstance,\n        wordpressInstance.ID,\n    ); err != nil {\n        return 0, fmt.Errorf(\"failed to remove attachment to deleted workload instance: %w\", err)\n    }\n\n    // delete relational database instance if it exists\n    awsRdsInstanceIds, err := tpclient.GetObjectIdsByAttachedObject(\n        r.APIClient,\n        r.APIServer,\n        tpapi.ObjectTypeAwsRelationalDatabaseInstance,\n        v0.ObjectTypeWordpressInstance,\n        *wordpressInstance.ID,\n    )\n    if err != nil {\n        return 0, fmt.Errorf(\"failed to get attached relational database IDs: %w\", err)\n    }\n    for _, rdsInstanceId := range awsRdsInstanceIds {\n        _, err := tpclient.DeleteAwsRelationalDatabaseInstance(\n            r.APIClient,\n            r.APIServer,\n            *rdsInstanceId,\n        )\n        if err != nil {\n            return 0, fmt.Errorf(\"failed to delete AWS RDS instance with id %d: %w\", *rdsInstanceId, err)\n        }\n        if err := tpclient.EnsureAttachedObjectReferenceRemoved(\n            r.APIClient,\n            r.APIServer,\n            tpapi.ObjectTypeAwsRelationalDatabaseInstance,\n            rdsInstanceId,\n            v0.ObjectTypeWordpressInstance,\n            wordpressInstance.ID,\n        ); err != nil {\n            return 0, fmt.Errorf(\"failed to remove attachment to deleted AWS relational database instance: %w\", err)\n        }\n    }\n\n    return 0, nil\n}\n</code></pre> <p>Ensure the following imports are included in this file.</p> <pre><code>import (\n    \"fmt\"\n\n    logr \"github.com/go-logr/logr\"\n    tpapi \"github.com/threeport/threeport/pkg/api/v0\"\n    tpclient \"github.com/threeport/threeport/pkg/client/v0\"\n    controller \"github.com/threeport/threeport/pkg/controller/v0\"\n    util \"github.com/threeport/threeport/pkg/util/v0\"\n\n    v0 \"wordpress-threeport-module/pkg/api/v0\"\n    client \"wordpress-threeport-module/pkg/client/v0\"\n)\n</code></pre>"},{"location":"sdk/tutorial/#add-internalwordpresswordpress_manifestgo","title":"Add <code>internal/wordpress/wordpress_manifest.go</code>","text":"<p>The updates we've made so far reference some functions that don't exist yet. These functions define the Kubernetes configurations for the WordPress workloads and set the variables needed for different install options.</p> <p>Add a new file <code>internal/wordpress/wordpress_manifest.go</code> with the following contents.</p> <pre><code>package wordpress\n\nimport (\n    \"errors\"\n    \"fmt\"\n\n    tpapi \"github.com/threeport/threeport/pkg/api/v0\"\n    kube \"github.com/threeport/threeport/pkg/kube/v0\"\n    util \"github.com/threeport/threeport/pkg/util/v0\"\n    \"gorm.io/datatypes\"\n    \"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured\"\n)\n\n// wordpressYaml returns a YAML manifest for the wordpress workload.\nfunc wordpressYaml(\n    definitionName string,\n    wordpressReplicas int,\n    environment string,\n    managedDatabase bool,\n    dbStorageGb int,\n    dbConnectionSecret string,\n) (string, error) {\n    var yamlDoc string\n\n    if !managedDatabase {\n        var unmanagedDbYamlDoc string\n\n        var serviceAccountMariadb = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"v1\",\n                \"kind\":       \"ServiceAccount\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"mariadb\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"automountServiceAccountToken\": false,\n            },\n        }\n        unmanagedDbYamlDoc, err := kube.AppendObjectToYamlDoc(serviceAccountMariadb, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        var secretMariadb = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"v1\",\n                \"kind\":       \"Secret\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"mariadb\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"type\": \"Opaque\",\n                \"data\": map[string]interface{}{\n                    \"mariadb-root-password\": \"WHZOWUhMZ3RFUw==\",\n                    \"mariadb-password\":      \"VHlycG1KVDVPTg==\",\n                },\n            },\n        }\n        unmanagedDbYamlDoc, err = kube.AppendObjectToYamlDoc(secretMariadb, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        var configMapMariadb = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"v1\",\n                \"kind\":       \"ConfigMap\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"mariadb\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"app.kubernetes.io/component\":  \"primary\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"data\": map[string]interface{}{\n                    \"my.cnf\": `[mysqld]\nskip-name-resolve\nexplicit_defaults_for_timestamp\nbasedir=/opt/bitnami/mariadb\nplugin_dir=/opt/bitnami/mariadb/plugin\nport=3306\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\ntmpdir=/opt/bitnami/mariadb/tmp\nmax_allowed_packet=16M\nbind-address=*\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid\nlog-error=/opt/bitnami/mariadb/logs/mysqld.log\ncharacter-set-server=UTF8\ncollation-server=utf8_general_ci\nslow_query_log=0\nslow_query_log_file=/opt/bitnami/mariadb/logs/mysqld.log\nlong_query_time=10.0\n\n[client]\nport=3306\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\ndefault-character-set=UTF8\nplugin_dir=/opt/bitnami/mariadb/plugin\n\n[manager]\nport=3306\nsocket=/opt/bitnami/mariadb/tmp/mysql.sock\npid-file=/opt/bitnami/mariadb/tmp/mysqld.pid`,\n                },\n            },\n        }\n        unmanagedDbYamlDoc, err = kube.AppendObjectToYamlDoc(configMapMariadb, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        var serviceMariadb = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"v1\",\n                \"kind\":       \"Service\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"mariadb\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"app.kubernetes.io/component\":  \"primary\",\n                        \"environment\":                  environment,\n                    },\n                    \"annotations\": nil,\n                },\n                \"spec\": map[string]interface{}{\n                    \"type\":            \"ClusterIP\",\n                    \"sessionAffinity\": \"None\",\n                    \"ports\": []interface{}{\n                        map[string]interface{}{\n                            \"name\":       \"mysql\",\n                            \"port\":       3306,\n                            \"protocol\":   \"TCP\",\n                            \"targetPort\": \"mysql\",\n                            \"nodePort\":   nil,\n                        },\n                    },\n                    \"selector\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":      \"mariadb\",\n                        \"app.kubernetes.io/instance\":  definitionName,\n                        \"app.kubernetes.io/component\": \"primary\",\n                    },\n                },\n            },\n        }\n        unmanagedDbYamlDoc, err = kube.AppendObjectToYamlDoc(serviceMariadb, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        var statefulSetMariadb = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"apps/v1\",\n                \"kind\":       \"StatefulSet\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"mariadb\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"app.kubernetes.io/component\":  \"primary\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"spec\": map[string]interface{}{\n                    \"replicas\":             1,\n                    \"revisionHistoryLimit\": 10,\n                    \"selector\": map[string]interface{}{\n                        \"matchLabels\": map[string]interface{}{\n                            \"app.kubernetes.io/name\":      \"mariadb\",\n                            \"app.kubernetes.io/instance\":  definitionName,\n                            \"app.kubernetes.io/component\": \"primary\",\n                        },\n                    },\n                    \"serviceName\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                    \"updateStrategy\": map[string]interface{}{\n                        \"type\": \"RollingUpdate\",\n                    },\n                    \"template\": map[string]interface{}{\n                        \"metadata\": map[string]interface{}{\n                            \"annotations\": map[string]interface{}{\n                                \"checksum/configuration\": \"abe9c954f29a801817e9c9bae83f5353a24b42f21603fd18da496edd12991d82\",\n                            },\n                            \"labels\": map[string]interface{}{\n                                \"app.kubernetes.io/name\":       \"mariadb\",\n                                \"app.kubernetes.io/instance\":   definitionName,\n                                \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                                \"app.kubernetes.io/component\":  \"primary\",\n                                \"environment\":                  environment,\n                            },\n                        },\n                        \"spec\": map[string]interface{}{\n                            \"serviceAccountName\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                            \"affinity\": map[string]interface{}{\n                                \"podAffinity\": nil,\n                                \"podAntiAffinity\": map[string]interface{}{\n                                    \"preferredDuringSchedulingIgnoredDuringExecution\": []interface{}{\n                                        map[string]interface{}{\n                                            \"podAffinityTerm\": map[string]interface{}{\n                                                \"labelSelector\": map[string]interface{}{\n                                                    \"matchLabels\": map[string]interface{}{\n                                                        \"app.kubernetes.io/name\":      \"mariadb\",\n                                                        \"app.kubernetes.io/instance\":  definitionName,\n                                                        \"app.kubernetes.io/component\": \"primary\",\n                                                    },\n                                                },\n                                                \"topologyKey\": \"kubernetes.io/hostname\",\n                                            },\n                                            \"weight\": 1,\n                                        },\n                                    },\n                                },\n                                \"nodeAffinity\": nil,\n                            },\n                            \"securityContext\": map[string]interface{}{\n                                \"fsGroup\": 1001,\n                            },\n                            \"containers\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\":            \"mariadb\",\n                                    \"image\":           \"docker.io/bitnami/mariadb:10.11.3-debian-11-r0\",\n                                    \"imagePullPolicy\": \"IfNotPresent\",\n                                    \"securityContext\": map[string]interface{}{\n                                        \"allowPrivilegeEscalation\": false,\n                                        \"privileged\":               false,\n                                        \"runAsNonRoot\":             true,\n                                        \"runAsUser\":                1001,\n                                    },\n                                    \"env\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":  \"BITNAMI_DEBUG\",\n                                            \"value\": \"false\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"MARIADB_ROOT_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                                                    \"key\":  \"mariadb-root-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"MARIADB_USER\",\n                                            \"value\": \"bn_wordpress\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"MARIADB_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                                                    \"key\":  \"mariadb-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"MARIADB_DATABASE\",\n                                            \"value\": \"bitnami_wordpress\",\n                                        },\n                                    },\n                                    \"ports\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":          \"mysql\",\n                                            \"containerPort\": 3306,\n                                        },\n                                    },\n                                    \"livenessProbe\": map[string]interface{}{\n                                        \"failureThreshold\":    3,\n                                        \"initialDelaySeconds\": 120,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      1,\n                                        \"exec\": map[string]interface{}{\n                                            \"command\": []interface{}{\n                                                \"/bin/bash\",\n                                                \"-ec\",\n                                                `password_aux=\"${MARIADB_ROOT_PASSWORD:-}\"\nif [[ -f \"${MARIADB_ROOT_PASSWORD_FILE:-}\" ]]; then\n    password_aux=$(cat \"$MARIADB_ROOT_PASSWORD_FILE\")\nfi\nmysqladmin status -uroot -p\"${password_aux}\"\n`,\n                                            },\n                                        },\n                                    },\n                                    \"readinessProbe\": map[string]interface{}{\n                                        \"failureThreshold\":    3,\n                                        \"initialDelaySeconds\": 30,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      1,\n                                        \"exec\": map[string]interface{}{\n                                            \"command\": []interface{}{\n                                                \"/bin/bash\",\n                                                \"-ec\",\n                                                `password_aux=\"${MARIADB_ROOT_PASSWORD:-}\"\nif [[ -f \"${MARIADB_ROOT_PASSWORD_FILE:-}\" ]]; then\n    password_aux=$(cat \"$MARIADB_ROOT_PASSWORD_FILE\")\nfi\nmysqladmin status -uroot -p\"${password_aux}\"\n`,\n                                            },\n                                        },\n                                    },\n                                    \"resources\": map[string]interface{}{\n                                        \"limits\":   map[string]interface{}{},\n                                        \"requests\": map[string]interface{}{},\n                                    },\n                                    \"volumeMounts\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":      \"data\",\n                                            \"mountPath\": \"/bitnami/mariadb\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":      \"config\",\n                                            \"mountPath\": \"/opt/bitnami/mariadb/conf/my.cnf\",\n                                            \"subPath\":   \"my.cnf\",\n                                        },\n                                    },\n                                },\n                            },\n                            \"volumes\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\": \"config\",\n                                    \"configMap\": map[string]interface{}{\n                                        \"name\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                                    },\n                                },\n                            },\n                        },\n                    },\n                    \"volumeClaimTemplates\": []interface{}{\n                        map[string]interface{}{\n                            \"metadata\": map[string]interface{}{\n                                \"name\": \"data\",\n                                \"labels\": map[string]interface{}{\n                                    \"app.kubernetes.io/name\":      \"mariadb\",\n                                    \"app.kubernetes.io/instance\":  definitionName,\n                                    \"app.kubernetes.io/component\": \"primary\",\n                                    \"environment\":                 environment,\n                                },\n                            },\n                            \"spec\": map[string]interface{}{\n                                \"accessModes\": []interface{}{\n                                    \"ReadWriteOnce\",\n                                },\n                                \"resources\": map[string]interface{}{\n                                    \"requests\": map[string]interface{}{\n                                        \"storage\": fmt.Sprintf(\"%dGi\", dbStorageGb),\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n        unmanagedDbYamlDoc, err = kube.AppendObjectToYamlDoc(statefulSetMariadb, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        var deploymentWordpress = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"apps/v1\",\n                \"kind\":       \"Deployment\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-wordpress\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"wordpress\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"spec\": map[string]interface{}{\n                    \"selector\": map[string]interface{}{\n                        \"matchLabels\": map[string]interface{}{\n                            \"app.kubernetes.io/name\":     \"wordpress\",\n                            \"app.kubernetes.io/instance\": definitionName,\n                        },\n                    },\n                    \"strategy\": map[string]interface{}{\n                        \"type\": \"RollingUpdate\",\n                    },\n                    \"replicas\": wordpressReplicas,\n                    \"template\": map[string]interface{}{\n                        \"metadata\": map[string]interface{}{\n                            \"labels\": map[string]interface{}{\n                                \"app.kubernetes.io/name\":       \"wordpress\",\n                                \"app.kubernetes.io/instance\":   definitionName,\n                                \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                                \"environment\":                  environment,\n                            },\n                        },\n                        \"spec\": map[string]interface{}{\n                            // yamllint disable rule:indentation\n                            \"hostAliases\": []interface{}{\n                                map[string]interface{}{\n                                    \"hostnames\": []interface{}{\n                                        \"status.localhost\",\n                                    },\n                                    \"ip\": \"127.0.0.1\",\n                                },\n                            },\n                            // yamllint enable rule:indentation\n                            \"affinity\": map[string]interface{}{\n                                \"podAffinity\": nil,\n                                \"podAntiAffinity\": map[string]interface{}{\n                                    \"preferredDuringSchedulingIgnoredDuringExecution\": []interface{}{\n                                        map[string]interface{}{\n                                            \"podAffinityTerm\": map[string]interface{}{\n                                                \"labelSelector\": map[string]interface{}{\n                                                    \"matchLabels\": map[string]interface{}{\n                                                        \"app.kubernetes.io/name\":     \"wordpress\",\n                                                        \"app.kubernetes.io/instance\": definitionName,\n                                                    },\n                                                },\n                                                \"topologyKey\": \"kubernetes.io/hostname\",\n                                            },\n                                            \"weight\": 1,\n                                        },\n                                    },\n                                },\n                                \"nodeAffinity\": nil,\n                            },\n                            \"securityContext\": map[string]interface{}{\n                                \"fsGroup\": 1001,\n                                \"seccompProfile\": map[string]interface{}{\n                                    \"type\": \"RuntimeDefault\",\n                                },\n                            },\n                            \"serviceAccountName\": \"default\",\n                            \"containers\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\":            \"wordpress\",\n                                    \"image\":           \"docker.io/bitnami/wordpress:6.2.0-debian-11-r22\",\n                                    \"imagePullPolicy\": \"IfNotPresent\",\n                                    \"securityContext\": map[string]interface{}{\n                                        \"allowPrivilegeEscalation\": false,\n                                        \"capabilities\": map[string]interface{}{\n                                            \"drop\": []interface{}{\n                                                \"ALL\",\n                                            },\n                                        },\n                                        \"runAsNonRoot\": true,\n                                        \"runAsUser\":    1001,\n                                    },\n                                    \"env\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":  \"BITNAMI_DEBUG\",\n                                            \"value\": \"false\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"ALLOW_EMPTY_PASSWORD\",\n                                            \"value\": \"yes\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"MARIADB_HOST\",\n                                            \"value\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"MARIADB_PORT_NUMBER\",\n                                            \"value\": \"3306\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_DATABASE_NAME\",\n                                            \"value\": \"bitnami_wordpress\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_DATABASE_USER\",\n                                            \"value\": \"bn_wordpress\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_DATABASE_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": fmt.Sprintf(\"%s-mariadb\", definitionName),\n                                                    \"key\":  \"mariadb-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_USERNAME\",\n                                            \"value\": \"user\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": fmt.Sprintf(\"%s-wordpress\", definitionName),\n                                                    \"key\":  \"wordpress-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_EMAIL\",\n                                            \"value\": \"user@example.com\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_FIRST_NAME\",\n                                            \"value\": \"FirstName\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_LAST_NAME\",\n                                            \"value\": \"LastName\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_HTACCESS_OVERRIDE_NONE\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_ENABLE_HTACCESS_PERSISTENCE\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_BLOG_NAME\",\n                                            \"value\": \"User's Blog!\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_SKIP_BOOTSTRAP\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_TABLE_PREFIX\",\n                                            \"value\": \"wp_\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_SCHEME\",\n                                            \"value\": \"http\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_EXTRA_WP_CONFIG_CONTENT\",\n                                            \"value\": \"\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_PLUGINS\",\n                                            \"value\": \"none\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"APACHE_HTTP_PORT_NUMBER\",\n                                            \"value\": \"8080\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"APACHE_HTTPS_PORT_NUMBER\",\n                                            \"value\": \"8443\",\n                                        },\n                                    },\n                                    \"envFrom\": nil,\n                                    \"ports\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":          \"http\",\n                                            \"containerPort\": 8080,\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":          \"https\",\n                                            \"containerPort\": 8443,\n                                        },\n                                    },\n                                    \"livenessProbe\": map[string]interface{}{\n                                        \"failureThreshold\": 6,\n                                        \"httpGet\": map[string]interface{}{\n                                            \"httpHeaders\": []interface{}{},\n                                            \"path\":        \"/wp-admin/install.php\",\n                                            \"port\":        \"http\",\n                                            \"scheme\":      \"HTTP\",\n                                        },\n                                        \"initialDelaySeconds\": 120,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      5,\n                                    },\n                                    \"readinessProbe\": map[string]interface{}{\n                                        \"failureThreshold\": 6,\n                                        \"httpGet\": map[string]interface{}{\n                                            \"httpHeaders\": []interface{}{},\n                                            \"path\":        \"/wp-login.php\",\n                                            \"port\":        \"http\",\n                                            \"scheme\":      \"HTTP\",\n                                        },\n                                        \"initialDelaySeconds\": 30,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      5,\n                                    },\n                                    \"resources\": map[string]interface{}{\n                                        \"limits\": map[string]interface{}{},\n                                        \"requests\": map[string]interface{}{\n                                            \"cpu\":    \"300m\",\n                                            \"memory\": \"512Mi\",\n                                        },\n                                    },\n                                    \"volumeMounts\": []interface{}{\n                                        map[string]interface{}{\n                                            \"mountPath\": \"/bitnami/wordpress\",\n                                            \"name\":      \"wordpress-data\",\n                                            \"subPath\":   \"wordpress\",\n                                        },\n                                    },\n                                },\n                            },\n                            \"volumes\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\": \"wordpress-data\",\n                                    \"persistentVolumeClaim\": map[string]interface{}{\n                                        \"claimName\": fmt.Sprintf(\"%s-wordpress\", definitionName),\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n        unmanagedDbYamlDoc, err = kube.AppendObjectToYamlDoc(deploymentWordpress, unmanagedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        yamlDoc = unmanagedDbYamlDoc\n    } else {\n        var managedDbYamlDoc string\n\n        var deploymentWordpress = &amp;unstructured.Unstructured{\n            Object: map[string]interface{}{\n                \"apiVersion\": \"apps/v1\",\n                \"kind\":       \"Deployment\",\n                \"metadata\": map[string]interface{}{\n                    \"name\":      fmt.Sprintf(\"%s-wordpress\", definitionName),\n                    \"namespace\": \"default\",\n                    \"labels\": map[string]interface{}{\n                        \"app.kubernetes.io/name\":       \"wordpress\",\n                        \"app.kubernetes.io/instance\":   definitionName,\n                        \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                        \"environment\":                  environment,\n                    },\n                },\n                \"spec\": map[string]interface{}{\n                    \"selector\": map[string]interface{}{\n                        \"matchLabels\": map[string]interface{}{\n                            \"app.kubernetes.io/name\":     \"wordpress\",\n                            \"app.kubernetes.io/instance\": definitionName,\n                        },\n                    },\n                    \"strategy\": map[string]interface{}{\n                        \"type\": \"RollingUpdate\",\n                    },\n                    \"replicas\": wordpressReplicas,\n                    \"template\": map[string]interface{}{\n                        \"metadata\": map[string]interface{}{\n                            \"labels\": map[string]interface{}{\n                                \"app.kubernetes.io/name\":       \"wordpress\",\n                                \"app.kubernetes.io/instance\":   definitionName,\n                                \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                                \"environment\":                  environment,\n                            },\n                        },\n                        \"spec\": map[string]interface{}{\n                            // yamllint disable rule:indentation\n                            \"hostAliases\": []interface{}{\n                                map[string]interface{}{\n                                    \"hostnames\": []interface{}{\n                                        \"status.localhost\",\n                                    },\n                                    \"ip\": \"127.0.0.1\",\n                                },\n                            },\n                            // yamllint enable rule:indentation\n                            \"affinity\": map[string]interface{}{\n                                \"podAffinity\": nil,\n                                \"podAntiAffinity\": map[string]interface{}{\n                                    \"preferredDuringSchedulingIgnoredDuringExecution\": []interface{}{\n                                        map[string]interface{}{\n                                            \"podAffinityTerm\": map[string]interface{}{\n                                                \"labelSelector\": map[string]interface{}{\n                                                    \"matchLabels\": map[string]interface{}{\n                                                        \"app.kubernetes.io/name\":     \"wordpress\",\n                                                        \"app.kubernetes.io/instance\": definitionName,\n                                                    },\n                                                },\n                                                \"topologyKey\": \"kubernetes.io/hostname\",\n                                            },\n                                            \"weight\": 1,\n                                        },\n                                    },\n                                },\n                                \"nodeAffinity\": nil,\n                            },\n                            \"securityContext\": map[string]interface{}{\n                                \"fsGroup\": 1001,\n                                \"seccompProfile\": map[string]interface{}{\n                                    \"type\": \"RuntimeDefault\",\n                                },\n                            },\n                            \"serviceAccountName\": \"default\",\n                            \"containers\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\":            \"wordpress\",\n                                    \"image\":           \"docker.io/bitnami/wordpress:6.2.0-debian-11-r22\",\n                                    \"imagePullPolicy\": \"IfNotPresent\",\n                                    \"securityContext\": map[string]interface{}{\n                                        \"allowPrivilegeEscalation\": false,\n                                        \"capabilities\": map[string]interface{}{\n                                            \"drop\": []interface{}{\n                                                \"ALL\",\n                                            },\n                                        },\n                                        \"runAsNonRoot\": true,\n                                        \"runAsUser\":    1001,\n                                    },\n                                    \"env\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":  \"BITNAMI_DEBUG\",\n                                            \"value\": \"false\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"ALLOW_EMPTY_PASSWORD\",\n                                            \"value\": \"yes\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"MARIADB_HOST\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": dbConnectionSecret,\n                                                    \"key\":  \"db-endpoint\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"MARIADB_PORT_NUMBER\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": dbConnectionSecret,\n                                                    \"key\":  \"db-port\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_DATABASE_NAME\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": dbConnectionSecret,\n                                                    \"key\":  \"db-name\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_DATABASE_USER\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": dbConnectionSecret,\n                                                    \"key\":  \"db-user\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_DATABASE_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": dbConnectionSecret,\n                                                    \"key\":  \"db-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_USERNAME\",\n                                            \"value\": \"user\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\": \"WORDPRESS_PASSWORD\",\n                                            \"valueFrom\": map[string]interface{}{\n                                                \"secretKeyRef\": map[string]interface{}{\n                                                    \"name\": fmt.Sprintf(\"%s-wordpress\", definitionName),\n                                                    \"key\":  \"wordpress-password\",\n                                                },\n                                            },\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_EMAIL\",\n                                            \"value\": \"user@example.com\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_FIRST_NAME\",\n                                            \"value\": \"FirstName\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_LAST_NAME\",\n                                            \"value\": \"LastName\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_HTACCESS_OVERRIDE_NONE\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_ENABLE_HTACCESS_PERSISTENCE\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_BLOG_NAME\",\n                                            \"value\": \"User's Blog!\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_SKIP_BOOTSTRAP\",\n                                            \"value\": \"no\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_TABLE_PREFIX\",\n                                            \"value\": \"wp_\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_SCHEME\",\n                                            \"value\": \"http\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_EXTRA_WP_CONFIG_CONTENT\",\n                                            \"value\": \"\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"WORDPRESS_PLUGINS\",\n                                            \"value\": \"none\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"APACHE_HTTP_PORT_NUMBER\",\n                                            \"value\": \"8080\",\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":  \"APACHE_HTTPS_PORT_NUMBER\",\n                                            \"value\": \"8443\",\n                                        },\n                                    },\n                                    \"envFrom\": nil,\n                                    \"ports\": []interface{}{\n                                        map[string]interface{}{\n                                            \"name\":          \"http\",\n                                            \"containerPort\": 8080,\n                                        },\n                                        map[string]interface{}{\n                                            \"name\":          \"https\",\n                                            \"containerPort\": 8443,\n                                        },\n                                    },\n                                    \"livenessProbe\": map[string]interface{}{\n                                        \"failureThreshold\": 6,\n                                        \"httpGet\": map[string]interface{}{\n                                            \"httpHeaders\": []interface{}{},\n                                            \"path\":        \"/wp-admin/install.php\",\n                                            \"port\":        \"http\",\n                                            \"scheme\":      \"HTTP\",\n                                        },\n                                        \"initialDelaySeconds\": 120,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      5,\n                                    },\n                                    \"readinessProbe\": map[string]interface{}{\n                                        \"failureThreshold\": 6,\n                                        \"httpGet\": map[string]interface{}{\n                                            \"httpHeaders\": []interface{}{},\n                                            \"path\":        \"/wp-login.php\",\n                                            \"port\":        \"http\",\n                                            \"scheme\":      \"HTTP\",\n                                        },\n                                        \"initialDelaySeconds\": 30,\n                                        \"periodSeconds\":       10,\n                                        \"successThreshold\":    1,\n                                        \"timeoutSeconds\":      5,\n                                    },\n                                    \"resources\": map[string]interface{}{\n                                        \"limits\": map[string]interface{}{},\n                                        \"requests\": map[string]interface{}{\n                                            \"cpu\":    \"300m\",\n                                            \"memory\": \"512Mi\",\n                                        },\n                                    },\n                                    \"volumeMounts\": []interface{}{\n                                        map[string]interface{}{\n                                            \"mountPath\": \"/bitnami/wordpress\",\n                                            \"name\":      \"wordpress-data\",\n                                            \"subPath\":   \"wordpress\",\n                                        },\n                                    },\n                                },\n                            },\n                            \"volumes\": []interface{}{\n                                map[string]interface{}{\n                                    \"name\": \"wordpress-data\",\n                                    \"persistentVolumeClaim\": map[string]interface{}{\n                                        \"claimName\": fmt.Sprintf(\"%s-wordpress\", definitionName),\n                                    },\n                                },\n                            },\n                        },\n                    },\n                },\n            },\n        }\n        managedDbYamlDoc, err := kube.AppendObjectToYamlDoc(deploymentWordpress, managedDbYamlDoc)\n        if err != nil {\n            return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n        }\n\n        yamlDoc = managedDbYamlDoc\n    }\n\n    var secretWordpress = &amp;unstructured.Unstructured{\n        Object: map[string]interface{}{\n            \"apiVersion\": \"v1\",\n            \"kind\":       \"Secret\",\n            \"metadata\": map[string]interface{}{\n                \"name\":      fmt.Sprintf(\"%s-wordpress\", definitionName),\n                \"namespace\": \"default\",\n                \"labels\": map[string]interface{}{\n                    \"app.kubernetes.io/name\":       \"wordpress\",\n                    \"app.kubernetes.io/instance\":   definitionName,\n                    \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                    \"environment\":                  environment,\n                },\n            },\n            \"type\": \"Opaque\",\n            \"data\": map[string]interface{}{\n                \"wordpress-password\": \"VkR5MUJhSno5Uw==\",\n            },\n        },\n    }\n    yamlDoc, err := kube.AppendObjectToYamlDoc(secretWordpress, yamlDoc)\n    if err != nil {\n        return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n    }\n\n    var serviceWordpress = &amp;unstructured.Unstructured{\n        Object: map[string]interface{}{\n            \"apiVersion\": \"v1\",\n            \"kind\":       \"Service\",\n            \"metadata\": map[string]interface{}{\n                \"name\":      getWordpressServiceName(definitionName),\n                \"namespace\": \"default\",\n                \"labels\": map[string]interface{}{\n                    \"app.kubernetes.io/name\":       \"wordpress\",\n                    \"app.kubernetes.io/instance\":   definitionName,\n                    \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                    \"environment\":                  environment,\n                },\n            },\n            \"spec\": map[string]interface{}{\n                \"type\":            \"ClusterIP\",\n                \"sessionAffinity\": \"None\",\n                \"ports\": []interface{}{\n                    map[string]interface{}{\n                        \"name\":       \"http\",\n                        \"port\":       80,\n                        \"protocol\":   \"TCP\",\n                        \"targetPort\": \"http\",\n                    },\n                    map[string]interface{}{\n                        \"name\":       \"https\",\n                        \"port\":       443,\n                        \"protocol\":   \"TCP\",\n                        \"targetPort\": \"https\",\n                    },\n                },\n                \"selector\": map[string]interface{}{\n                    \"app.kubernetes.io/name\":     \"wordpress\",\n                    \"app.kubernetes.io/instance\": definitionName,\n                },\n            },\n        },\n    }\n    yamlDoc, err = kube.AppendObjectToYamlDoc(serviceWordpress, yamlDoc)\n    if err != nil {\n        return yamlDoc, fmt.Errorf(\"failed to append object to YAML manifest: %w\", err)\n    }\n\n    return yamlDoc, nil\n}\n\n// getWordpressServiceName returns the WordPress deployment's service name.\nfunc getWordpressServiceName(definitionName string) string {\n    return fmt.Sprintf(\"%s-wordpress\", definitionName)\n}\n\n// getPvcManifest returns the JSON for the persistent volume claim with the\n// storage class name set for the infra provider.\nfunc getPvcManifest(\n    infraProvider string,\n    definitionName string,\n    environment string,\n) (*datatypes.JSON, error) {\n    var storageClassName string\n    switch infraProvider {\n    case tpapi.KubernetesRuntimeInfraProviderKind:\n        storageClassName = \"standard\"\n    case tpapi.KubernetesRuntimeInfraProviderEKS:\n        storageClassName = \"gp2\"\n    default:\n        return nil, errors.New(\"unrecognized infra provider\")\n    }\n\n    var persistentVolumeClaimWordpress = &amp;unstructured.Unstructured{\n        Object: map[string]interface{}{\n            \"kind\":       \"PersistentVolumeClaim\",\n            \"apiVersion\": \"v1\",\n            \"metadata\": map[string]interface{}{\n                \"name\":      fmt.Sprintf(\"%s-wordpress\", definitionName),\n                \"namespace\": \"default\",\n                \"labels\": map[string]interface{}{\n                    \"app.kubernetes.io/name\":       \"wordpress\",\n                    \"app.kubernetes.io/instance\":   definitionName,\n                    \"app.kubernetes.io/managed-by\": \"wordrpess-threepport-module\",\n                    \"environment\":                  environment,\n                },\n            },\n            \"spec\": map[string]interface{}{\n                \"storageClassName\": storageClassName,\n                \"accessModes\": []interface{}{\n                    \"ReadWriteOnce\",\n                },\n                \"resources\": map[string]interface{}{\n                    \"requests\": map[string]interface{}{\n                        \"storage\": \"10Gi\",\n                    },\n                },\n            },\n        },\n    }\n\n    jsonData, err := util.UnstructuredToDatatypesJson(persistentVolumeClaimWordpress)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to generate JSON for PVC: %w\", err)\n    }\n\n    return &amp;jsonData, nil\n}\n</code></pre> <p>At this point the create and delete functionality for the WordPress objects has been implemented.  For now, we will skip the update functionality for now.  That can be added later.</p>"},{"location":"sdk/tutorial/#add-config-abstractions","title":"Add Config Abstractions","text":""},{"location":"sdk/tutorial/#updates-to-pkgconfigv0wordpressgo","title":"Updates to <code>pkg/config/v0/wordpress.go</code>","text":"<p>The file <code>pkg/config/v0/wordpress.go</code> contains scaffolding for config abstractions that allow a single user command to make multiple API calls on the user's behalf.  This is an important way to reduce toil on the user of the system and provide useful user abstractions.</p> <p>Let's add the source code to provide these config abstractions.</p> <p>First, we need to update three types.  These types determine the schema for config interfaces that will be used to manage WordPress objects.</p> <p>Find the types below in that file and update them to match the code below.</p> <pre><code>// WordpressValues contains the attributes needed to manage a wordpress\n// definition and wordpress instance with a single operation.\ntype WordpressValues struct {\n    Name                      *string                                   `yaml:\"Name\"`\n    Environment               *string                                   `yaml:\"Environment\"`\n    Replicas                  *int                                      `yaml:\"Replicas\"`\n    ManagedDatabase           *bool                                     `yaml:\"ManagedDatabase\"`\n    DomainName                *tpconfig.DomainNameValues                `yaml:\"DomainName\"`\n    SubDomain                 *string                                   `yaml:\"SubDomain\"`\n    KubernetesRuntimeInstance *tpconfig.KubernetesRuntimeInstanceValues `yaml:\"KubernetesRuntimeInstance\"`\n    AwsAccountName            *string                                   `yaml:\"AwsAccountName\"`\n}\n\n...\n\n// WordpressDefinitionValues contains the attributes for the wordpress definition\n// config abstraction.\ntype WordpressDefinitionValues struct {\n    Name            *string                    `yaml:\"Name\"`\n    Environment     *string                    `yaml:\"Environment\"`\n    Replicas        *int                       `yaml:\"Replicas\"`\n    ManagedDatabase *bool                      `yaml:\"ManagedDatabase\"`\n    DomainName      *tpconfig.DomainNameValues `yaml:\"DomainName\"`\n    AwsAccountName  *string                    `yaml:\"AwsAccount\"`\n}\n\n...\n\n// WordpressInstanceValues contains the attributes for the wordpress instance\n// config abstraction.\ntype WordpressInstanceValues struct {\n    Name                      *string                                   `yaml:\"Name\"`\n    SubDomain                 *string                                   `yaml:\"SubDomain\"`\n    WordpressDefinition       WordpressDefinitionValues                 `yaml:\"WordpressDefinition\"`\n    KubernetesRuntimeInstance *tpconfig.KubernetesRuntimeInstanceValues `yaml:\"KubernetesRuntimeInstance\"`\n}\n</code></pre> <p>Next, let's update the methods on the <code>WordpressValues</code> object to match the code shown here.</p> <pre><code>// Create creates a wordpress definition and instance in the Threeport API.\nfunc (w *WordpressValues) Create(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressDefinition, *api_v0.WordpressInstance, error) {\n    // get operations\n    operations, createdWordpressDefinition, createdWordpressInstance := w.GetOperations(\n        apiClient,\n        apiEndpoint,\n    )\n\n    // execute create operations\n    if err := operations.Create(); err != nil {\n        return nil, nil, fmt.Errorf(\n            \"failed to execute create operations for wordpress defined instance with name %s: %w\",\n            *w.Name,\n            err,\n        )\n    }\n\n    return createdWordpressDefinition, createdWordpressInstance, nil\n}\n\n// Delete deletes a wordpress definition and instance from the Threeport API.\nfunc (w *WordpressValues) Delete(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressDefinition, *api_v0.WordpressInstance, error) {\n    // get operations\n    operations, _, _ := w.GetOperations(\n        apiClient,\n        apiEndpoint,\n    )\n\n    // execute delete operations\n    if err := operations.Delete(); err != nil {\n        return nil, nil, fmt.Errorf(\n            \"failed to execute delete operations for wordpress defined instance with name %s: %w\",\n            *w.Name,\n            err,\n        )\n    }\n\n    return nil, nil, nil\n}\n\n// GetOperations returns a slice of operations used to create or delete a\n// wordpress defined instance.\nfunc (w *WordpressValues) GetOperations(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*util.Operations, *api_v0.WordpressDefinition, *api_v0.WordpressInstance) {\n    var err error\n    var createdWordpressDefinition api_v0.WordpressDefinition\n    var createdWordpressInstance api_v0.WordpressInstance\n\n    operations := util.Operations{}\n\n    // add wordpress definition operation\n    wordpressDefinitionValues := WordpressDefinitionValues{\n        Name:            w.Name,\n        Environment:     w.Environment,\n        Replicas:        w.Replicas,\n        ManagedDatabase: w.ManagedDatabase,\n        DomainName:      w.DomainName,\n        AwsAccountName:  w.AwsAccountName,\n    }\n    operations.AppendOperation(util.Operation{\n        Create: func() error {\n            wordpressDefinition, err := wordpressDefinitionValues.Create(apiClient, apiEndpoint)\n            if err != nil {\n                return fmt.Errorf(\"failed to create wordpress definition with name %s: %w\", *w.Name, err)\n            }\n            createdWordpressDefinition = *wordpressDefinition\n            return nil\n        },\n        Delete: func() error {\n            _, err = wordpressDefinitionValues.Delete(apiClient, apiEndpoint)\n            if err != nil {\n                return fmt.Errorf(\"failed to delete wordpress definition with name %s: %w\", *w.Name, err)\n            }\n            return nil\n        },\n        Name: \"wordpress definition\",\n    })\n\n    // add wordpress instance operation\n    wordpressInstanceValues := WordpressInstanceValues{\n        Name:      w.Name,\n        SubDomain: w.SubDomain,\n        WordpressDefinition: WordpressDefinitionValues{\n            Name: w.Name,\n        },\n        KubernetesRuntimeInstance: w.KubernetesRuntimeInstance,\n    }\n    operations.AppendOperation(util.Operation{\n        Create: func() error {\n            wordpressInstance, err := wordpressInstanceValues.Create(apiClient, apiEndpoint)\n            if err != nil {\n                return fmt.Errorf(\"failed to create wordpress instance with name %s: %w\", *w.Name, err)\n            }\n            createdWordpressInstance = *wordpressInstance\n            return nil\n        },\n        Delete: func() error {\n            _, err = wordpressInstanceValues.Delete(apiClient, apiEndpoint)\n            if err != nil {\n                return fmt.Errorf(\"failed to delete wordpress instance with name %s: %w\", *w.Name, err)\n            }\n            return nil\n        },\n        Name: \"wordpress instance\",\n    })\n\n    return &amp;operations, &amp;createdWordpressDefinition, &amp;createdWordpressInstance\n}\n</code></pre> <p>Now, update the <code>Create</code> and <code>Delete</code> methods on the <code>WordpressDefinitionValues</code> object as shown below.</p> <pre><code>// Create creates a wordpress definition in the Threeport API.\nfunc (w *WordpressDefinitionValues) Create(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressDefinition, error) {\n    // validate config\n    // environment\n    if w.Environment != nil {\n        validEnvs := []string{\"dev\", \"prod\"}\n        envValid := false\n        for _, env := range validEnvs {\n            if *w.Environment == env {\n                envValid = true\n                break\n            }\n        }\n        if !envValid {\n            return nil, fmt.Errorf(\"invalid Environment - must be one of %s\", validEnvs)\n        }\n    }\n    // domain name\n    if w.DomainName != nil {\n        if w.DomainName.Name == nil {\n            return nil, errors.New(\"must provide a name for the domain name definition to use\")\n        }\n    }\n\n    // construct wordpress definition object\n    wordpressDefinition := api_v0.WordpressDefinition{\n        Definition: tpapi_v0.Definition{\n            Name: w.Name,\n        },\n    }\n    if w.Environment != nil {\n        wordpressDefinition.Environment = w.Environment\n    }\n    if w.Replicas != nil {\n        wordpressDefinition.Replicas = w.Replicas\n    }\n    if w.ManagedDatabase != nil {\n        wordpressDefinition.ManagedDatabase = w.ManagedDatabase\n    }\n    // create wordpress definition\n    createdWordpressDefinition, err := client_v0.CreateWordpressDefinition(\n        apiClient,\n        apiEndpoint,\n        &amp;wordpressDefinition,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create wordpress definition in threeport API: %w\", err)\n    }\n\n    // make domain name definition attachment if defined\n    if w.DomainName != nil {\n        // look up domain name by name\n        domainNameDefinition, err := tpclient.GetDomainNameDefinitionByName(\n            apiClient,\n            apiEndpoint,\n            *w.DomainName.Name,\n        )\n        if err != nil {\n            return nil, fmt.Errorf(\"domain name definition %s not found: %w\", *w.DomainName.Name, err)\n        }\n        // set attachment of wordpress definition to domain name definition\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            apiClient,\n            apiEndpoint,\n            tpapi_v0.ObjectTypeDomainNameDefinition,\n            domainNameDefinition.ID,\n            api_v0.ObjectTypeWordpressDefinition,\n            createdWordpressDefinition.ID,\n        ); err != nil {\n            return nil, fmt.Errorf(\"failed to attach wordpress definition to domain name definition: %w\", err)\n        }\n    }\n\n    // make AWS account attachment if needed\n    if w.ManagedDatabase != nil &amp;&amp; *w.ManagedDatabase {\n        var awsAccountId uint\n        if w.AwsAccountName == nil {\n            // look for default account\n            queryString := \"default=true\"\n            awsAccounts, err := tpclient.GetAwsAccountsByQueryString(\n                apiClient,\n                apiEndpoint,\n                queryString,\n            )\n            if err != nil {\n                return nil, fmt.Errorf(\"failed to get default AWS account: %w\", err)\n            }\n            if len(*awsAccounts) == 0 {\n                return nil, errors.New(\"no AWS account name provided and no default account found\")\n            }\n            awsAccountId = *(*awsAccounts)[0].ID\n        } else {\n            // look up AWS account by name\n            awsAccount, err := tpclient.GetAwsAccountByName(\n                apiClient,\n                apiEndpoint,\n                *w.AwsAccountName,\n            )\n            if err != nil {\n                return nil, fmt.Errorf(\"failed to get AWS account by name %s: %w\", *w.AwsAccountName, err)\n            }\n            awsAccountId = *awsAccount.ID\n        }\n        // set attachment of wordpress definition to AWS account\n        if err := tpclient.EnsureAttachedObjectReferenceExists(\n            apiClient,\n            apiEndpoint,\n            tpapi_v0.ObjectTypeAwsAccount,\n            &amp;awsAccountId,\n            api_v0.ObjectTypeWordpressDefinition,\n            createdWordpressDefinition.ID,\n        ); err != nil {\n            return nil, fmt.Errorf(\"failed to attach wordpress definition to AWS account: %w\", err)\n        }\n    }\n\n    return createdWordpressDefinition, nil\n}\n\n// Delete deletes a wordpress definition from the Threeport API.\nfunc (w *WordpressDefinitionValues) Delete(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressDefinition, error) {\n    // get wordpress definition by name\n    wordpressDefinition, err := client_v0.GetWordpressDefinitionByName(\n        apiClient,\n        apiEndpoint,\n        *w.Name,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to find wordpress definition with name %s: %w\", *w.Name, err)\n    }\n\n    // delete wordpress definition\n    deletedWordpressDefinition, err := client_v0.DeleteWordpressDefinition(\n        apiClient,\n        apiEndpoint,\n        *wordpressDefinition.ID,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to delete wordpress definition from Threeport API: %w\", err)\n    }\n\n    return deletedWordpressDefinition, nil\n}\n</code></pre> <p>Finally, update the <code>Create</code> and <code>Delete</code> methods on the <code>WordpressInstanceValues</code> object as shown below.</p> <pre><code>// Create creates a wordpress instance in the Threeport API.\nfunc (w *WordpressInstanceValues) Create(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressInstance, error) {\n    // validate config\n    // TODO\n\n    // get kubernetes runtime instance API object\n    kubernetesRuntimeInstance, err := tpconfig.SetKubernetesRuntimeInstanceForConfig(\n        w.KubernetesRuntimeInstance,\n        apiClient,\n        apiEndpoint,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to set kubernetes runtime instance: %w\", err)\n    }\n\n    // get wordpress definition by name\n    wordpressDefinition, err := client_v0.GetWordpressDefinitionByName(\n        apiClient,\n        apiEndpoint,\n        *w.WordpressDefinition.Name,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\n            \"failed to get wordpress definition by name %s: %w\",\n            w.WordpressDefinition.Name,\n            err,\n        )\n    }\n\n    // construct wordpress instance object\n    wordpressInstance := api_v0.WordpressInstance{\n        Instance: tpapi_v0.Instance{\n            Name: w.Name,\n        },\n        WordpressDefinitionID: wordpressDefinition.ID,\n    }\n    if w.SubDomain != nil {\n        wordpressInstance.SubDomain = w.SubDomain\n    }\n\n    // create wordpress instance\n    createdWordpressInstance, err := client_v0.CreateWordpressInstance(\n        apiClient,\n        apiEndpoint,\n        &amp;wordpressInstance,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create wordpress instance in threeport API: %w\", err)\n    }\n\n    // create attached object reference to kubernetes runtime instance\n    if err := tpclient.EnsureAttachedObjectReferenceExists(\n        apiClient,\n        apiEndpoint,\n        tpapi_v0.ObjectTypeKubernetesRuntimeInstance,\n        kubernetesRuntimeInstance.ID,\n        api_v0.ObjectTypeWordpressInstance,\n        createdWordpressInstance.ID,\n    ); err != nil {\n        return nil, fmt.Errorf(\"failed to attach wordpress instance to kubernetes runtime instance: %w\", err)\n    }\n\n    return createdWordpressInstance, nil\n}\n\n// Delete deletes a wordpress instance from the Threeport API.\nfunc (w *WordpressInstanceValues) Delete(\n    apiClient *http.Client,\n    apiEndpoint string,\n) (*api_v0.WordpressInstance, error) {\n    // get wordpress instance by name\n    wordpressInstance, err := client_v0.GetWordpressInstanceByName(\n        apiClient,\n        apiEndpoint,\n        *w.Name,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to find wordpress instance with name %s: %w\", *w.Name, err)\n    }\n\n    // delete wordpress instance\n    deletedWordpressInstance, err := client_v0.DeleteWordpressInstance(\n        apiClient,\n        apiEndpoint,\n        *wordpressInstance.ID,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to delete wordpress instance from Threeport API: %w\", err)\n    }\n\n    // wait for workload instance to be deleted\n    util.Retry(60, 1, func() error {\n        if _, err := client_v0.GetWordpressInstanceByName(apiClient, apiEndpoint, *w.Name); err == nil {\n            return errors.New(\"workload instance not deleted\")\n        }\n        return nil\n    })\n\n    // get kubernetes runtime instance API object\n    kubernetesRuntimeInstance, err := tpconfig.SetKubernetesRuntimeInstanceForConfig(\n        w.KubernetesRuntimeInstance,\n        apiClient,\n        apiEndpoint,\n    )\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to set kubernetes runtime instance: %w\", err)\n    }\n\n    // remove attached object reference to kubernetes runtime instance\n    if err := tpclient.EnsureAttachedObjectReferenceRemoved(\n        apiClient,\n        apiEndpoint,\n        tpapi_v0.ObjectTypeKubernetesRuntimeInstance,\n        kubernetesRuntimeInstance.ID,\n        api_v0.ObjectTypeWordpressInstance,\n        deletedWordpressInstance.ID,\n    ); err != nil {\n        return nil, fmt.Errorf(\"failed to remove wordpress instance attachment to kubernetes runtime instance: %w\", err)\n    }\n\n    return deletedWordpressInstance, nil\n}\n</code></pre> <p>Ensure the imports for this <code>pkg/config/v0/wordpress.go</code> file match the following.</p> <pre><code>import (\n    \"errors\"\n    \"fmt\"\n    \"net/http\"\n\n    tpapi_v0 \"github.com/threeport/threeport/pkg/api/v0\"\n    tpclient \"github.com/threeport/threeport/pkg/client/v0\"\n    tpconfig \"github.com/threeport/threeport/pkg/config/v0\"\n    util \"github.com/threeport/threeport/pkg/util/v0\"\n\n    api_v0 \"wordpress-threeport-module/pkg/api/v0\"\n    client_v0 \"wordpress-threeport-module/pkg/client/v0\"\n)\n</code></pre> <p>That's it!  We've added 1 file and modified 3 others.  We're ready to build and deploy the module to Threeport.</p>"},{"location":"sdk/tutorial/#build","title":"Build","text":"<p>First, we need to satisfy the project's package dependencies.</p> <pre><code>go mod tidy\n</code></pre> <p>The Threeport SDK provides mage targets with convenient development utilities.  To see all available mage targets, simple run <code>mage</code>.</p> <p>Next, let's build the <code>tptctl</code> plugin for the WordPress module.</p> <pre><code>mage build:plugin\n</code></pre> <p>To install a tptctl plugin, simply copy the plugin binary to the tptctl plugin directory - by default <code>~/.threeport/plugins</code>.  See <code>tptctl help</code> for more info on installing tptctl plugins.</p> <pre><code>cp bin/wordpress ~/.threeport/plugins/\n</code></pre> <p>Check the plugin was successfully installed.</p> <pre><code>tptctl wordpress -h\n</code></pre> <p>Note:  If you're using a Mac, you may encounter security restrictions that prevent your workstation from running the plugin.  If, when you run it, you see output similar to this: <pre><code>[1]    40259 killed     tptctl wordpress -h\n</code></pre> Then run the following command. <pre><code>codesign -f -s - bin/wordpress\n</code></pre> Then repeat the two steps below to install and test the plugin.</p> <p>You should see the help output for the wordpress plugin similar to that shown below.</p> <pre><code>Manage the Wordpress Threeport module\n\nUsage:\n  wordpress [command]\n\nAvailable Commands:\n  completion  Generate the autocompletion script for the specified shell\n  create      Create a Threeport Wordpress object\n  delete      Delete a Threeport Wordpress object\n  describe    Describe a Threeport Wordpress object\n  get         Get a Threeport Wordpress object\n  help        Help about any command\n  install     Install the Wordpress module to an existing Threeport control plane\n\nFlags:\n  -h, --help                      help for wordpress\n      --provider-config string    Path to infra provider config directory (default is $HOME/.threeport/).\n      --threeport-config string   Path to config file (default is $HOME/.threeport/config.yaml). Can also be set with environment variable THREEPORT_CONFIG\n  -t, --toggle                    Help message for toggle\n\nAdditional help topics:\n  wordpress update     Update a Threeport Wordpress object\n\nUse \"wordpress [command] --help\" for more information about a command.\n</code></pre> <p>Next, we need to build the binaries and container images for each containerized component that will be installed into a Threeport control plane.  After the images are built, they will be pushed to a container registry to make them available for installation.</p> <p>Note: In this and other following sections, you will have the option to test the WordPress module in a \"Local Dev Environment\" on your workstation, or in a \"Remote Environment\" running in AWS.</p> <p>The remote environment option will provide a more realistic use case and will allow you to test using AWS RDS as the persistent data store for WordPress, but requires an AWS account, will cost money and take a little longer.  This tutorial will also require a Route53 hosted zone you can use for DNS.  The local dev environment will be faster to spin up and down and cost nothing on your cloud bill.  Choose the appropriate tab in each section for the method you choose.</p> Local Dev EnvironmentRemote Environment <p>If you're going to test this locally, first spin up a local container registry so we don't have to wait for images to pushed to - and pulled from - a remote registry.  This mage target will create run a local docker container to serve as the container registry.</p> <pre><code>mage dev:localRegistryUp\n</code></pre> <p>Now we can build and push the container images to the local registry.</p> <pre><code>mage build:allImagesDev\n</code></pre> <p>If using a remote AWS environment, build for the release architecture (amd64). This step will build the binaries and container images, then push them to your registry (as defined in the <code>sdk-config.yaml</code> file).  This may take a few minutes as three container images will be pushed to your remote container registry.  You will need to be logged in to your container registry from your command line.</p> <pre><code>mage build:allImagesRelease\n</code></pre>"},{"location":"sdk/tutorial/#threeport-control-plane","title":"Threeport Control Plane","text":"<p>If you don't aleady have one, install a Threeport control plane for testing.</p> Local Dev EnvironmentRemote Environment <p>To install Threeport that will pull images from a local registry, use the following command.</p> <pre><code>tptctl up \\\n    --name test \\\n    --provider kind \\\n    --auth-enabled false \\\n    --local-registry\n</code></pre> <p>For more info on installing Threeport locally, see the documentation to Install Threeport Locally.</p> <p>To install Threeport in AWS, use the following command.  Substitute your region of choice as needed.</p> <pre><code>tptctl up \\\n    --name test \\\n    --provider eks \\\n    --aws-region us-east-2\n</code></pre> <p>For more info on installing Threeport remotely, see the documentation to Install Threeport on AWS.</p>"},{"location":"sdk/tutorial/#install-wordpress-module","title":"Install WordPress Module","text":"Local Dev EnvironmentRemote Environment <p>To install the WordPress module using the image pushed to the local dev registry, use the following command.</p> <pre><code>tptctl wordpress install -r localhost:5001\n</code></pre> <p>If installing remotely, run the install as shown here to pull images from your default image repo (as declared in your <code>sdk-config.yaml</code> file).</p> <pre><code>tptctl wordpress install\n</code></pre>"},{"location":"sdk/tutorial/#use-the-wordpress-module","title":"Use the WordPress Module","text":"Local Dev EnvironmentRemote Environment <p>For a local install of WordPress use the following config.  The <code>Environment</code> and <code>ManagedDatabase</code> fields are shown with their default values and aren't required.  They are only included for the sake of explicitness for this tutorial.</p> <pre><code># wordpress-local.yaml\nWordpress:\n  Name: local\n  Environment: dev\n  ManagedDatabase: false\n</code></pre> <p>Install WordPress.</p> <pre><code>tptctl wordpress create wordpress -c wordpress-local.yaml\n</code></pre> <p>In order to use a Route53 hosted zone to manage DNS for your WordPress app, you will need to register that with Threeport.  Create a domain name definition config like this.  Replace the values for the <code>Domain</code> and <code>AdminEmail</code> fields to work for your setup.</p> <pre><code># domain-name.yaml\nDomainNameDefinition:\n  Name: test-domain\n  Domain: example.com\n  Zone: Public\n  AdminEmail: admin@example.com\n</code></pre> <p>Now you can register this hosted zone with Threeport.</p> <pre><code>tptctl create domain-name-definition -c domain-name.yaml\n</code></pre> <p>For a remote install, we can use AWS RDS for the database as well as Route53 for DNS.</p> <pre><code># wordpress-remote.yaml\nWordpress:\n  Name: remote\n  Environment: dev\n  ManagedDatabase: true\n  DomainName:\n    Name: test-domain\n  SubDomain: blog\n  KubernetesRuntimeInstance:\n    Name: threeport-test\n</code></pre> <p>Install WordPress.</p> <pre><code>tptctl wordpress create wordpress -c wordpress-remote.yaml\n</code></pre>"},{"location":"sdk/tutorial/#verification","title":"Verification","text":"<p>After a few minutes, the wordpress instance should be running.  You can view the app in your browser by following the following steps.</p> Local Dev EnvironmentRemote Environment <p>Note: You will need to have kubectl installed on your machine to perform these steps.</p> <p>Get the Threeport-managed namespace that was created for the WordPress app.</p> <pre><code>WORDPRESS_NAMESPACE=$(kubectl get ns -A -l app.kubernetes.io/name=local -o=jsonpath='{.items[0].metadata.name}')\n</code></pre> <p>Start a port forward to the WordPress service.</p> <pre><code>kubectl port-forward -n $WORDPRESS_NAMESPACE svc/local-wordpress 8080:80\n</code></pre> <p>Now visit http://localhost:8080 in your browser.</p> <p>When finished, hit Ctrl+C in the terminal where the port forward is running to cancel it.</p> <p>To verify the app is up and running, just type <code>blog.[your domain]</code> (using the domain you configured in <code>domain-name.yaml</code>) into a browser.  By default, Let's Encrypt is used as the TLS cert provider.  Also, by default, the staging environment is used.  This means the certificate will be valid but not publicly trusted.  So your browser will give you a warning.  You can tell your browser to proceed anyway, and you should get the default homepage served to you.</p>"},{"location":"sdk/tutorial/#clean-up","title":"Clean Up","text":"<p>Follow the instructions to remove the WordPress app and Threeport for either the Local or Remote environment.</p> Local Dev EnvironmentRemote Environment <p>Remove the WordPress app by deleting it with tptctl.</p> <pre><code>tptctl wordpress delete wordpress -c wordpress-local.yaml\n</code></pre> <p>Remove the local Threeport control plane.</p> <pre><code>tptctl down -n test\n</code></pre> <p>Remove the local container registry.</p> <pre><code>mage dev:localRegistryDown\n</code></pre> <p>Remove the WordPress app by deleting it with tptctl.</p> <pre><code>tptctl wordpress delete wordpress -c wordpress-remote.yaml\n</code></pre> <p>After deleting the WordPress app, wait a few minutes before proceeding.  We need to give the system enough time to clean up your Route53 hosted zone before removing the support services in the next step.  If you like, you can check your Route53 hosted zone in the AWS portal before proceeding.  Otherwise, just wait 5 minutes to be safe.</p> <p>Next, we need to Remove the support service workloads that were deployed.  By default, Threeport will not remove a Kubernetes runtime with workloads deployed.  We can view them with this command.</p> <pre><code>tptctl get workloads\n</code></pre> <p>Delete the support service workloads.</p> <pre><code>tptctl delete workload-instance -n gloo-edge-threeport-test\ntptctl delete workload-instance -n external-dns-threeport-test\n</code></pre> <p>Wait another 5 minutes before proceeding to ensure the AWS load balancer connected to your ingress layer is removed before deleting the control plane altogether in the next step.</p> <p>Remove the local Threeport control plane.</p> <pre><code>tptctl down -n test\n</code></pre>"},{"location":"sdk/tutorial/#summary","title":"Summary","text":"<p>In this tutorial we walked through each and every step to build a sample module to the Threeport control plane.  You can apply the same process to create any module to Threeport that you like.  Use cases are not limited to particular workload support.  Other use cases can include:</p> <ul> <li>Support for alternative infrastructure providers.</li> <li>Support for managed services on infrastructure providers.  This is not limited   to cloud providers.  It could include services like DataDog, Splunk, MongoDB,   or literally any other software service that has an API.</li> <li>Support for alternative runtime environments besides Kubernetes, e.g. VMs or   function-as-a-service offerings.</li> </ul>"},{"location":"sdk/workload-abstraction/","title":"Basic Workload Abstraction","text":"<p>Guide for construction of Kubernetes resources using go and leveraging workload objects.</p>"},{"location":"secrets/secrets-intro/","title":"Secrets","text":"<p>If your application needs to access sensitive values that are stored in a secret vault, Threeport supports this requirement with Secrets as a support service. Under the hood, Threeport uses a project called external-secrets.</p> <p>Note: Currently the only supported secret vault is AWS Secrets Manager. We plan to support other secret vaults in the future.</p>"},{"location":"secrets/secrets-intro/#secret-definition","title":"Secret Definition","text":"<p>The secret definition represents some secret value.  The secret definition stores the AWS account ID where the secret should be stored in AWS Secrets Manager and the secret data as JSON&gt;</p> <p>Reference: SecretDefinition</p>"},{"location":"secrets/secrets-intro/#secretinstance","title":"SecretInstance","text":"<p>A secret instance is an instance of a secret value being exposed to a workload. It is a union of a workload instance and secret definition.  When a secret instance is created the secret data is exposed to the workload.</p> <p>Reference: SecretInstance</p>"},{"location":"secrets/secrets-intro/#next-steps","title":"Next Steps","text":"<p>Our Deploy Workload with Secret on AWS guide walks through the use of secrets with workloads on Threeport.</p>"},{"location":"terraform/rds-database/","title":"Deploy RDS Instance with Terraform","text":"<p>In this guide, we're going to use a Terraform definition and instance to deploy an instance of the AWS Relational Database Service (RDS) using Threeport.</p> <p>You'll need an active AWS account to follow this guide.</p> <p>Note: At this time, you can only use Terraform to deploy resources on AWS with Threeport.</p>"},{"location":"terraform/rds-database/#prerequisites","title":"Prerequisites","text":"<p>You'll need a Threeport control plane for this guide.  Follow the Install Threeport Locally guide to set that up a local control plane or the Install Threeport on AWS guide for a remote control plane.  Either will work.</p>"},{"location":"terraform/rds-database/#work-space","title":"Work Space","text":"<p>First, create a temporary work space on your machine.</p> <pre><code>mkdir threeport-terraform-test\ncd threeport-terraform-test\n</code></pre>"},{"location":"terraform/rds-database/#aws-account","title":"AWS Account","text":"<p>If you installed Threeport on AWS, you'll already have an AWS account available to use (the same one used to deploy EKS for the Threeport control plane).  If you'd like to use a different AWS account for this guide - or if you installed Threeport locally, you'll need to register an AWS account with Threeport.</p> <p>Download a config to register AWS with Threeport.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/aws/default-aws-account.yaml\n</code></pre> <p>Open this file:</p> <pre><code>AwsAccount:\n  Name: default-account\n  AccountID: \"555555555555\"\n  DefaultAccount: true\n\n  # option 1: provide explicit configs/credentials\n  #DefaultRegion: us-east-1\n  #AccessKeyID: \"ABCDEABCDEABCDEABCDE\"\n  #SecretAccessKey: \"123abcABC123abcABC123abcABC123abcABC123a\"\n\n  # option 2: use local AWS configs/credentials\n  LocalConfig: /path/to/local/.aws/config\n  LocalCredentials: /path/to/local/.aws/credentials\n  LocalProfile: default\n</code></pre> <p>Edit the file to make the following changes:</p> <ol> <li>On line 2, update the <code>AccountID</code> with the value for your account.</li> <li>If using option 1, enter the <code>DefaultRegion</code> you'd like to use on line 7 and    add the keys on lines 8 and 9.  If you're unsure how to create access keys    for AWS, see the AWS    guide for managing access    keys.</li> <li>If using option 2, you'll need to have your local config and credentials set    up.  If you have set up the AWS CLI in the past, you'll likely have this    ready.  If not, see the AWS guide to set up the AWS    CLI.    With this set up, enter the file paths for the config and credentials along    with the profile you'd prefer to use.</li> </ol> <p>Now, register the AWS account with Threeport.</p> <pre><code>tptctl create aws-account --config default-aws-account.yaml\n</code></pre>"},{"location":"terraform/rds-database/#create-terraform-definition","title":"Create Terraform Definition","text":"<p>The Terraform definition includes the Terraform configs to deploy some AWS resources.</p> <p>Download a sample Threeport config.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/rds-terraform-definition.yaml\n</code></pre> <p>The sample config for a Terraform definition looks as follows:</p> <pre><code>TerraformDefinition:\n  Name: rds-instance\n  ConfigDir: config\n</code></pre> <p>It indicates that it will look for Terraform configs in a directory <code>config</code>.</p> <p>Let's create that directory and download sample Terraform configs.</p> <pre><code>mkdir config\ncurl -O --output-dir config https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/config/main.tf\ncurl -O --output-dir config https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/config/outputs.tf\ncurl -O --output-dir config https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/config/variables.tf\n</code></pre> <p>Now we can create the Terraform definition:</p> <pre><code>tptctl create terraform-definition --config rds-terraform-definition.yaml\n</code></pre> <p>The Terraform configs for an RDS instance are now stored in Threeport.  Next, we can create an instance from that definition.</p>"},{"location":"terraform/rds-database/#create-terraform-instance","title":"Create Terraform Instance","text":"<p>This step will actually deploy the RDS instance on AWS.</p> <p>Download a sample config.</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/rds-terraform-instance.yaml\n</code></pre> <p>The config looks as follows:</p> <pre><code>TerraformInstance:\n  Name: rds-instance-01\n  VarsDocument: config/terraform.tfvars\n  TerraformDefinition:\n    Name: rds-instance\n  AwsAccount:\n    Name: default-account\n</code></pre> <p>This config specifies:</p> <ul> <li>An arbitrary name for the RDS instance</li> <li>Terraform variables to use for this deployment</li> <li>The name of the definition we just created</li> <li>The AWS account we registered earlier</li> </ul> <p>Download Terraform a sample variables file:</p> <pre><code>curl -O --output-dir config https://raw.githubusercontent.com/threeport/threeport/main/samples/terraform/config/terraform.tfvars\n</code></pre> <p>Open the <code>config/terraform.tfvars</code> file.</p> <pre><code>region = \"us-east-2\"\nvpc_id = \"vpc-asdf1234asdf12345\"\nsubnet_ids = [\"subnet-asdf1234asdf12345\", \"subnet-asdf1234asdf12345\",\n\"subnet-asdf1234asdf12345\"]\ndb_port = 3306\napp_security_group = \"sg-asdf1234asdf12345\"\ndb_password = \"unsecurepwd\"\n</code></pre> <p>There are several values we'll have to set for your environment:</p> <ul> <li>Set the <code>region</code> to your desired AWS region.</li> <li>Log into the AWS console and go to the VPC dashboard.  If you have a Threeport   control plane installed in AWS, select the VPC where that is installed.   Otherwise, use your default VPC.  Enter the VPC ID on line 2 in the tfvars file.</li> <li>Go the subnets dashboard in the AWS console.  Select the subnets used for   Threeport, or the default subnets.  Enter the subnet IDs on line 3.</li> <li>For the security group, use your default security group ID on line 6.  We   won't be connecting an app in this guide so it is not important.</li> <li>Change the password to something unique on line 7.</li> </ul> <p>Now we can create the Terraform instance.</p> <pre><code>tptctl create terraform-instance --config rds-terraform-instance.yaml\n</code></pre> <p>If you go to the AWS RDS console, you'll shortly see the RDS instance being created.  Terraform takes a few minutes to initialize and deploy resources, so it won't be immediate.  Give it a little time.</p> <p>You can view your Terraforms with this command:</p> <pre><code>tptctl get terraforms\n</code></pre> <p>Once the RDS instance is up, you should see output similar to this:</p> <pre><code>NAME              TERRAFORM DEFINITION     TERRAFORM INSTANCE     AWS ACCOUNT          STATUS       AGE\nrds-instance      rds-instance             rds-instance-01        default-account      Healthy      11m42s\n</code></pre>"},{"location":"terraform/rds-database/#get-terraform-outputs","title":"Get Terraform Outputs","text":"<p>In order to connect to the database, there are several outputs from Terraform that you'll need to retrieve.  These are stored securely in the Threeport database.</p> <p>Once the RDS instance is up, get those outputs as follows:</p> <pre><code>tptctl describe terraform-instance -n rds-instance-01 -o yaml\n</code></pre> <p>You'll notice the sensitive encrypted values are redacted.  You can view those values by requesting specific fields.</p> <pre><code>tptctl describe terraform-instance -n rds-instance-01 -f Outputs\n</code></pre> <p>You'll see the Terraform outputs in JSON format similar to this:</p> <pre><code>{\n  \"rds_db_name\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"wordpress\"\n  },\n  \"rds_hostname\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"wordpress-db.ccccmqr3ixkh.us-east-2.rds.amazonaws.com\"\n  },\n  \"rds_password\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"unsecurepwd\"\n  },\n  \"rds_port\": {\n    \"sensitive\": true,\n    \"type\": \"number\",\n    \"value\": 3306\n  },\n  \"rds_username\": {\n    \"sensitive\": true,\n    \"type\": \"string\",\n    \"value\": \"wordpress_user\"\n  }\n}\n</code></pre> <p>You can now use these values as inputs to a workload to use this database.</p>"},{"location":"terraform/rds-database/#delete-terraform-instance","title":"Delete Terraform Instance","text":"<p>The following command will delete the database instance:</p> <pre><code>tptctl delete terraform-instance -n rds-instance-01\n</code></pre> <p>The command will not return a response until the AWS resources have been removed.  For an RDS instance this will take a few minutes.</p> <p>Once the resources are removed and the prompt returns, you can delete the Terraform definition as well.</p> <pre><code>tptctl delete terraform-definition -n rds-instance\n</code></pre>"},{"location":"terraform/rds-database/#clean-up","title":"Clean Up","text":"<p>Before we finish, let's clean up the files we downloaded to your file system.</p> <pre><code>cd ../\nrm -rf threeport-terraform-test\n</code></pre>"},{"location":"terraform/rds-database/#summary","title":"Summary","text":"<p>In this guide you used a Terraform definition and instance to deploy and delete an AWS RDS instance.  You also learned how to get the outputs from Terraform to provide DB connection info to a client application.</p> <p>Therein lies one of the challenges with Terraform: programmatically providing outputs from Terraform as inputs to another operation to deploy a workload that connects to that DB.  In the near future, we will provide guides on how to use the Threeport SDK to wire these concerns together to remove human copy-paste operations from the process.</p>"},{"location":"terraform/terraform-intro/","title":"Terraform","text":"<p>Terraform is a popular infrastructure-as-code tool used to declare the configuration for a set of cloud resources.  Terraform is commonly used as a CLI tool with a set of configs that declare the cloud resources required.</p> <p>Note: Since AWS is currently the only supported cloud provider in Threeport, Terraform use is limited to AWS.</p> <p>We offer Terraform support in Threeport since many teams have already invested in using this tool.  However, it has clear drawbacks in the logical constructs available in Terraform configs to specify resource configurations under different conditions.  It is inferior to a general purpose programming language in this respect.  Additionally, there are commonly outputs from the provisioned resources that need to be plumbed into other configs - such as for workloads. This output must be captured and stored in a way that it can be used elsewhere. This interoperability with other parts of a system must be solved for and is not ideal.</p> <p>That said, Terraform can be useful for relatively simple use cases with limited inputs (Terraform variables) and outputs.</p>"},{"location":"terraform/terraform-intro/#terraform-definition","title":"Terraform Definition","text":"<p>The definition object contains all the Terraform configs that declare the cloud resources needed.  When you create this object with <code>tptctl</code> you can simply provide the directory in which those configs live and they will be stored in the Threeport database for use when creating instances of the resource stack.</p> <p>Reference: TerraformDefinition</p>"},{"location":"terraform/terraform-intro/#terraform-instance","title":"Terraform Instance","text":"<p>A Terraform Instance takes the Terraform variables (usually in a file with the extension <code>.tfvars</code>) that provides the inputs for the config in a definition. When you create a Terraform Instance, the variables will be passed to the config and the resources defined in the Terraform Definition will be provisioned.</p> <p>Once the resources have been provisioned the Terraform controller will store the outputs in the Threeport database so they can be retrieved.</p> <p>Reference: TerraformInstance</p>"},{"location":"terraform/terraform-intro/#next-steps","title":"Next Steps","text":"<p>Check out our Deploy RDS Instance with Terraform guide for a walk through on how to use Terraform in to provision cloud resources.</p>"},{"location":"workloads/deploy-workload-aws/","title":"Deploy Workload on AWS","text":"<p>In this guide, we're going to deploy a sample WordPress app and use Threeport to manage several dependencies for it:</p> <ul> <li>Network ingress routing</li> <li>TLS termination</li> <li>DNS record using AWS Route53</li> <li>Managed database using AWS RDS</li> <li>Managed object storage using AWS S3</li> <li>Managed secrets using AWS Secrets Manager</li> </ul>"},{"location":"workloads/deploy-workload-aws/#prerequisites","title":"Prerequisites","text":"<p>You'll need a Threeport control plane for this guide.  You have two options:</p> <ol> <li>Install a Local Threeport instance and    then provision a Remote Kubernetes    Runtime for your workload.</li> <li>Install a Remote Threeport instance    on AWS and use the Kubernetes instance that is used to host Threeport to deploy    your workload.</li> </ol>"},{"location":"workloads/deploy-workload-aws/#download-sample-configs","title":"Download Sample Configs","text":"<p>First, create a work space on your local file system:</p> <pre><code>mkdir threeport-test\ncd threeport-test\n</code></pre> <p>Download a sample workload config as follows:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/workload/wordpress-workload-remote.yaml\n</code></pre> <p>You now have the workload config on your local file system.  If you open the file you'll see it has the following contents:</p> <pre><code>Workload:\n  Name: \"wordpress\"\n  YAMLDocument: \"wordpress-manifest-remote.yaml\"\n  KubernetesRuntimeInstance:\n    Name: eks-k8s-runtime\n  AwsRelationalDatabase:\n    Name: wordpress-db\n    AwsAccountName: default-account\n    Engine: mariadb\n    EngineVersion: \"10.11\"\n    DatabaseName: wordpress\n    DatabasePort: 3306\n    StorageGb: 20\n    MachineSize: XSmall\n    WorkloadSecretName: wordpress-db-conn\n  AwsObjectStorageBucket:\n    Name: s3-client-bucket\n    AwsAccountName: default-account\n    PublicReadAccess: false\n    WorkloadServiceAccountName: s3-client\n    WorkloadBucketEnvVar: S3_BUCKET_NAME\n  DomainName:\n    Name: example-domain\n    Domain: example.com\n    Zone: Public\n    AdminEmail: admin@example.com\n  Secret:\n    Name: wordpress-secret\n    AwsAccountName: default-account\n    Data:\n      WORDPRESS_PASSWORD: admin_password\n      WORDPRESS_SMTP_PASSWORD: smtp_password\n  Gateway:\n    Name: web-service-gateway\n    HttpPorts:\n      - Port: 80\n        HTTPSRedirect: true\n        Path: \"/\"\n      - Port: 443\n        TLSEnabled: true\n        Path: \"/\"\n    ServiceName: getting-started-wordpress\n    SubDomain: blog\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#name-configuration","title":"Name Configuration","text":"<p>The <code>Name</code> field is an arbitrary, user-defined name that must be unique, i.e. no other workload may use the same name.</p>"},{"location":"workloads/deploy-workload-aws/#yamldocument-configuration","title":"YAMLDocument Configuration","text":"<p>The <code>YAMLDocument</code> field refers to another file with the Kubernetes resource manifests.  Download that file as well:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/workload/wordpress-manifest-remote.yaml\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#kubernetes-runtime-configuration","title":"Kubernetes Runtime Configuration","text":"<p>Set name of the Kubernetes runtime you wish to use.  You can use <code>tptctl get kubernetes-runtime-instances</code> to see which runtimes are available.</p> <pre><code>  KubernetesRuntimeInstance:\n    Name: eks-k8s-runtime        # &lt;-- set this value\n</code></pre> <p>You can also remove this config to simply use the default runtime.</p>"},{"location":"workloads/deploy-workload-aws/#awsrelationaldatabase-configuration","title":"AwsRelationalDatabase Configuration","text":"<p>The <code>AwsRelationalDatabase</code> field includes the specification for an AWS RDS instance that will be used for the WordPress database.  Threeport will spin up that RDS instance for the sample app and connect it.  Also, when you delete your app, Threeport will clean up the RDS instance as well.</p> <p>The most important thing to note in the <code>AwsRelationalDatabase</code> config is the <code>WorkloadSecretName</code>.</p> <pre><code>  AwsRelationalDatabase:\n    Name: wordpress-db-0\n    AwsAccountName: default-account\n    Engine: mariadb\n    EngineVersion: \"10.11\"\n    DatabaseName: wordpress\n    DatabasePort: 3306\n    StorageGb: 20\n    MachineSize: XSmall\n    WorkloadSecretName: wordpress-db-conn  # &lt;-- note this value\n</code></pre> <p>The value for this field tells Threeport what name to give to the Kubernetes secret that provides the database connection credentials to the WordPress app. In the <code>wordpress-manifest-remote.yaml</code> file is the following snippet.</p> <pre><code>          env:\n            - name: BITNAMI_DEBUG\n              value: \"false\"\n            - name: ALLOW_EMPTY_PASSWORD\n              value: \"yes\"\n            - name: MARIADB_HOST\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-db-conn       ## &lt;-- secret name reference\n                  key: db-endpoint              ## &lt;-- value key\n            - name: MARIADB_PORT_NUMBER\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-db-conn       ## &lt;-- secret name reference\n                  key: db-port                  ## &lt;-- value key\n            - name: WORDPRESS_DATABASE_NAME\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-db-conn       ## &lt;-- secret name reference\n                  key: db-name                  ## &lt;-- value key\n            - name: WORDPRESS_DATABASE_USER\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-db-conn       ## &lt;-- secret name reference\n                  key: db-user                  ## &lt;-- value key\n            - name: WORDPRESS_DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-db-conn       ## &lt;-- secret name reference\n                  key: db-password              ## &lt;-- value key\n</code></pre> <p>WordPress uses specific environment variables to retrieve database connection info.  For different applications, the values from the <code>wordpress-db-conn</code> secret simply need to be mapped to the appropriate environment variables for that app.  Be sure to set the value keys shown - these are set by Threeport in the secret it creates and never change.</p>"},{"location":"workloads/deploy-workload-aws/#awsobjectstoragebucket-configuration","title":"AwsObjectStorageBucket Configuration","text":"<p>The <code>AwsObjectStorageBucket</code> field provides the configuration for the S3 bucket to be used by the application.  Note the <code>WorkloadServiceAccountName</code> and <code>WorkloadBucketEnvVar</code> values.</p> <pre><code>  AwsObjectStorageBucket:\n    Name: s3-client-bucket\n    AwsAccountName: default-account\n    PublicReadAccess: false\n    WorkloadServiceAccountName: s3-client   ## &lt;-- note this value\n    WorkloadBucketEnvVar: S3_BUCKET_NAME    ## &lt;-- note this value\n</code></pre> <p>The <code>WorkloadServiceAccountName</code> refers to the name of a service account that must be present in the <code>YAMLDocument</code>.  The service account used for this example is included in this snippet from the <code>wordpress-manifest-remote.yaml</code> file.</p> <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: s3-client       ## &lt;-- service account name\n</code></pre> <p>If a service account with the same name referenced by the <code>WorkloadServiceAccountName</code> field does not exist, the workload will not be able to connect to the S3 bucket.</p> <p>The <code>WorkloadBucketEnvVar</code> is the name of the environment variable that will be provided to the workload to get the bucket name to connect to.  Set the value to the environment variable your application will use.</p>"},{"location":"workloads/deploy-workload-aws/#domainname-configuration","title":"DomainName Configuration","text":"<p>The <code>DomainName</code> field provides a config for managing a DNS record for the sample app.  This will currently only work if you are managing a domain with Route53 in AWS with a Hosted Zone.  If you aren't using Route53, comment out the entire <code>DomainName</code> section and we'll use an AWS load balancer endpoint to connect to the sample app.  If you have a hosted zone in Route53 to use, make the following updates.</p> <pre><code>  DomainName:\n    Name: example-domain\n    Domain: example.com             # &lt;-- set your Route53 hosted zone here\n    Zone: Public\n    AdminEmail: admin@example.com   # &lt;-- put your email address here\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#secret-configuration","title":"Secret Configuration","text":"<p>The <code>Secret</code> field provides config for managing secret values for the sample app.</p> <p>Note: AWS Secrets Manager is currently the only supported provider for secrets management and will be used by default by your Threeport control plane.</p> <p>Threeport handles the integration between secrets and Kubernetes manifests in a similar manner to AWS RDS connection credentials. A secret is created in the same namespace as the sample app, and the manifests must configure the secret values as needed. Below is an example <code>Secret</code> configuration:</p> <pre><code>  Secret:\n    Name: wordpress-secret # &lt;-- note this value\n    AwsAccountName: default-account\n    Data:\n      WORDPRESS_PASSWORD: admin_password     # &lt;-- secret key and value\n      WORDPRESS_SMTP_PASSWORD: smtp_password # &lt;-- secret key and value\n</code></pre> <p>The <code>Name</code> field in an arbitrary name provided by the user.</p> <p>Important: The <code>Name</code> value determines what the secret will be called in AWS Secrets Manager.  If the provided <code>Name</code> value is already in use, Threeport will not be able to create it.  Furthermore, AWS Secrets Manager reserves the name for a restoration grace period (minimum of 7 days).  So if you delete a secret and then attempt to re-create it with the same name, it will fail if that grace period has not expired.</p> <p><code>wordpress-manifest-remote.yaml</code> contains the following snippet, which shows how secret values map into the sample app's Kubernetes manifest.</p> <pre><code>          env:\n          ...\n            - name: WORDPRESS_PASSWORD         # &lt;-- environment variable expected by app\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-secret\n                  key: WORDPRESS_PASSWORD      # &lt;-- secret data key\n            - name: WORDPRESS_SMTP_PASSWORD    # &lt;-- environment variable expected by app\n              valueFrom:\n                secretKeyRef:\n                  name: wordpress-secret\n                  key: WORDPRESS_SMTP_PASSWORD # &lt;-- secret data key\n          ...\n</code></pre> <p>Below is an example of the Kubernetes secret that is inserted into the app's namespace by the Threeport Control Plane. This object is managed on behalf of the user by Threeport and provided here for illustration purposes only. The keys within the <code>data</code> field are what must be referenced by the user-supplied manifest, as illustrated above.</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: wordpress-secret\ntype: Opaque\ndata:\n  WORDPRESS_PASSWORD: YWRtaW5fcGFzc3dvcmQ=      # encoded value of \"admin_password\"\n  WORDPRESS_SMTP_PASSWORD: c210cF9wYXNzd29yZA== # encoded value of \"smtp_password\"\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#gateway-configuration","title":"Gateway Configuration","text":"<p>The <code>Gateway</code> field includes a config to set up ingress to our sample app from the public internet and terminate TLS.  The <code>SubDomain</code> field here will result in a record for <code>blog.example.com</code> being added to the <code>example.com</code> Route53 hosted zone.</p> <pre><code>  Gateway:\n    HttpPorts:\n      - Port: 80\n        HTTPSRedirect: true\n        Path: \"/\"\n      - Port: 443\n        TLSEnabled: true\n        Path: \"/\"\n    ServiceName: getting-started-wordpress\n    SubDomain: blog                         # &lt;-- set your desired subdomain\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#create-workload","title":"Create Workload","text":"<p>Once you have made the necessary changes to the workload config, we can create the workload as follows:</p> <pre><code>tptctl create workload --config wordpress-workload-remote.yaml\n</code></pre> <p>Threeport will now do the following:</p> <ul> <li>Install the WordPress app.</li> <li>Spin up an RDS database for your app.</li> <li>Create a new S3 bucket for your app and provide workload identity access to   your app.</li> <li>If you specified a <code>DomainName</code> config, Threeport will install   external-dns on your EKS   cluster and instruct it to configure Route53.</li> <li>Install Gloo Edge for network ingress   control and configure it for your app.</li> <li>Install cert-manager to   provision and rotate TLS certificates for the sample app.   Note: the Let's Encrypt staging environment will   be used for this guide.  This means the certificate issued will not be   publicly trusted - you will have to tell your browser to trust it.  When the   production environment is used, it will be publicly trusted.</li> </ul>"},{"location":"workloads/deploy-workload-aws/#validate","title":"Validate","text":"<p>It will take a few minutes for AWS to spin up the RDS database instance. You can check the RDS console in AWS to track its progress if you like. Shortly after the database is up, Threeport will create a secret to provide the database connection credentials to the sample app and it will begin running.</p>"},{"location":"workloads/deploy-workload-aws/#kubernetes-resources","title":"Kubernetes Resources","text":"<p>If you have kubectl and the AWS CLI installed, you can check the progress of the app as follows.</p> <p>Update your kubeconfig:</p> <pre><code>aws eks update-kubeconfig --name threeport-test\n</code></pre> <p>Then, view the pods in the remote Kubernetes cluster:</p> <pre><code>kubectl get pods -A\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#visit-wordpress-app","title":"Visit WordPress App","text":"<p>Once your WordPress app pods show Status: Running, your app is ready to visit.</p> <p>Remember, you will need to tell your browser to trust the connection as we're using the Let's Encrypt staging environment.</p> <p>In your browser, visit: <code>https://www.example.com</code>.  Change the domain to the one you used, or replace it with the AWS load balancer endpoint which can be found in the AWS EC2 console.</p>"},{"location":"workloads/deploy-workload-aws/#s3-bucket","title":"S3 Bucket","text":"<p>The sample WordPress app in this guide does not actually use the S3 bucket. However we can validate that it works as follows.</p> <p>Threeport has taken care of access to the S3 bucket using IAM roles for service accounts (IRSA) and provided the environment variable to retrieve the bucket name.  So we can just connect to the container and test it out.</p> <p>First, get the managed namespace for the app.</p> <pre><code>export WORDPRESS_NAMESPACE=$(kubectl get ns -l \"control-plane.threeport.io/managed-by=threeport\" -o=jsonpath='{.items[0].metadata.name}')\n</code></pre> <p>Next get the pod name.</p> <pre><code>export WORDPRESS_POD=$(kubectl get po -n $WORDPRESS_NAMESPACE -o=jsonpath='{.items[0].metadata.name}')\n</code></pre> <p>Now we can connect to the S3 client sidecar container.</p> <pre><code>kubectl exec -it -n $WORDPRESS_NAMESPACE $WORDPRESS_POD -c s3-client -- bash\n</code></pre> <p>You should now have a shell inside that container.  Next, create a file to transfer to S3.</p> <pre><code>echo \"test file content\" &gt; testing.txt\n</code></pre> <p>Now we can transfer the file to S3.  This container has the aws CLI tool installed.</p> <pre><code>aws s3 cp testing.txt s3://$S3_BUCKET_NAME\n</code></pre> <p>You can now verify in the S3 AWS console that the file has been transferred successfully.  At this point you can delete the file from S3 to ensure the bucket can be cleaned up.  (AWS will not remove a bucket that has objects in it.)</p> <p>Now exit the container.</p> <pre><code>exit\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#clean-up","title":"Clean Up","text":""},{"location":"workloads/deploy-workload-aws/#wordpress-workload","title":"WordPress Workload","text":"<p>Threeport will not delete a Kubernetes cluster with workload instances running by default.  This prevents inadvertently deleting apps that need to continue running.</p> <p>View the workload instances with:</p> <pre><code>tptctl get workload-instances\n</code></pre> <p>Delete the WordPress workload instance.</p> <pre><code>tptctl delete workload-instance -n wordpress\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#support-service-workloads","title":"Support Service Workloads","text":"<p>If you used a <code>DomainName</code> config, ensure your DNS records have been removed (it can take a minute or two for external-dns to clean those up), then delete the gloo-edge and external-dns workloads.</p> <p>Delete the Gloo Edge, external-dns and external-secrets workload instances.</p> <pre><code>tptctl delete workload-instance -n gloo-edge-threeport-test # name may differ\ntptctl delete workload-instance -n external-dns-threeport-test # name may differ\ntptctl delete workload-instance -n external-secrets-threeport-test  # name may difer\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#secret-definition","title":"Secret Definition","text":"<p>To delete the secret from AWS Secrets Manager, first check the name of the secret definition:</p> <pre><code>tptctl get secret-definitions\n</code></pre> <p>You should see something like this in the output:</p> <pre><code>NAME                  AGE\nwordpress-secret      24m19s\n</code></pre> <p>Then delete it by name to remove it from AWS Secrets Manager:</p> <pre><code>tptctl delete secret-definition -n wordpress-secret\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#threeport-control-plane","title":"Threeport Control Plane","text":"<p>Uninstall Threeport:</p> <p>Give Threeport a few minutes to clean up your AWS resources, then remove the control plane.  If you delete the control plane before it has finished removing the gloo-edge service resource, you will be left with a dangling AWS load balancer which will prevent tearing down all of the AWS infra.</p> <pre><code>tptctl down -n test\n</code></pre> <p>Remove the test configs from you file system:</p> <pre><code>cd ../\nrm -rf threeport-test\n</code></pre>"},{"location":"workloads/deploy-workload-aws/#next-steps","title":"Next Steps","text":"<p>Now that you've tried out Threeport with a sample WordPress workload, we suggest you try it out with one of your workloads.  Get in touch via Discord if you have any questions.</p> <p>Also, check out the Managed Threeport offerings to fast-track getting Threeport into use at your organization.</p>"},{"location":"workloads/deploy-workload-local/","title":"Deploy Workload Locally","text":"<p>In this guide, we're going to use the simplest possible mechanism to deploy an app.  It uses a very basic workload config.</p>"},{"location":"workloads/deploy-workload-local/#prerequisites","title":"Prerequisites","text":"<p>You'll need a local Threeport control plane for this guide.  Follow the Install Threeport Locally guide to set that up.</p>"},{"location":"workloads/deploy-workload-local/#configs","title":"Configs","text":"<p>First, create a work space on your local file system:</p> <pre><code>mkdir threeport-test\ncd threeport-test\n</code></pre> <p>Download a sample workload config as follows:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/workload/wordpress-workload-local.yaml\n</code></pre> <p>You now have the workload config on your local file system.  If you open the file you'll see it has the following fields:</p> <pre><code>Workload:\n  Name: \"wordpress\"\n  YAMLDocument: \"wordpress-manifest-local.yaml\"\n</code></pre> <p>The <code>Name</code> field is an arbitrary user-defined name that must be unique, i.e. no other workload may use the same name.</p> <p>The <code>YAMLDocument</code> field refers to another file with the Kubernetes resource manifests.  Download that file as well:</p> <pre><code>curl -O https://raw.githubusercontent.com/threeport/threeport/main/samples/workload/wordpress-manifest-local.yaml\n</code></pre>"},{"location":"workloads/deploy-workload-local/#create-workload","title":"Create Workload","text":"<p>We can now create the workload as follows:</p> <pre><code>tptctl create workload --config wordpress-workload-local.yaml\n</code></pre> <p>This command calls the Threeport API to create the Workload objects. The API notifies the workload controller via the message broker.  The workload controller processes the workload definition and creates the workload instance by calling the Kubernetes API.</p> <p>We can use <code>tptctl</code> to view deployed workloads:</p> <pre><code>tptctl get workloads\n</code></pre> <p>Note: the status of the workload will state <code>Reconciling</code> or <code>Down</code> for a short time until the workload is running.  It will usually take a minute or two for the container images to be pulled to start the containers.  Once the Threeport agent confirms the workload is up, you will see the status become <code>Healthy</code>.</p> <p>We can also use <code>kubectl</code> to query the Kubernetes API directly. First, set a local environment variable to the appropriate namespace for the WordPress application:</p> <pre><code>NAMESPACE=$(kubectl get namespace -l control-plane.threeport.io/managed-by=threeport -o=jsonpath='{.items[0].metadata.name}')\n</code></pre> <p>Confirm the WordPress application is running with:</p> <pre><code>kubectl get pods -l app.kubernetes.io/instance=getting-started -n $NAMESPACE\n</code></pre> <p>If using the kind provider, you can now visit the WordPress application by forwarding a local port to it with this command:</p> <pre><code>kubectl port-forward svc/getting-started-wordpress 8080:80 -n $NAMESPACE\n</code></pre> <p>Now visit the app here.  It will display the welcome screen of the WordPress application.</p>"},{"location":"workloads/deploy-workload-local/#namespace-management","title":"Namespace Management","text":"<p>You may have noticed the Kubernetes manifest does not include a namespace resource for the sample WordPress app.  This is the recommended way to deploy workloads with Threeport.  If you don't supply a namespace, Threeport will manage namespaces for you, allowing you to seamlessly deploy multiple instances of a workload to a particular Kubernetes cluster.</p>"},{"location":"workloads/deploy-workload-local/#summary","title":"Summary","text":"<p>This diagram illustrates the relationships between components introduced in this guide.</p> <p></p> <p>When we installed Threeport using <code>tptctl up</code> we created a new control plane on a new Kubernetes cluster.</p> <p>When we installed the sample app using <code>tptctl create workload</code> we called the Threeport API to create the workload.  The reconciliation for these objects was carried out by the workload controller which created the necessary Kubernetes resources via the Kubernetes control plane.</p> <p>While this approach doesn't provide any special outcomes that you could not have achieved with other tools, it does do something unique under the hood.  It manages Kubernetes workloads using a workload abstraction and the corresponding controller that enables the following:</p> <ul> <li>Support Service Dependency Management: Installing and configuring support   services such as ingress, TLS termination, DNS management and more.</li> <li>Cloud Provider Service Dependency Management: Calling cloud providers on your   behalf to spin up managed services such as S3 and RDS that your app relies on.</li> </ul> <p>To see these features in action, see our guides on installing Threeport in AWS and deploying workloads there.</p>"},{"location":"workloads/deploy-workload-local/#clean-up","title":"Clean Up","text":"<p>To delete a workload: <pre><code>tptctl delete workload --config wordpress-workload-local.yaml\n</code></pre></p> <p>To uninstall the Threeport control plane locally:</p> <pre><code>tptctl down control-plane -n test\n</code></pre> <p>Remove the test configs from you file system:</p> <pre><code>cd ../\nrm -rf threeport-test\n</code></pre>"},{"location":"workloads/deploy-workload-local/#next-steps","title":"Next Steps","text":"<p>Next, we recommend you try out Threeport on AWS.  See our Install Threeport on AWS guide for instructions.</p>"},{"location":"workloads/namespaces/","title":"Namespaces","text":"<p>When deploying workloads, Threeport can manage Kubernetes namespaces for you. This is the recommended approach.</p>"},{"location":"workloads/namespaces/#prerequisites","title":"Prerequisites","text":"<p>For this guide you will need a Threeport control plane installed.  Follow the Install Threeport Locally guide to install a local control plane.</p>"},{"location":"workloads/namespaces/#unmanaged-namespaces","title":"Unmanaged Namespaces","text":"<p>If you do not want Threeport to manage Kubernetes namespaces for you, you will need to include the Namespace resource in the workload definition's <code>YAMLDocument</code> that provides the manifest of Kubernetes resources.</p> <p>To demonstrate, create a work space on your local file system.</p> <pre><code>mkdir threeport-test\ncd threeport-test\n</code></pre> <p>Create a very simple Kubernetes manifest to deploy a pod into a namespace.</p> <pre><code>cat &lt;&lt;EOF &gt; unmanaged-nginx-manifest.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: test-nginx\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: test-nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    ports:\n    - containerPort: 80\nEOF\n</code></pre> <p>This Kubernetes manifest includes a Namespace resource and the Pod resource must have its <code>metadata.namespace</code> set to the same namespace.  This is an example of the user managing the namespace, not Threeport.</p> <p>Next we'll need workload configs for Threeport.  Let's create the WorkloadDefinition.</p> <pre><code>cat &lt;&lt;EOF &gt; unmanaged-nginx-workload-definition.yaml\nWorkloadDefinition:\n  Name: unmanaged-nginx\n  YAMLDocument: unmanaged-nginx-manifest.yaml\nEOF\n</code></pre> <p>And a WorkloadInstance.</p> <pre><code>cat &lt;&lt;EOF &gt; unmanaged-nginx-workload-instance-0.yaml\nWorkloadInstance:\n  Name: unmanaged-nginx-0\n  WorkloadDefinition:\n    Name: unmanaged-nginx\nEOF\n</code></pre> <p>Now let's create those workload resources.</p> <pre><code>tptctl create workload-definition -c unmanaged-nginx-workload-definition.yaml\ntptctl create workload-instance -c unmanaged-nginx-workload-instance-0.yaml\n</code></pre> <p>We can now see the objects we created in Threeport.</p> <pre><code>tptctl get workloads\n</code></pre> <p>You should see the following output.</p> <pre><code>NAME                 WORKLOAD DEFINITION     WORKLOAD INSTANCE      KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nunmanaged-nginx      unmanaged-nginx         unmanaged-nginx-0      threeport-dev                   Healthy      42s\n</code></pre> <p>If you have kubectl installed, you can see the pod resource in Kubernetes as well.</p> <pre><code>kubectl get po -n test-nginx\n</code></pre> <p>Now let's attempt to create a second instance of this workload.  We'll create a second workload instance that references the same workload definition.</p> <pre><code>cat &lt;&lt;EOF &gt; unmanaged-nginx-workload-instance-1.yaml\nWorkloadInstance:\n  Name: unmanaged-nginx-1\n  WorkloadDefinition:\n    Name: unmanaged-nginx\nEOF\n</code></pre> <p>When you create the workload instance you will get an error.</p> <pre><code>tptctl create workload-instance -c unmanaged-nginx-workload-instance-1.yaml\n</code></pre> <p>This is because the workload definition for this instance contains a namespace. Another namespace with the same name cannot be created in Kubernetes so a new, distinct workload using this manifest is impossible.</p> <p>In order to create multiple workload instances in a Kubernetes runtime from a single definition, use managed namespaces in Threeport.</p>"},{"location":"workloads/namespaces/#managed-namespaces","title":"Managed Namespaces","text":"<p>The recommended approach is to use managed namespaces in Threeport.</p> <p>To demonstrate, create a very simple Kubernetes manifest to deploy a pod.</p> <pre><code>cat &lt;&lt;EOF &gt; managed-nginx-manifest.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    ports:\n    - containerPort: 80\nEOF\n</code></pre> <p>This Kubernetes manifest includes only the Pod resource without any reference to a namespace.  In this case, Threeport will manage the namespace for you so you don't need to include the Namespace resource.</p> <p>Next we'll need workload configs for Threeport.  Let's create the WorkloadDefinition.</p> <pre><code>cat &lt;&lt;EOF &gt; managed-nginx-workload-definition.yaml\nWorkloadDefinition:\n  Name: managed-nginx\n  YAMLDocument: managed-nginx-manifest.yaml\nEOF\n</code></pre> <p>And a WorkloadInstance.</p> <pre><code>cat &lt;&lt;EOF &gt; managed-nginx-workload-instance-0.yaml\nWorkloadInstance:\n  Name: managed-nginx-0\n  WorkloadDefinition:\n    Name: managed-nginx\nEOF\n</code></pre> <p>Now let's create those workload resources.</p> <pre><code>tptctl create workload-definition -c managed-nginx-workload-definition.yaml\ntptctl create workload-instance -c managed-nginx-workload-instance-0.yaml\n</code></pre> <p>List the Threeport workloads.</p> <pre><code>tptctl get workloads\n</code></pre> <p>You should see the following output.</p> <pre><code>NAME                 WORKLOAD DEFINITION     WORKLOAD INSTANCE      KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nunmanaged-nginx      unmanaged-nginx         unmanaged-nginx-0      threeport-dev-0                 Healthy      2h36m34s\nmanaged-nginx        managed-nginx           managed-nginx-0        threeport-dev-0                 Healthy      1m22s\n</code></pre> <p>If you have kubectl installed, you can query the namespaces and see a new namespace has been created.</p> <pre><code>kubectl get ns\n</code></pre> <p>There will be a new namespace called something like <code>managed-nginx-0-4g0i0kshyu</code>.  Yours will be slightly different because Threeport puts a random suffix on the namespace name.  This namespace is where the nginx pod is running.</p> <p>Now we can create a second instance of this workload.  We'll create a second workload instance that references the same workload definition.</p> <pre><code>cat &lt;&lt;EOF &gt; managed-nginx-workload-instance-1.yaml\nWorkloadInstance:\n  Name: managed-nginx-1\n  WorkloadDefinition:\n    Name: managed-nginx\nEOF\n</code></pre> <p>And you can now successfully create a second instance.</p> <pre><code>tptctl create workload-instance -c managed-nginx-workload-instance-1.yaml\n</code></pre> <p>Now you can list Threeport workloads again.</p> <pre><code>tptctl get workloads\n</code></pre> <p>You should see the following:</p> <pre><code>NAME                 WORKLOAD DEFINITION     WORKLOAD INSTANCE      KUBERNETES RUNTIME INSTANCE     STATUS       AGE\nunmanaged-nginx      unmanaged-nginx         unmanaged-nginx-0      threeport-dev-0                 Healthy      2h45m35s\nmanaged-nginx        managed-nginx           managed-nginx-0        threeport-dev-0                 Healthy      10m22s\nmanaged-nginx        managed-nginx           managed-nginx-1        threeport-dev-0                 Healthy      2m58s\n</code></pre> <p>Notice there are two instances of the <code>managed-nginx</code> workload derived from the same workload definition.</p> <p>You can also re-check the namespaces in your cluster.</p> <pre><code>kubectl get ns | grep nginx\n</code></pre> <p>You should see results similar to this:</p> <pre><code>managed-nginx-0-4g0i0kshyu   Active   8m5s\nmanaged-nginx-1-5nuxe87le3   Active   42s\ntest-nginx                   Active   163m\n</code></pre> <p>In this way, using managed namespaces, you are free to deploy as many workload instances to a Kubernetes cluster from a common workload definition as you wish. When using unmanaged namespaces you are limited to one workload instance per workload definition in a single Kubernetes runtime instance.</p>"},{"location":"workloads/namespaces/#summary","title":"Summary","text":"<p>In this guide you have seen how to use managed namespaces in Threeport and the utility they provide in allowing you to deploy as many workload instances from a single workload definition to a single Kubernetes runtime instance as you like.</p> <p>Clean up.</p> <pre><code>cd ../\nrm -rf threeport-test\n</code></pre>"},{"location":"workloads/workload-intro/","title":"Workloads","text":"<p>A Workload is a set of Kubernetes resources that constitute some software that you want to run on a server somewhere.</p>"},{"location":"workloads/workload-intro/#workload-vs-application","title":"Workload vs Application","text":"<p>What do we mean by these terms?  A \"workload\" is just an arbitrary grouping of Kubernetes resources.  To be meaningful, it generally implies that it includes Kubernetes resources that run some kind of containerized software, such as:</p> <ul> <li>Pod</li> <li>Deployment</li> <li>StatefulSet</li> <li>DaemonSet</li> <li>Job</li> </ul> <p>An application is a software system that provides value to an end user.  That software system could be a single workload or a group of workloads in a distributed system.  Many applications include not just workloads, but also managed services offered by a cloud provider, such as a managed database or job queue.</p>"},{"location":"workloads/workload-intro/#workload-constitution","title":"Workload Constitution","text":"<p>This begs the question of how you should define and separate Workloads that make up some distributed application.  There are no hard and fast rules.  It is up to the Threeport user but here are some considerations:</p> <ul> <li>If a code repo produces a single program that runs on a server and serves   traffic, such as a web application, that would make sense to deploy as a   Workload.</li> <li>Anything that can be updated or upgraded independently of other services in a   distributed application system, should be managed as its own distinct   Workload.</li> <li>A web application that uses a dedicated database that always has a one-to-one   relationship, both the web app and database can be deployed together as a   single Workload, since one without the other is meaningless.</li> <li>If different components of a software system are managed by different teams,   it usually works best for each team to define and use distinct Workloads in   Threeport.</li> </ul>"},{"location":"workloads/workload-intro/#workload-definition","title":"Workload Definition","text":"<p>The definition for a workload includes all the Kubernetes resources needed to run the containerized workload.  You will need to create a Kubernetes resource manifest to reference in the Workload Definition config.</p> <p>Reference: WorkloadDefinition</p>"},{"location":"workloads/workload-intro/#workload-instance","title":"Workload Instance","text":"<p>A workload instance allows you to specify which Kubernetes Runtime Instance you would like to run the workload in.</p> <p>Reference: WorkloadInstance</p> <p>Note: You can also run multiple instances of a workload in a single Kubernetes cluster if you use Threeport to manage Kubernetes namespaces.  See the Namespaces guide for more info.</p>"},{"location":"workloads/workload-intro/#next-steps","title":"Next Steps","text":"<p>In order to get a practical grasp on deploying Workloads, see our Local Workload guide to try it out on your workstation.</p> <p>If you'd like to deploy a sample Workload into AWS using Threeport, see our Remote Workload guide.</p>"}]}